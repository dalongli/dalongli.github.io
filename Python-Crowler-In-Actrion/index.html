<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<link rel="icon" href="/assets/images/logo.png">

<title>Python Crowler In Action | Dalong's personal blog</title>

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Python Crowler In Action | Dalong’s personal blog</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="Python Crowler In Action" />
<meta name="author" content="Dalong" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="网络爬网是一种强大的技术，通过查找一个或多个域的所有 URL 来从网络收集数据。Python有几个流行的网络爬虫库和框架。 在本文中，我们将介绍不同的框架, 抓取策略和用例。使用 Python 从头开始构建简单的网络爬虫, 并告诉你为什么最好使用像 Scrapy 这样的网络爬虫框架。" />
<meta property="og:description" content="网络爬网是一种强大的技术，通过查找一个或多个域的所有 URL 来从网络收集数据。Python有几个流行的网络爬虫库和框架。 在本文中，我们将介绍不同的框架, 抓取策略和用例。使用 Python 从头开始构建简单的网络爬虫, 并告诉你为什么最好使用像 Scrapy 这样的网络爬虫框架。" />
<link rel="canonical" href="http://localhost:4000/Python-Crowler-In-Actrion/" />
<meta property="og:url" content="http://localhost:4000/Python-Crowler-In-Actrion/" />
<meta property="og:site_name" content="Dalong’s personal blog" />
<meta property="og:image" content="http://localhost:4000/assets/images/crower.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-09-24T00:00:00+08:00" />
<script type="application/ld+json">
{"@type":"BlogPosting","headline":"Python Crowler In Action","dateModified":"2018-09-24T00:00:00+08:00","datePublished":"2018-09-24T00:00:00+08:00","description":"网络爬网是一种强大的技术，通过查找一个或多个域的所有 URL 来从网络收集数据。Python有几个流行的网络爬虫库和框架。 在本文中，我们将介绍不同的框架, 抓取策略和用例。使用 Python 从头开始构建简单的网络爬虫, 并告诉你为什么最好使用像 Scrapy 这样的网络爬虫框架。","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/images/logo.png"},"name":"Dalong"},"image":"http://localhost:4000/assets/images/crower.png","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/Python-Crowler-In-Actrion/"},"url":"http://localhost:4000/Python-Crowler-In-Actrion/","author":{"@type":"Person","name":"Dalong"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
    
<link href="/assets/css/screen.css" rel="stylesheet">

<link href="/assets/css/main.css" rel="stylesheet">

<script src="/assets/js/jquery.min.js"></script>

</head>




<body class="layout-post">
	<!-- defer loading of font and font awesome -->
	<noscript id="deferred-styles">
		<link href="https://fonts.googleapis.com/css?family=Righteous%7CMerriweather:300,300i,400,400i,700,700i" rel="stylesheet">
		<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">
        <link rel="preconnect" href="https://fonts.googleapis.com"> 
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> 
        <link href="https://fonts.googleapis.com/css2?family=Carter+One&display=swap" rel="stylesheet">
    </noscript>


<!-- Begin Menu Navigation
================================================== -->
<nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top mediumnavigation nav-down">

    <div class="container pr-0">

    <!-- Begin Logo -->
    <a class="navbar-brand" href="/">
    <img src="/assets/images/logo.png" alt="Dalong's personal blog">
    </a>
    <!-- End Logo -->

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarMediumish" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarMediumish">

        <!-- Begin Menu -->

            <ul class="navbar-nav ml-auto">

                
                <li class="nav-item">
                
                <a class="nav-link" href="/index.html">Blog</a>
                </li>

                <li class="nav-item">
                <a class="nav-link" href="/about">About</a>
                </li>

<!-- 以后再加上相关链接

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://bootstrapstarter.com/bootstrap-templates/template-mediumish-bootstrap-jekyll/"> Docs</a>
                </li>

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://www.wowthemes.net/themes/mediumish-wordpress/"><i class="fab fa-wordpress-simple"></i> WP Version</a>
                </li>

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://www.wowthemes.net/themes/mediumish-ghost/"><i class="fab fa-snapchat-ghost"></i> Ghost Version</a>
                </li>
-->
                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://github.com/dalongli"><i class="fab fa-github"></i> Fork on Github</a>
                </li>

                <script src="/assets/js/lunr.js"></script>


<style>
    .lunrsearchresult .title {color: #d9230f;}
    .lunrsearchresult .url {color: silver;}
    .lunrsearchresult a {display: block; color: #777;}
    .lunrsearchresult a:hover, .lunrsearchresult a:focus {text-decoration: none;}
    .lunrsearchresult a:hover .title {text-decoration: underline;}
</style>


<form class="bd-search" onSubmit="return lunr_search(document.getElementById('lunrsearch').value);">
    <input type="text" class="form-control text-small launch-modal-search" id="lunrsearch" name="q" maxlength="255" value="" placeholder="Type and enter..."/>
</form>

<div id="lunrsearchresults">
    <ul></ul>
</div>

<script src="/assets/js/lunrsearchengine.js"></script>

            </ul>

        <!-- End Menu -->

    </div>

    </div>
</nav>
<!-- End Navigation
================================================== -->

<div class="site-content">

<div class="container">

<!-- Site Title
================================================== -->
<div class="mainheading">
    <h1 class="sitetitle">Dalong's personal blog</h1>
    <p class="lead">
        Record the bits and pieces of the technology big bang.
    </p>
</div>

<!-- Content
================================================== -->
<div class="main-content">
    <!-- Begin Article
================================================== -->
<div class="container">
    <div class="row">

        <!-- Post Share -->
        <div class="col-md-2 pl-0">
            <div class="share sticky-top sticky-top-offset">
    <p>
        Share
    </p>
    <ul>
        <li class="ml-1 mr-1">
            <a target="_blank" href="https://twitter.com/intent/tweet?text=Python Crowler In Action&url=http://localhost:4000/Python-Crowler-In-Actrion/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                <i class="fab fa-twitter"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://facebook.com/sharer.php?u=http://localhost:4000/Python-Crowler-In-Actrion/" onclick="window.open(this.href, 'facebook-share', 'width=550,height=435');return false;">
                <i class="fab fa-facebook-f"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/Python-Crowler-In-Actrion/" onclick="window.open(this.href, 'width=550,height=435');return false;">
                <i class="fab fa-linkedin-in"></i>
            </a>
        </li>

    </ul>
    
    <div class="sep">
    </div>
    <ul>
        <li>
        <a class="small smoothscroll" href="#disqus_thread"></a>
        </li>
    </ul>
    
</div>

        </div>

        <!-- Post -->
        

        <div class="col-md-9 flex-first flex-md-unordered">
            <div class="mainheading">

                <!-- Author Box -->
                
                <div class="row post-top-meta">
                    <div class="col-xs-12 col-md-3 col-lg-2 text-center text-md-left mb-4 mb-md-0">
                        
                        <img class="author-thumb" src="/assets/images/avatar_dl.png" alt="Dalong">
                        
                    </div>
                    <div class="col-xs-12 col-md-9 col-lg-10 text-center text-md-left">
                        <a target="_blank" class="link-dark" href="https://dalongli.github.io/about">Dalong</a><a target="_blank" href="https://dalongli.github.io." class="btn follow">Follow</a>
                        <span class="author-description">A profesional technical consultant and blogger.</span>
                    </div>
                </div>
                

                <!-- Post Title -->
                <h1 class="posttitle">Python Crowler In Action</h1>

            </div>

            <!-- Adsense if enabled from _config.yml (change your pub id and slot) -->
            
            <!-- End Adsense -->

            <!-- Post Featured Image -->
            

            
            <img class="featured-image img-fluid" src="/assets/images/crower.png" alt="Python Crowler In Action">
            

            
            <!-- End Featured Image -->

            <!-- Post Content -->
            <div class="article-post">
                <!-- Toc if any -->
                
                    
                    <div class="toc mt-4 mb-4 lead">
                        <h3 class="font-weight-bold">Summary</h3>
                        <ul>
  <li><a href="#爬虫">爬虫</a>
    <ul>
      <li><a href="#课程大纲内容">课程大纲内容</a></li>
      <li><a href="#爬虫概览">爬虫概览</a>
        <ul>
          <li><a href="#核心-数据分析">核心: 数据分析</a></li>
          <li><a href="#难点-爬虫和反爬虫的博弈">难点: 爬虫和反爬虫的博弈</a></li>
          <li><a href="#爬虫相关开发语言-python-java-php-python-更灵活-有-scrapy-框架">爬虫相关开发语言: Python, Java, PHP. (Python 更灵活, 有 scrapy 框架)</a></li>
          <li><a href="#爬虫分类">爬虫分类:</a>
            <ul>
              <li><a href="#一--通用爬虫-比如百度-360-google-sougou等搜索引"><strong>一 , 通用爬虫</strong>: 比如百度, 360, google, sougou等搜索引</a></li>
              <li><a href="#二-专项爬虫-根据自己的需求-实现爬虫程序-抓取需要的数据">二, <strong>专项爬虫</strong>: 根据自己的需求, 实现爬虫程序, 抓取需要的数据</a></li>
            </ul>
          </li>
          <li><a href="#请求头信息">请求头信息:</a></li>
          <li><a href="#响应头信息">响应头信息:</a></li>
          <li><a href="#使用工具---fiddler">使用工具 - fiddler</a></li>
        </ul>
      </li>
      <li><a href="#urllib-库">Urllib 库</a>
      - {:.} <a href="#读取url-urllibrequesturlopen-respread-respgeturl-respgetcode-respgetheaders">读取URL <code class="language-plaintext highlighter-rouge">urllib.request.urlopen(), resp.read(), resp.geturl(), resp.getcode(), resp.getheaders()</code></a>
      - {:.} <a href="#保存读取内容到文件-urllibrequesturlretrieve">保存读取内容到文件 <code class="language-plaintext highlighter-rouge">urllib.request.urlretrieve()</code></a>
      - {:.} <a href="#url-中汉字参数的处理--urllibparseurlencode">URL 中汉字参数的处理  <code class="language-plaintext highlighter-rouge">urllib.parse.urlencode()</code></a>
      - {:.} <a href="#模拟浏览器请求--urllibrequestrequest">模拟浏览器请求  <code class="language-plaintext highlighter-rouge">urllib.request.Request()</code></a>
      - {:.} <a href="#post-请求">POST 请求</a>
      - {:.} <a href="#ajax-请求">AJAX 请求</a>
      - {:.} <a href="#urlerror--httperror">URLError / HTTPError</a>
      - {:.} <a href="#cookie-处理">Cookie 处理</a>
      - {:.} <a href="#代理服务器">代理服务器</a>
      - {:.} <a href="#mac-设置代理的方法"><a href="http://www.beihaiting.com/a/SJC/PG/20141122/5726.html">Mac 设置代理的方法</a></a>
      - {:.} <a href="#用代码配置爬虫代理">用代码配置爬虫代理</a></li>
      <li><a href="#用正则表达式爬取数据">用正则表达式爬取数据</a></li>
      <li><a href="#xpath">XPath</a></li>
      <li><a href="#beautiful-soap-爬取网页">Beautiful soap 爬取网页</a></li>
      <li><a href="#selenium-模仿浏览器操作行为">selenium 模仿浏览器操作行为</a></li>
      <li><a href="#phantomjs-配合-selenium-进行无界面浏览器的模拟浏览">phantomJS 配合 selenium 进行无界面浏览器的模拟浏览</a></li>
      <li><a href="#jsonpath">jsonPath</a></li>
      <li><a href="#requests-库">requests 库</a></li>
      <li><a href="#scrapy">Scrapy</a>
        <ul>
          <li><a href="#概念与安装">概念与安装</a></li>
          <li><a href="#实战一-糗事百科-拿作者头像-名称和内容">实战一: 糗事百科, 拿作者头像, 名称和内容</a></li>
          <li><a href="#scrapy-shell-介绍">Scrapy Shell 介绍</a>
      - {:.} <a href="#用-xpath-获取数据"><em>用 xpath 获取数据</em></a>
      - {:.} <a href="#用responsecss-定位数据"><em>用response.css 定位数据</em></a></li>
          <li><a href="#pipelinespy-的作用">pipelines.py 的作用</a>
            <ul>
              <li><a href="#实例分析--抓取百度首页的文字">实例分析 – 抓取百度首页的文字</a></li>
              <li><a href="#案例二-抓取电影信息">案例二: 抓取电影信息</a></li>
            </ul>
          </li>
          <li><a href="#链接提取器-link-extractors">链接提取器 Link Extractors</a></li>
          <li><a href="#爬虫的日志信息">爬虫的日志信息</a></li>
          <li><a href="#post-请求-1">POST 请求</a>
            <ul>
              <li><a href="#小练习-爬取王者荣耀官网">小练习: 爬取王者荣耀官网</a></li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
                    </div>
                
                <!-- End Toc -->
                <p>网络爬网是一种强大的技术，通过查找一个或多个域的所有 URL 来从网络收集数据。Python有几个流行的网络爬虫库和框架。  在本文中，我们将介绍不同的框架, 抓取策略和用例。使用 Python 从头开始构建简单的网络爬虫, 并告诉你为什么最好使用像 Scrapy 这样的网络爬虫框架。</p>

<h1 id="爬虫">爬虫</h1>

<p>[TOC]</p>

<h2 id="课程大纲内容">课程大纲内容</h2>

<ul>
  <li>用到的Python 库
    <ul>
      <li>urllib.request</li>
      <li>urllib.parse</li>
      <li>requests</li>
    </ul>
  </li>
  <li>解析内容:
    <ul>
      <li>正则表达式</li>
      <li>xpath</li>
      <li>bs4</li>
      <li>jsonpath</li>
    </ul>
  </li>
  <li>采集动态内容
    <ul>
      <li>selenium+phantomjs
        <ul>
          <li>网页中有些内容是动态加载的, 比如通过 js 或者 ajax 加载产生的数据</li>
          <li>因为如果只对静态内容爬取,可能导致获取内容不全, 所以需要模拟浏览器的请求, 获取动态内容部分.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>scrapy 框架</strong>
    <ul>
      <li>高性能的异步网络爬虫框架</li>
    </ul>
  </li>
  <li>分布式爬虫
    <ul>
      <li>scrapy-redis 组件, 通过多台电脑, 同时爬取数据, 结合redis 数据库存储数据</li>
    </ul>
  </li>
  <li>反爬虫
    <ul>
      <li>某些数据比较敏感, 不希望爬虫爬取的方法.  是爬虫和反爬虫的博弈</li>
      <li>手段:
        <ul>
          <li>User-Agent: 浏览器的标志信息, 会通过请求头传递给服务器端, 用于说明访问网站的客户端信息. 服务端会检查UA是否合法. 不合法就会禁止爬虫访问</li>
          <li>代理: 服务端通过检查请求客户端IP 来确定是否是爬虫. 解决方法是去找代理开改变自己的IP地址.</li>
          <li>验证码访问: 服务端通过验证码来判断访问者是人还是爬虫. 如果想解决, 就可能需要半自动的方式 – 手工输入验证码, 然后继续爬取</li>
          <li>验证加密: 服务端将内容加密, 客户端就无法读取内容</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="爬虫概览">爬虫概览</h2>

<h3 id="核心-数据分析">核心: 数据分析</h3>

<h3 id="难点-爬虫和反爬虫的博弈">难点: 爬虫和反爬虫的博弈</h3>

<h3 id="爬虫相关开发语言-python-java-php-python-更灵活-有-scrapy-框架">爬虫相关开发语言: Python, Java, PHP. (Python 更灵活, 有 scrapy 框架)</h3>

<h3 id="爬虫分类">爬虫分类:</h3>

<h4 id="一--通用爬虫-比如百度-360-google-sougou等搜索引"><strong>一 , 通用爬虫</strong>: 比如百度, 360, google, sougou等搜索引</h4>

<p>访问网页-&gt;抓取数据-&gt;数据存储-&gt;数据处理-&gt;提供检索服务</p>

<p><strong>爬取方式</strong>:</p>

<ol>
  <li>给定起始URL, 放入爬取队列.</li>
  <li>从队列中获取URL 对象, 开始爬取</li>
  <li>分析网页, 获取该网页内所有URL, 再加入队列, 继续重复这第2部操作</li>
</ol>

<p><strong>如何让百度爬取到你的网页</strong></p>

<ol>
  <li>主动提交到搜索引擎</li>
  <li>在其他网站设置友情链接</li>
  <li>百度和CDN服务商合作, 只要有域名, 就会被百度爬取</li>
</ol>

<p><strong>如何限制爬虫抓取你的网站</strong></p>

<ol>
  <li>
    <p>robots.txt 可以进行限制, 比如 https://www.taobao.com/robots.txt</p>

    <pre><code class="language-txt">User-agent:  Baiduspider
Allow:  /article
Allow:  /oshtml
Disallow:  /product/
Disallow:  /

User-Agent:  Googlebot
Allow:  /article
Allow:  /oshtml
Allow:  /product
Allow:  /spu
Allow:  /dianpu
Allow:  /oversea
Allow:  /list
Disallow:  /

User-agent:  Bingbot
Allow:  /article
Allow:  /oshtml
Allow:  /product
Allow:  /spu
Allow:  /dianpu
Allow:  /oversea
Allow:  /list
Disallow:  /

User-Agent:  360Spider
Allow:  /article
Allow:  /oshtml
Disallow:  /

User-Agent:  Yisouspider
Allow:  /article
Allow:  /oshtml
Disallow:  /

User-Agent:  Sogouspider
Allow:  /article
Allow:  /oshtml
Allow:  /product
Disallow:  /

User-Agent:  Yahoo!  Slurp
Allow:  /product
Allow:  /spu
Allow:  /dianpu
Allow:  /oversea
Allow:  /list
Disallow:  /

User-Agent:  *
Disallow:  /
</code></pre>
  </li>
</ol>

<p>SEO , SEM 排名: 通过 pagerank 排名 和 付费排名</p>

<h4 id="二-专项爬虫-根据自己的需求-实现爬虫程序-抓取需要的数据">二, <strong>专项爬虫</strong>: 根据自己的需求, 实现爬虫程序, 抓取需要的数据</h4>

<p><strong>网页特征</strong>: 1. http, https , 2. html 内容, 3. 有独立的url 地址</p>

<p><strong>爬取步骤</strong>: 确定html -&gt; 模拟浏览器访问URL, 获取网页的html 内容 -&gt; 解析html 字符串, 按规则获取数据</p>

<h3 id="请求头信息">请求头信息:</h3>

<ul>
  <li>accept:text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,<em>/</em>;q=0.8  可接受的请求类型</li>
  <li>request url: https://www.baidu.com/ 请求地址</li>
  <li>request method: Get/ Post</li>
  <li>status code:200 ok , 服务端响应码</li>
  <li>remote address: 服务器IP地址+端口号</li>
  <li>referer: 前一个页面地址</li>
  <li>accept-encoding: gzip 内容压缩方式, 浏览器会自动解压缩, 我们爬虫不需要设置这个</li>
  <li>accept-language: 可接受的请求语言</li>
  <li>cookie: BAIDU 可接受的cookie 信息(用户不敏感信息, 用户名, session id 等)</li>
</ul>

<h3 id="响应头信息">响应头信息:</h3>

<ul>
  <li>connection: keep-alive  连接方式长连接</li>
  <li>content-encoding: gzip 内容压缩方式, 浏览器会自动解压缩, 我们爬虫不需要设置这个</li>
  <li>content-type:  text/html;charset=utf-8  响应文件内容类型,  可以是 json , 可以是 html, xml</li>
  <li>date: 服务器日期</li>
  <li>server: 服务器版本</li>
  <li>set-cookie: 设置cookie值</li>
</ul>

<h3 id="使用工具---fiddler">使用工具 - fiddler</h3>

<ul>
  <li>安装方法: http://www.cocoachina.com/apple/20170704/19729.html
    <ul>
      <li>运行命令: <code class="language-plaintext highlighter-rouge">sudo mono --arch=32 /Applications/fiddler-mac/Fiddler.exe</code></li>
    </ul>
  </li>
  <li>Fiddler
    <ul>
      <li><strong>右侧 inspectors 按钮:</strong> 查看主要请求和响应的信息内容. 如果内容未解码, 点击黄色长条按钮就可以解码</li>
      <li><strong>右侧 Statistics 面板</strong>: 查看统计信息</li>
    </ul>
  </li>
</ul>

<h2 id="urllib-库">Urllib 库</h2>

<p>是python 提供的 网页获取库</p>

<p>urllib.request 负责请求数据:</p>

<blockquote>
  <p>read()  读取全部信息. b’….’ 表示为二进制信息</p>

  <p>readline()   按行读取, 返回一个列表</p>

  <p>getcode() 获取状态码</p>

  <p>geturl()  获取url</p>

  <p>getheaders() 获取头信息</p>
</blockquote>

<p>urllib.parse 用于处理获取的数据</p>

<h4 id="读取url-urllibrequesturlopen-respread-respgeturl-respgetcode-respgetheaders">读取URL <code class="language-plaintext highlighter-rouge">urllib.request.urlopen(), resp.read(), resp.geturl(), resp.getcode(), resp.getheaders()</code></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17</pre></td><td class="code"><pre><span class="kn">import</span> <span class="nn">urllib.request</span>
<span class="kn">import</span> <span class="nn">ssl</span>

<span class="n">ssl</span><span class="o">.</span><span class="n">_create_default_https_context</span> <span class="o">=</span> <span class="n">ssl</span><span class="o">.</span><span class="n">_create_unverified_context</span>


<span class="n">url</span><span class="o">=</span><span class="s">'https://www.baidu.com'</span>

<span class="c"># 尽量保证运行代码时不要开启fiddler</span>
<span class="n">resp</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">resp</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">getcode</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">geturl</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">getheaders</span><span class="p">())</span>
<span class="c"># print(resp.read())                # 读取全部信息. b'....' 表示为二进制信息</span>
<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>  <span class="c"># 解码utf-8</span>
</pre></td></tr></tbody></table>
</div>
</div>

<h4 id="保存读取内容到文件-urllibrequesturlretrieve">保存读取内容到文件 <code class="language-plaintext highlighter-rouge">urllib.request.urlretrieve()</code></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre><span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s">'baidu.com'</span><span class="p">)</span>
</pre></td></tr></tbody></table>
</div>
</div>

<h4 id="url-中汉字参数的处理--urllibparseurlencode">URL 中汉字参数的处理  <code class="language-plaintext highlighter-rouge">urllib.parse.urlencode()</code></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14</pre></td><td class="code"><pre><span class="c"># 汉字不能作为URL 内容, 必须先进行编码和解码</span>
<span class="c"># http://tool.chinaz.com/Tools/urlencode.aspx</span>
<span class="n">url2</span> <span class="o">=</span> <span class="s">'https://www.baidu.com/s?'</span>
<span class="n">source</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'wd'</span><span class="p">:</span><span class="s">'美女'</span>
<span class="p">}</span>
<span class="n">url3</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">parse</span><span class="o">.</span><span class="n">urlencode</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>

<span class="n">url</span>  <span class="o">=</span> <span class="n">url2</span><span class="o">+</span><span class="n">url3</span>

<span class="n">resp</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">getcode</span><span class="p">())</span>
</pre></td></tr></tbody></table>
</div>
</div>

<h4 id="模拟浏览器请求--urllibrequestrequest">模拟浏览器请求  <code class="language-plaintext highlighter-rouge">urllib.request.Request()</code></h4>

<p><code class="language-plaintext highlighter-rouge">Request()</code> 可以帮我们定制 请求的 headers</p>

<p>将User-Agent 放到请求中</p>

<p><a href="http://blog.csdn.net/tao_627/article/details/42297443">更多user-agent</a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13</pre></td><td class="code"><pre><span class="c"># 模拟user-agent  http://blog.csdn.net/tao_627/article/details/42297443</span>
<span class="c"># 使用 urllib.open</span>

<span class="c"># safari 浏览器</span>
<span class="c"># Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'User-Agent'</span><span class="p">:</span> <span class="s">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2'</span><span class="p">,</span>

<span class="p">}</span>
<span class="n">req</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span> <span class="o">=</span> <span class="s">'http://www.baidu.com/'</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
<span class="n">resp</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">req</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">getcode</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>
</pre></td></tr></tbody></table>
</div>
</div>

<h4 id="post-请求">POST 请求</h4>

<p>POST 请求需要通过代码方式将参数带入请求中.</p>

<p>案例: 百度翻译  fanyi.baidu.com</p>

<ul>
  <li>第一步: 抓包分析百度翻译, 查看网址有没有跟搜索内容相关的单词显示.</li>
  <li>猜测是GET 还是 POST 请求</li>
  <li>如果是GET,  <code class="language-plaintext highlighter-rouge">青花瓷 Querystring</code> 中会带参数, 如果是POST, <code class="language-plaintext highlighter-rouge">青花瓷 form</code> 可以找到所有参数</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45</pre></td><td class="code"><pre>
<span class="kn">import</span> <span class="nn">urllib.request</span>
<span class="kn">import</span> <span class="nn">urllib.parse</span>
<span class="kn">import</span> <span class="nn">ssl</span>

<span class="n">ssl</span><span class="o">.</span><span class="n">_create_default_https_context</span> <span class="o">=</span> <span class="n">ssl</span><span class="o">.</span><span class="n">_create_unverified_context</span>

<span class="c"># 通过抓包工具解析到URL</span>

<span class="n">post_url</span> <span class="o">=</span> <span class="s">'http://fanyi.baidu.com/sug/'</span>

<span class="c"># 通过抓包工具找到参数</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'kw'</span><span class="p">:</span><span class="s">'baby'</span>
<span class="p">}</span>

<span class="c"># 配置post 参数, 需要把data 进行encode 转换.</span>
<span class="c"># urlencode 先转汉字, encode 再转字符</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">parse</span><span class="o">.</span><span class="n">urlencode</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">)</span>

<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'User-Agent'</span><span class="p">:</span> <span class="s">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2'</span><span class="p">,</span>

<span class="p">}</span>

<span class="n">req</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">post_url</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>


<span class="n">resp</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">req</span><span class="p">)</span>
<span class="c"># print(resp.getcode())</span>
<span class="c"># print(resp.read().decode('utf-8'))</span>

<span class="c"># 最后将结果放在网页的json 读取器里面就可以正常显示返回的中文内容了</span>

<span class="c"># 转换成 JSON</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="n">json_obj</span><span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>

<span class="n">answer</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">json_obj</span><span class="p">,</span><span class="n">ensure_ascii</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'fanyi.json'</span><span class="p">,</span><span class="s">'w'</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
    <span class="n">fp</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">answer</span><span class="p">)</span>

</pre></td></tr></tbody></table>
</div>
</div>

<h4 id="ajax-请求">AJAX 请求</h4>

<p>案例: <a href="https://movie.douban.com/j/chart/top_list?type=5&amp;interval_id=100%3A90&amp;action=&amp;start=0&amp;limit=1">豆瓣电影排行榜</a> GET</p>

<p>需求: 由用户指定页码, 进行抓取豆瓣电影动作排行榜的电影信息.</p>

<p>步骤: 抓包工具分析请求页面的AJAX 请求 信息 和响应信息</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40</pre></td><td class="code"><pre><span class="c"># 豆瓣电影分析</span>

<span class="kn">import</span> <span class="nn">urllib.request</span>
<span class="kn">import</span> <span class="nn">urllib.parse</span>
<span class="kn">import</span> <span class="nn">ssl</span>

<span class="n">ssl</span><span class="o">.</span><span class="n">_create_default_https_context</span> <span class="o">=</span> <span class="n">ssl</span><span class="o">.</span><span class="n">_create_unverified_context</span>

<span class="n">url1</span> <span class="o">=</span> <span class="s">'https://movie.douban.com/j/chart/top_list?type=5&amp;interval_id=100</span><span class="si">%3</span><span class="s">A90&amp;action=&amp;start=0&amp;limit=1'</span>
<span class="n">url2</span> <span class="o">=</span> <span class="s">'https://movie.douban.com/j/chart/top_list?type=5&amp;interval_id=100</span><span class="si">%3</span><span class="s">A90&amp;action=&amp;start=0&amp;limit=20'</span>

<span class="n">base_url</span> <span class="o">=</span> <span class="s">'https://movie.douban.com/j/chart/top_list?type=5&amp;interval_id=100</span><span class="si">%3</span><span class="s">A90&amp;action=&amp;limit=20&amp;'</span>


<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">start_page</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">input</span><span class="p">(</span><span class="s">'请输入要查看的页码'</span><span class="p">))</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">'start'</span><span class="p">:(</span><span class="n">start_page</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="mi">20</span>
    <span class="p">}</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">parse</span><span class="o">.</span><span class="n">urlencode</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">url</span> <span class="o">=</span> <span class="n">base_url</span><span class="o">+</span><span class="n">data</span>
    <span class="n">download_message</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">download_message</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>


    <span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">'User-Agent'</span><span class="p">:</span> <span class="s">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2'</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">req</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
    <span class="n">resp</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">req</span><span class="p">)</span>
    <span class="n">content</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'douban.json'</span><span class="p">,</span><span class="s">'w'</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
        <span class="n">fp</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>



<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">'__main__'</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></td></tr></tbody></table>
</div>
</div>

<p>案例: <a href="http://www.kfc.com.cn/kfccda/storelist/index.aspx">肯德基餐厅查询</a> POST</p>

<p>需求: 分析点击页码后的ajax 请求 , 查看 抓包工具的 X-Requested-With: XMLHttpRequest</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31</pre></td><td class="code"><pre><span class="c"># 肯德基餐厅分析</span>

<span class="kn">import</span> <span class="nn">urllib.request</span>
<span class="kn">import</span> <span class="nn">urllib.parse</span>
<span class="kn">import</span> <span class="nn">ssl</span>

<span class="n">ssl</span><span class="o">.</span><span class="n">_create_default_https_context</span> <span class="o">=</span> <span class="n">ssl</span><span class="o">.</span><span class="n">_create_unverified_context</span>


<span class="n">post_url</span> <span class="o">=</span> <span class="s">'http://www.kfc.com.cn/kfccda/ashx/GetStoreList.ashx?op=cname'</span>

<span class="n">page</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'cname'</span><span class="p">:</span><span class="s">'上海'</span><span class="p">,</span>
    <span class="s">'pageIndex'</span><span class="p">:</span>	<span class="s">'4'</span><span class="p">,</span>
    <span class="s">'pageSize'</span><span class="p">:</span>	<span class="s">'10'</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">parse</span><span class="o">.</span><span class="n">urlencode</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">)</span>

<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'User-Agent'</span><span class="p">:</span> <span class="s">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2'</span><span class="p">,</span>

<span class="p">}</span>

<span class="n">req</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">post_url</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>

<span class="n">resp</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">req</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">getcode</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>
</pre></td></tr></tbody></table>
</div>
</div>

<p>案例: 由用户录入贴吧的名字, 并输入起始页和结束页, 将获取到的信息保存到文件中, 每页为一个html 文件.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32</pre></td><td class="code"><pre><span class="c"># 获取百度贴吧信息 -- 科幻电影吧</span>
<span class="c"># 由用户录入贴吧的名字, 并输入起始页和结束页, 将获取到的信息保存到文件中, 每页为一个html 文件.</span>

<span class="kn">import</span> <span class="nn">urllib.request</span>
<span class="kn">import</span> <span class="nn">urllib.parse</span>
<span class="kn">import</span> <span class="nn">ssl</span>

<span class="n">ssl</span><span class="o">.</span><span class="n">_create_default_https_context</span> <span class="o">=</span> <span class="n">ssl</span><span class="o">.</span><span class="n">_create_unverified_context</span>


<span class="k">def</span> <span class="nf">download_message</span><span class="p">(</span><span class="n">url</span><span class="p">,</span><span class="n">pn</span><span class="p">):</span>
    <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">pn</span><span class="p">)</span><span class="o">+</span><span class="s">'tieba.html'</span><span class="p">)</span>



<span class="n">bar_name</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s">'请输入贴吧名称: '</span><span class="p">)</span>
<span class="n">page_start</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s">'请输入起始页码:'</span><span class="p">)</span>
<span class="n">page_end</span>   <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s">'请输入结束页码:'</span><span class="p">)</span>
<span class="n">pns</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">page_end</span><span class="p">)</span><span class="o">-</span><span class="nb">int</span><span class="p">(</span><span class="n">page_start</span><span class="p">)):</span>
    <span class="n">pns</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="n">page_start</span><span class="p">)</span><span class="o">+</span><span class="n">i</span><span class="p">)</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
<span class="n">post_url</span> <span class="o">=</span> <span class="s">'http://tieba.baidu.com/f?&amp;ie=utf-8&amp;'</span>

<span class="k">for</span> <span class="n">pn</span> <span class="ow">in</span> <span class="n">pns</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">'pn'</span><span class="p">:</span><span class="n">pn</span><span class="p">,</span>
        <span class="s">'kw'</span><span class="p">:</span><span class="n">bar_name</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">parse</span><span class="o">.</span><span class="n">urlencode</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">url</span> <span class="o">=</span> <span class="n">post_url</span> <span class="o">+</span> <span class="n">data</span>
    <span class="c"># print(url)</span>
    <span class="n">download_message</span><span class="p">(</span><span class="n">url</span><span class="p">,</span><span class="n">pn</span><span class="p">)</span>
</pre></td></tr></tbody></table>
</div>
</div>

<h4 id="urlerror--httperror">URLError / HTTPError</h4>

<p>处理网页爬取过程中的异常情况</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26</pre></td><td class="code"><pre><span class="c"># HTTP 异常处理</span>

<span class="kn">import</span> <span class="nn">urllib.request</span>
<span class="kn">import</span> <span class="nn">urllib.error</span> <span class="kn">as</span> <span class="nn">error</span>


<span class="n">url</span> <span class="o">=</span> <span class="s">'http://sh.meituan.com/meishi123/'</span>

<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'User-Agent'</span><span class="p">:</span> <span class="s">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2'</span><span class="p">,</span>

<span class="p">}</span>

<span class="n">req</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">resp</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">req</span><span class="p">)</span>
<span class="k">except</span> <span class="n">error</span><span class="o">.</span><span class="n">HTTPError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
<span class="k">except</span> <span class="n">error</span><span class="o">.</span><span class="n">URLError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
<span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</pre></td></tr></tbody></table>
</div>
</div>

<h4 id="cookie-处理">Cookie 处理</h4>

<p>模拟网站对于一些数据在浏览器的存储操作</p>

<p>比如网站登录后, 会通过cookie 记住用户登录状态.</p>

<p>爬虫可以制造cookie 模仿登录状态.</p>

<p>handler</p>

<ul>
  <li>HTTPHandler</li>
  <li>CookieHandler – 定制cookie</li>
  <li>ProxyHandler  – 定制代理</li>
</ul>

<p>使用 handler 访问数据</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30</pre></td><td class="code"><pre><span class="c"># Cookie 处理</span>

<span class="kn">import</span> <span class="nn">urllib.request</span>
<span class="kn">import</span> <span class="nn">urllib.parse</span>

<span class="kn">import</span> <span class="nn">ssl</span>

<span class="n">ssl</span><span class="o">.</span><span class="n">_create_default_https_context</span> <span class="o">=</span> <span class="n">ssl</span><span class="o">.</span><span class="n">_create_unverified_context</span>


<span class="n">url</span> <span class="o">=</span> <span class="s">'https://www.baidu.com'</span>


<span class="c"># 创建 handler 对象</span>
<span class="n">handler</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">HTTPHandler</span><span class="p">()</span>

<span class="c"># 构建 opener 对象 , 可以取代 urllib.request.urlopen()</span>
<span class="n">openner</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">build_opener</span><span class="p">(</span><span class="n">handler</span><span class="p">)</span>

<span class="c"># 定制请求对象</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
<span class="s">'User-Agent'</span><span class="p">:</span> <span class="s">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2'</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">req</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>


<span class="c"># 使用 opener 发送请求</span>
<span class="n">resp</span> <span class="o">=</span> <span class="n">openner</span><span class="o">.</span><span class="nb">open</span><span class="p">(</span><span class="n">req</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>
</pre></td></tr></tbody></table>
</div>
</div>

<p>定制 cookie对象</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35</pre></td><td class="code"><pre><span class="c"># Cookie 处理</span>

<span class="kn">import</span> <span class="nn">urllib.request</span>
<span class="kn">import</span> <span class="nn">urllib.parse</span>
<span class="kn">import</span> <span class="nn">http.cookiejar</span>
<span class="kn">import</span> <span class="nn">ssl</span>

<span class="n">ssl</span><span class="o">.</span><span class="n">_create_default_https_context</span> <span class="o">=</span> <span class="n">ssl</span><span class="o">.</span><span class="n">_create_unverified_context</span>

<span class="c"># 构建cookie对象, 这个对象可以帮助我们保存服务器想浏览器cookie 写入的所有信息</span>
<span class="n">cookie</span> <span class="o">=</span> <span class="n">http</span><span class="o">.</span><span class="n">cookiejar</span><span class="o">.</span><span class="n">CookieJar</span><span class="p">()</span>
<span class="c"># 使用cookie对象来构建 handler对象</span>
<span class="n">handler</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">HTTPCookieProcessor</span><span class="p">(</span><span class="n">cookie</span><span class="p">)</span>
<span class="c"># 使用 handler 构建 opener 对象</span>
<span class="n">opener</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">build_opener</span><span class="p">(</span><span class="n">handler</span><span class="p">)</span>
<span class="c"># 定制请求对象</span>
<span class="n">post_url</span> <span class="o">=</span> <span class="s">'http://www.renren.com/ajaxLogin/1=1&amp;uniqueTimestamp=2018221554272'</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>

<span class="p">}</span>

<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'User-Agent'</span><span class="p">:</span> <span class="s">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2'</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">req</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">post_url</span><span class="p">,</span><span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
<span class="n">resp</span> <span class="o">=</span> <span class="n">opener</span><span class="o">.</span><span class="nb">open</span><span class="p">(</span><span class="n">req</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'登录成功'</span><span class="p">)</span>

<span class="n">get_url</span> <span class="o">=</span> <span class="s">'http://www.renren.com/224549540/profile'</span>
<span class="n">req1</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">get_url</span><span class="p">,</span><span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
<span class="n">resp1</span> <span class="o">=</span> <span class="n">opener</span><span class="o">.</span><span class="nb">open</span><span class="p">(</span><span class="n">req1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">resp1</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>

</pre></td></tr></tbody></table>
</div>
</div>

<h4 id="代理服务器">代理服务器</h4>

<p>概念: 通过代理去爬取数据, 伪装自己的IP.</p>

<p>代理常用功能:</p>

<ul>
  <li>突破自身IP瓶颈, 访问外国站点</li>
  <li>访问一些单位或团体内部资源</li>
  <li>提高访问速度</li>
  <li>隐藏真实IP</li>
</ul>

<p>配置方法:</p>

<ul>
  <li>本地浏览器配置代理</li>
  <li>代码配置代理</li>
</ul>

<p>国内主要免费的代理: <a href="http://www.xicidaili.com">西次代理</a></p>

<p>主要的两种匿名代理:</p>

<ul>
  <li>透明代理 – 告诉服务器我是代理, 但是不告诉你我的真实IP</li>
  <li>高匿代理 – 带个面具, 不告诉你我是代理, 也让你不知道我的真实IP.</li>
</ul>

<p>查看自己IP的方法: <em>百度中搜索 IP</em></p>

<h4 id="mac-设置代理的方法"><a href="http://www.beihaiting.com/a/SJC/PG/20141122/5726.html">Mac 设置代理的方法</a></h4>

<p>设置后, 在百度搜索IP 查看地址是否变化, 变了代理就成功了.</p>

<h4 id="用代码配置爬虫代理">用代码配置爬虫代理</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26</pre></td><td class="code"><pre><span class="c"># 为爬虫设置代理</span>


<span class="kn">import</span> <span class="nn">urllib.request</span> <span class="kn">as</span> <span class="nn">request</span>
<span class="kn">import</span> <span class="nn">urllib.parse</span> <span class="kn">as</span> <span class="nn">parse</span>
<span class="kn">import</span> <span class="nn">ssl</span>

<span class="n">ssl</span><span class="o">.</span><span class="n">_create_default_https_context</span> <span class="o">=</span> <span class="n">ssl</span><span class="o">.</span><span class="n">_create_unverified_context</span>

<span class="c"># 构建代理ProxyHandler, 该对象帮我们使用代理来访问服务器</span>
<span class="n">handler</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">ProxyHandler</span><span class="p">(</span><span class="n">proxies</span><span class="o">=</span><span class="p">{</span><span class="s">'http'</span><span class="p">:</span><span class="s">'27.197.109.149:8118'</span><span class="p">})</span>
<span class="n">openner</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">build_opener</span><span class="p">(</span><span class="n">handler</span><span class="p">)</span>

<span class="n">url</span> <span class="o">=</span> <span class="s">'https://www.baidu.com/s?wd=ip'</span>

<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'User-Agent'</span><span class="p">:</span> <span class="s">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2'</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">req</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>

<span class="n">resp</span> <span class="o">=</span> <span class="n">openner</span><span class="o">.</span><span class="nb">open</span><span class="p">(</span><span class="n">req</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>

<span class="c"># 结果可以看到代理</span>
</pre></td></tr></tbody></table>
</div>
</div>

<h2 id="用正则表达式爬取数据">用正则表达式爬取数据</h2>

<p>案例: 糗事百科图片抓取</p>

<p>步骤</p>

<ol>
  <li>
    <p>先在网页中拿几张图片的html 标签, 比较查看一下规律</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>&lt;img src="//pic.qiushibaike.com/system/pictures/12011/120116488/medium/app120116488.jpg" alt="糗事#120116488" class="illustration" width="100%" height="auto"&gt;
</pre></td></tr></tbody></table>
</div>
    </div>

    <p>​</p>
  </li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42</pre></td><td class="code"><pre>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">urllib.request</span>
<span class="kn">import</span> <span class="nn">urllib.parse</span>
<span class="kn">import</span> <span class="nn">ssl</span>

<span class="n">ssl</span><span class="o">.</span><span class="n">_create_default_https_context</span> <span class="o">=</span> <span class="n">ssl</span><span class="o">.</span><span class="n">_create_unverified_context</span>

<span class="nb">str</span> <span class="o">=</span> <span class="s">'''
&lt;div class="thumb"&gt;

&lt;a href="/article/120116488" target="_blank"&gt;
&lt;img src="//pic.qiushibaike.com/system/pictures/12011/120116488/medium/app120116488.jpg" alt="糗事#120116488" class="illustration" width="100</span><span class="si">%</span><span class="s">" height="auto"&gt;
&lt;/a&gt;
&lt;/div&gt;
'''</span>

<span class="n">url</span> <span class="o">=</span> <span class="s">'https://www.qiushibaike.com/'</span>

<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'User-Agent'</span><span class="p">:</span> <span class="s">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2'</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">req</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>

<span class="n">resp</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">req</span><span class="p">)</span>

<span class="n">pt</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="nb">compile</span><span class="p">(</span><span class="s">r'&lt;div class="thumb"&gt;.*?&lt;img src="(.*?)" alt=.*?&lt;/div&gt;'</span><span class="p">,</span><span class="n">re</span><span class="o">.</span><span class="n">S</span><span class="p">)</span>

<span class="n">src_list</span> <span class="o">=</span> <span class="n">pt</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">src_list</span><span class="p">)</span>

<span class="c"># 下载图片到本地目录中</span>
<span class="k">print</span><span class="p">(</span><span class="s">'开始下载图片...'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">src</span> <span class="ow">in</span> <span class="n">src_list</span><span class="p">:</span>
    <span class="n">url</span> <span class="o">=</span> <span class="s">'http:'</span><span class="o">+</span><span class="n">src</span>
    <span class="n">img_name</span> <span class="o">=</span> <span class="n">src</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">'/'</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">file_path</span><span class="o">=</span> <span class="s">'qiubai/'</span> <span class="o">+</span> <span class="n">img_name</span>
    <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">file_path</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">img_name</span><span class="o">+</span><span class="s">'下载完成'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'全部图片下载完成'</span><span class="p">)</span>

</pre></td></tr></tbody></table>
</div>
</div>

<h2 id="xpath">XPath</h2>

<p><a href="http://www.w3school.com.cn/xpath/index.asp">w3scholl文档</a></p>

<p>html 是一种特殊的XML</p>

<p>XPath 用 xml 的方式获取 html 中的内容路径, 并抓取到需要的数据.</p>

<ul>
  <li>节点 node : xml 中的一个标签的整段内容, 可能包含父节点,子节点, 同胞节点等</li>
  <li>属性 :</li>
  <li>文本:</li>
</ul>

<p><strong>XPath 基本语法</strong></p>

<table>
  <thead>
    <tr>
      <th>表达式</th>
      <th>描述</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>bookstore</td>
      <td>查找此节点的所有子节点.</td>
    </tr>
    <tr>
      <td>/bookstore</td>
      <td>查找根节点节点是bookstore的标签直接子节点</td>
    </tr>
    <tr>
      <td>//bookstore</td>
      <td>查找所有是 bookstore 的标签</td>
    </tr>
    <tr>
      <td>//@lang</td>
      <td>查找所有包含 lang 的属性的值</td>
    </tr>
    <tr>
      <td>//title[@lang]</td>
      <td>查找包含lang 属性的 title 节点</td>
    </tr>
    <tr>
      <td>//title[@lang=’en’]</td>
      <td>查找包含lang 属性, 且属性值是 en 的 title 节点</td>
    </tr>
    <tr>
      <td>/bookstore/book[‘price&gt;35.00’]</td>
      <td>在bookstore元素的直接子节点中查找price大于35的所有 book 元素,</td>
    </tr>
    <tr>
      <td>//book/title | //book/price</td>
      <td>查找所有book下面的title 和 price 直接子标签</td>
    </tr>
    <tr>
      <td>//title | //price</td>
      <td>查找所有title 和 price 节点.</td>
    </tr>
    <tr>
      <td>//div[@id=’head’ and @class=’s_down’]</td>
      <td>查找所有 id=head, 并且 class=s_down 的所有 div 节点</td>
    </tr>
    <tr>
      <td>//div[contains(@id, ‘he’)]</td>
      <td>查找属性包含 he 的所有 div 标签</td>
    </tr>
    <tr>
      <td>//div[starts-with(@id,’he’)]</td>
      <td>查找属性以 he 开头的所有 div 标签</td>
    </tr>
    <tr>
      <td>//div[ends-with(@id,’he’)]</td>
      <td>查找属性以 he 结尾的所有 div 标签</td>
    </tr>
    <tr>
      <td>//div/h1/text()</td>
      <td>查找所有div下直接子节点是 h1 的内容.</td>
    </tr>
  </tbody>
</table>

<p><strong>Xpath 扩展工具的安装和使用:</strong></p>

<ol>
  <li>去 chrome store 下载 <code class="language-plaintext highlighter-rouge">xpath.crx</code> 文件, 并安装到谷歌浏览器中</li>
  <li>control + shift +x 快捷键 打开xparth 插件</li>
  <li>按住shift 键 + 移动鼠标, 就可以查看网页元素的xpath 了</li>
  <li>可以在插件的 query 输入框中编辑自动生成的xpath语句</li>
</ol>

<p><strong>安装 lxml 库:</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>pip3.6 install lxml
</pre></td></tr></tbody></table>
</div>
</div>

<p><strong>etree.parse() 和 etree.HTML()</strong></p>

<p>可以让我们对网页转成 xpath 树状数据, 让我们可以通过 xpath 语法进行解析</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2</pre></td><td class="code"><pre><span class="n">etree</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s">'xx.html'</span><span class="p">)</span>
<span class="n">etree</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>
</pre></td></tr></tbody></table>
</div>
</div>

<p>案例一: 爬取本地古诗html</p>

<p>test.html</p>

<div class="language-html highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30</pre></td><td class="code"><pre><span class="cp">&lt;!DOCTYPE html&gt;</span>
<span class="nt">&lt;html</span> <span class="na">lang=</span><span class="s">"en"</span><span class="nt">&gt;</span>
<span class="nt">&lt;head&gt;</span>
	<span class="nt">&lt;title&gt;</span>Document<span class="nt">&lt;/title&gt;</span>
<span class="nt">&lt;/head&gt;</span>
<span class="nt">&lt;body&gt;</span>
	<span class="nt">&lt;h1&gt;</span>这是一个无聊至极的网页<span class="nt">&lt;/h1&gt;</span>
	<span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"gushi"</span><span class="nt">&gt;</span>
		<span class="nt">&lt;ul&gt;</span>
			<span class="nt">&lt;li</span> <span class="na">id=</span><span class="s">"first"</span><span class="nt">&gt;</span>桃花坞里桃花庵<span class="nt">&lt;/li&gt;</span>
			<span class="nt">&lt;li</span> <span class="na">class=</span><span class="s">"haha"</span><span class="nt">&gt;</span>桃花庵里桃花仙<span class="nt">&lt;/li&gt;</span>
			<span class="nt">&lt;li</span> <span class="na">class=</span><span class="s">"hehe"</span><span class="nt">&gt;</span>桃花仙人种桃树<span class="nt">&lt;/li&gt;</span>
			<span class="nt">&lt;li</span> <span class="na">class=</span><span class="s">"heihei"</span><span class="nt">&gt;</span>再卖桃花换酒钱<span class="nt">&lt;/li&gt;</span>
		<span class="nt">&lt;/ul&gt;</span>
		<span class="nt">&lt;div</span> <span class="na">id=</span><span class="s">"author"</span> <span class="na">class=</span><span class="s">"tang"</span><span class="nt">&gt;</span>
			<span class="nt">&lt;a</span> <span class="na">href=</span><span class="s">"http://www.baidu.com"</span><span class="nt">&gt;</span>唐伯虎<span class="nt">&lt;/a&gt;</span>
		<span class="nt">&lt;/div&gt;</span>
	<span class="nt">&lt;/div&gt;</span>
	<span class="nt">&lt;ol&gt;</span>
		<span class="nt">&lt;li</span> <span class="na">class=</span><span class="s">"go"</span><span class="nt">&gt;</span>世间只有你最好<span class="nt">&lt;/li&gt;</span>
		<span class="nt">&lt;li</span> <span class="na">class=</span><span class="s">"love"</span><span class="nt">&gt;</span>有一种喜欢叫那个下午阳光很好，而你正好穿了一件白衬衫<span class="nt">&lt;/li&gt;</span>
		<span class="nt">&lt;li</span> <span class="na">class=</span><span class="s">"cray"</span><span class="nt">&gt;</span>45°也无法抹去我心中的创伤<span class="nt">&lt;/li&gt;</span>
		<span class="nt">&lt;li&gt;</span>夏至殇<span class="nt">&lt;/li&gt;</span>
		<span class="nt">&lt;li</span> <span class="na">class=</span><span class="s">"iii"</span><span class="nt">&gt;</span>天才是百分之百的灵感<span class="nt">&lt;/li&gt;</span>
	<span class="nt">&lt;/ol&gt;</span>
	<span class="nt">&lt;div&gt;</span>
		<span class="nt">&lt;p&gt;</span>这里再没有下文了<span class="nt">&lt;/p&gt;</span>
	<span class="nt">&lt;/div&gt;</span>
<span class="nt">&lt;/body&gt;</span>
<span class="nt">&lt;/html&gt;</span>
</pre></td></tr></tbody></table>
</div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27</pre></td><td class="code"><pre><span class="c"># XPath</span>

<span class="kn">from</span> <span class="nn">lxml</span> <span class="kn">import</span> <span class="n">etree</span>

<span class="c"># 获取本地HTML 文件, 创建一个tree 对象</span>
<span class="c"># 是一个属性结构, 支持使用 xpath 进行路径定位</span>
<span class="n">html_tree</span> <span class="o">=</span> <span class="n">etree</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s">'test.html'</span><span class="p">)</span>

<span class="c"># 返回一个符合路径定位的资源列表, 是一个 list</span>
<span class="c"># 参数就是xpath 路径</span>

<span class="c"># 查找古诗所有语句</span>
<span class="n">gushi1</span> <span class="o">=</span> <span class="n">html_tree</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//div[@class="gushi"]/ul/li/text()'</span><span class="p">)</span>
<span class="c"># 查找语句</span>
<span class="n">gushi2</span> <span class="o">=</span> <span class="n">html_tree</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//div[@class="gushi"]/ul/li[@class="haha"]/text() '</span><span class="p">)</span>
<span class="c"># 查找作者</span>
<span class="n">author</span> <span class="o">=</span> <span class="n">html_tree</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//div[@class="gushi"]/div[@id="author"]/a/text()'</span><span class="p">)</span>
<span class="c"># 查找作者链接</span>
<span class="n">link</span> <span class="o">=</span> <span class="n">html_tree</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//div[@class="gushi"]/div[@id="author"]/a/@href'</span><span class="p">)</span>
<span class="c"># 找所有带有 class 的 li 标签的内容</span>
<span class="n">lis</span> <span class="o">=</span> <span class="n">html_tree</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//li[@class]/text()'</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">gushi1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">gushi2</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">author</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">link</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">lis</span><span class="p">)</span>
</pre></td></tr></tbody></table>
</div>
</div>

<p>案例二: 站长素材图片抓取</p>

<p>需求: 将制定网址的图片下载, 并保存到制定文件夹, 以图片标题名为文件名</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60</pre></td><td class="code"><pre>
<span class="kn">import</span> <span class="nn">urllib.request</span>
<span class="kn">import</span> <span class="nn">urllib.parse</span>
<span class="kn">from</span> <span class="nn">lxml</span> <span class="kn">import</span> <span class="n">etree</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c"># 图片路径</span>
<span class="n">xpath_src</span> <span class="o">=</span> <span class="s">'//div[@id="container"]/div/div/a/img/@src2'</span>
<span class="c"># 标题路径</span>
<span class="n">xpath_alt</span> <span class="o">=</span> <span class="s">'//div[@id="container"]/div/div/a/@alt'</span>

<span class="c"># 请求数据</span>
<span class="n">base_url</span> <span class="o">=</span> <span class="s">'http://sc.chinaz.com/tupian/shuaigetupian'</span>
<span class="c"># http://sc.chinaz.com/tupian/shuaigetupian_2.html</span>



<span class="k">def</span> <span class="nf">conection_with_url</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
	<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
		<span class="s">'User-Agent'</span><span class="p">:</span> <span class="s">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36'</span>
	<span class="p">}</span>
	<span class="n">request</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span><span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
	<span class="n">response</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">request</span><span class="p">)</span>
	<span class="k">return</span> <span class="n">response</span>

<span class="k">def</span> <span class="nf">parse_data</span><span class="p">(</span><span class="n">response</span><span class="p">,</span><span class="n">page</span><span class="p">):</span>
	<span class="n">html_string</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">)</span>
	<span class="c"># 加载为tree对象</span>
	<span class="n">html_tree</span> <span class="o">=</span> <span class="n">etree</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="n">html_string</span><span class="p">)</span>
	<span class="c"># 使用xpath解析</span>
	<span class="n">alt_list</span> <span class="o">=</span> <span class="n">html_tree</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="n">xpath_alt</span><span class="p">)</span>
	<span class="n">src_list</span> <span class="o">=</span> <span class="n">html_tree</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="n">xpath_src</span><span class="p">)</span>
	<span class="k">print</span><span class="p">(</span><span class="s">'开始下载第</span><span class="si">%</span><span class="s">d页'</span><span class="o">%</span><span class="n">page</span><span class="p">)</span>
	<span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">alt_list</span><span class="p">)):</span>
		<span class="n">src</span> <span class="o">=</span> <span class="n">src_list</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
		<span class="n">suffix</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">src</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
		<span class="n">img_name</span> <span class="o">=</span> <span class="n">alt_list</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
		<span class="n">img_path</span> <span class="o">=</span> <span class="s">'shuaige/'</span> <span class="o">+</span> <span class="n">img_name</span> <span class="o">+</span> <span class="n">suffix</span>
		<span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="n">src</span><span class="p">,</span><span class="n">img_path</span><span class="p">)</span>
		<span class="k">print</span><span class="p">(</span><span class="n">img_name</span><span class="o">+</span><span class="s">'下载完成'</span><span class="p">)</span>
	<span class="k">print</span><span class="p">(</span><span class="s">'第</span><span class="si">%</span><span class="s">d页下载完成'</span><span class="o">%</span><span class="n">page</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
	<span class="n">start_page</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">input</span><span class="p">(</span><span class="s">'请输入起始页：'</span><span class="p">))</span>
	<span class="n">end_page</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">input</span><span class="p">(</span><span class="s">'请输入结束页：'</span><span class="p">))</span>

	<span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_page</span><span class="p">,</span><span class="n">end_page</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
		<span class="k">if</span> <span class="n">page</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
			<span class="n">url</span> <span class="o">=</span> <span class="n">base_url</span> <span class="o">+</span> <span class="s">'.html'</span>
		<span class="k">else</span><span class="p">:</span>
			<span class="n">url</span> <span class="o">=</span> <span class="n">base_url</span> <span class="o">+</span> <span class="s">'_'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">page</span><span class="p">)</span> <span class="o">+</span> <span class="s">'.html'</span>
		<span class="c"># 请求数据</span>
		<span class="n">response</span> <span class="o">=</span> <span class="n">conection_with_url</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
		<span class="c"># 解析并保存数据</span>
		<span class="n">parse_data</span><span class="p">(</span><span class="n">response</span><span class="p">,</span><span class="n">page</span><span class="p">)</span>
	<span class="k">print</span><span class="p">(</span><span class="s">'全部下载结束'</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">'__main__'</span><span class="p">:</span>
	<span class="n">main</span><span class="p">()</span>

</pre></td></tr></tbody></table>
</div>
</div>

<p>案例三: 内涵段子用户头像抓取</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34</pre></td><td class="code"><pre>
<span class="kn">import</span> <span class="nn">urllib.request</span>
<span class="kn">import</span> <span class="nn">urllib.parse</span>
<span class="kn">from</span> <span class="nn">lxml</span> <span class="kn">import</span> <span class="n">etree</span>

<span class="n">src_xpath</span> <span class="o">=</span> <span class="s">'//div[@class="content"]/ul[@id="detail-list"]/li/div/div/a/img/@data-src'</span>
<span class="n">name_xpath</span> <span class="o">=</span> <span class="s">'//div[@class="content"]/ul[@id="detail-list"]/li/div/div/a/div/span[@class="name"]/text()'</span>


<span class="n">url</span> <span class="o">=</span> <span class="s">'http://neihanshequ.com/'</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
	<span class="s">'User-Agent'</span><span class="p">:</span> <span class="s">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36'</span>
<span class="p">}</span>
<span class="n">request</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span><span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">request</span><span class="p">)</span>
<span class="n">html_string</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">)</span>

<span class="n">html_tree</span> <span class="o">=</span> <span class="n">etree</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="n">html_string</span><span class="p">)</span>


<span class="n">src_list</span> <span class="o">=</span> <span class="n">html_tree</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="n">src_xpath</span><span class="p">)</span>
<span class="n">name_list</span> <span class="o">=</span> <span class="n">html_tree</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="n">name_xpath</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">src_list</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">name_list</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">src_list</span><span class="p">)):</span>
	<span class="n">url</span> <span class="o">=</span> <span class="n">src_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
	<span class="k">if</span> <span class="n">url</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s">'.jpg'</span><span class="p">)</span> <span class="o">==</span> <span class="bp">False</span><span class="p">:</span>
		<span class="n">file_path</span> <span class="o">=</span> <span class="s">'neihan/'</span> <span class="o">+</span> <span class="n">name_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="s">'.jpg'</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="n">file_path</span> <span class="o">=</span> <span class="s">'neihan/'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="n">name_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="s">'.jpg'</span>
	<span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">,</span><span class="n">file_path</span><span class="p">)</span>


</pre></td></tr></tbody></table>
</div>
</div>

<h2 id="beautiful-soap-爬取网页">Beautiful soap 爬取网页</h2>

<p>需求: 通过制定的职位关键字, 城市, 页码来爬取智联招聘的网站的职位信息, 并将爬取的数据写成json格式保存到文件中.</p>

<p>bs4 是对Xpath 的封装</p>

<p>安装:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>pip3.7 install bs4
</pre></td></tr></tbody></table>
</div>
</div>

<p><strong>常用函数</strong></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">find()</code> 返回一个对象
    <ul>
      <li><code class="language-plaintext highlighter-rouge">find('a')</code> 返回第一个找到的a 标签</li>
      <li><code class="language-plaintext highlighter-rouge">find('a', title='xxx')</code></li>
      <li><code class="language-plaintext highlighter-rouge">find('a', class_='xxx')</code></li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">find_all()</code> 返回一个列表
    <ul>
      <li><code class="language-plaintext highlighter-rouge">find_all('a')</code>  返回所有a 标签</li>
      <li><code class="language-plaintext highlighter-rouge">find_all(['a','span'])</code>  返回所有 a 标签和 span 标签</li>
      <li><code class="language-plaintext highlighter-rouge">find_all('a', limit=2)</code> 返回前两个 a 标签</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">select()</code> 根据选择器得到节点对象  , <strong>推荐</strong></li>
</ul>

<p><strong>常用属性</strong></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">contents</code> 返回子孙节点的列表</li>
  <li><code class="language-plaintext highlighter-rouge">descendants</code> 返回子孙节点的生成器</li>
</ul>

<p><strong>选择器的语法</strong></p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">选择器</th>
      <th style="text-align: left">将匹配</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">soup.select(‘div’)</td>
      <td style="text-align: left">所有名为<code class="language-plaintext highlighter-rouge">&lt;div&gt;</code>的元素</td>
    </tr>
    <tr>
      <td style="text-align: left">soup.select(‘#author’)</td>
      <td style="text-align: left">带有 id 属性为 author 的元素</td>
    </tr>
    <tr>
      <td style="text-align: left">soup.select(‘.notice’)</td>
      <td style="text-align: left">所有使用 CSS class 属性名为 notice 的元素</td>
    </tr>
    <tr>
      <td style="text-align: left">soup.select(‘div span’)</td>
      <td style="text-align: left">所有在<code class="language-plaintext highlighter-rouge">&lt;div&gt;</code>元素之内的<code class="language-plaintext highlighter-rouge">&lt;span&gt;</code>元素</td>
    </tr>
    <tr>
      <td style="text-align: left">soup.select(‘div &gt; span’)</td>
      <td style="text-align: left">所有直接在<code class="language-plaintext highlighter-rouge">&lt;div&gt;</code>元素之内的<code class="language-plaintext highlighter-rouge">&lt;span&gt;</code>元素，中间没有其他元素</td>
    </tr>
    <tr>
      <td style="text-align: left">soup.select(‘input[name]’)</td>
      <td style="text-align: left">所有名为<code class="language-plaintext highlighter-rouge">&lt;input&gt;</code>，并有一个 name 属性，其值无所谓的元素</td>
    </tr>
    <tr>
      <td style="text-align: left">soup.select(‘input[type=”button”]’)</td>
      <td style="text-align: left">所有名为<code class="language-plaintext highlighter-rouge">&lt;input&gt;</code>，并有一个 type 属性，其值为 button 的元素</td>
    </tr>
  </tbody>
</table>

<p>案例一:</p>

<div class="language-html highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32</pre></td><td class="code"><pre><span class="cp">&lt;!DOCTYPE html&gt;</span>
<span class="nt">&lt;html</span> <span class="na">lang=</span><span class="s">"en"</span><span class="nt">&gt;</span>
<span class="nt">&lt;head&gt;</span>
	<span class="nt">&lt;title&gt;</span>bs4 测试文档<span class="nt">&lt;/title&gt;</span>
<span class="nt">&lt;/head&gt;</span>
<span class="nt">&lt;body&gt;</span>
	<span class="nt">&lt;div&gt;</span>
		<span class="nt">&lt;h1&gt;</span>金庸武侠杀人技能鉴赏<span class="nt">&lt;/h1&gt;</span>
		<span class="nt">&lt;div</span> <span class="na">class=</span><span class="s">"content"</span><span class="nt">&gt;</span>
			<span class="nt">&lt;ul</span> <span class="na">id=</span><span class="s">"wugongmiji"</span><span class="nt">&gt;</span>
				<span class="nt">&lt;li</span> <span class="na">title=</span><span class="s">"first"</span> <span class="na">class=</span><span class="s">"kuihua"</span><span class="nt">&gt;</span>葵花宝典<span class="nt">&lt;/li&gt;</span>
				<span class="c">&lt;!-- &lt;li name="jianfa" id="bixie"&gt;&lt;!-- 辟邪剑法 --&gt;</span><span class="nt">&lt;/li&gt;</span> --&gt;
				<span class="nt">&lt;li</span> <span class="na">age=</span><span class="s">"29"</span> <span class="na">class=</span><span class="s">"jiuyang"</span><span class="nt">&gt;</span>九阳神功<span class="nt">&lt;/li&gt;</span>
				<span class="nt">&lt;li</span> <span class="na">id=</span><span class="s">"shengong"</span> <span class="na">class=</span><span class="s">"jiuyin"</span><span class="nt">&gt;</span>九阴真经<span class="nt">&lt;/li&gt;</span>
				<span class="nt">&lt;li</span> <span class="na">class=</span><span class="s">"xixing"</span> <span class="na">title=</span><span class="s">"dafa"</span><span class="nt">&gt;</span>吸星大法<span class="nt">&lt;/li&gt;</span>
			<span class="nt">&lt;/ul&gt;</span>
			<span class="nt">&lt;a</span> <span class="na">href=</span><span class="s">"http://www.baidu.com"</span><span class="nt">&gt;</span>百度一下<span class="nt">&lt;/a&gt;</span>
		<span class="nt">&lt;/div&gt;</span>

		<span class="nt">&lt;ul&gt;</span>
			<span class="nt">&lt;p&gt;&lt;b&gt;</span> 你所熟悉的武侠人物 <span class="nt">&lt;/b&gt;&lt;/p&gt;</span>
			<span class="nt">&lt;li&gt;</span>张无忌<span class="nt">&lt;/li&gt;</span>
			<span class="nt">&lt;li&gt;</span>尹志平<span class="nt">&lt;/li&gt;</span>
			<span class="nt">&lt;li&gt;</span>令狐冲<span class="nt">&lt;/li&gt;</span>
			<span class="nt">&lt;li&gt;</span>郭靖<span class="nt">&lt;/li&gt;</span>
			<span class="nt">&lt;li&gt;</span>穆念慈<span class="nt">&lt;/li&gt;</span>
		<span class="nt">&lt;/ul&gt;</span>
		<span class="nt">&lt;a</span> <span class="na">href=</span><span class="s">"http://www.360.com"</span><span class="nt">&gt;&lt;/a&gt;</span>
	<span class="nt">&lt;/div&gt;</span>
	
<span class="nt">&lt;/body&gt;</span>
<span class="nt">&lt;/html&gt;</span>
</pre></td></tr></tbody></table>
</div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78</pre></td><td class="code"><pre><span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">bs4</span>

<span class="c"># 打开本地html文档，加载成BeatifullSoup对象</span>
<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="s">'bstext.html'</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">),</span><span class="s">'lxml'</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">soup</span><span class="p">))</span>

<span class="c"># # 获取单个节点-------------- </span>
<span class="c"># # 只能找到第一个</span>
<span class="c"># print(soup.li)</span>
<span class="c"># # 查找第一个li标签</span>
<span class="c"># print(soup.find('li'))</span>
<span class="c"># # 查找title=dafa的li标签,属性名字不需要单双引号</span>
<span class="c"># print(soup.find('li',title='dafa'))</span>
<span class="c"># # 查找name属性,error，不能查找name属性</span>
<span class="c"># # print(soup.find('li',name='jianfa'))</span>
<span class="c"># # 查找class属性等于jiuyang的li标签，注意class后面有下划线_</span>
<span class="c"># print(soup.find('li',class_='jiuyang'))</span>

<span class="c"># # 获取多个节点--------------</span>
<span class="c"># print(soup.find_all('a'))</span>
<span class="c"># # 注意什么是节点，节点里有什么</span>
<span class="c"># print(soup.find_all('ul'))</span>
<span class="c"># # 查找所有的a和h1标签</span>
<span class="c"># print(soup.find_all(['a','h1']))</span>

<span class="c"># # 如果获取到的标签节点仍然存在子节点，依然可以使用如上方法获取子节点</span>
<span class="c"># ul_node = soup.find('ul')</span>
<span class="c"># print(type(ul_node))</span>
<span class="c"># print(ul_node.find('li'))</span>

<span class="c"># # 限定find_all查找的个数</span>
<span class="c"># print(soup.find_all('li',limit=3))</span>


<span class="c"># # 使用CSS选择器定位节点 -------------</span>
<span class="c"># # 注意：选择器返回的是一个列表对象</span>
<span class="c"># # 使用标签名访问节点</span>
<span class="c"># print(soup.select('h1')[0])</span>
<span class="c"># # 使用class选择节点 . 等价于 class=</span>
<span class="c"># print(soup.select('.jiuyang'))</span>
<span class="c"># # 使用id选择节点 # 等价于 id=</span>
<span class="c"># print(soup.select('#shengong'))</span>
<span class="c"># # 使用属性查找 age=29</span>
<span class="c"># print(soup.select('[age="29"]'))</span>

<span class="c"># # 使用CSS选择器匹配路径</span>
<span class="c"># print(soup.select('.content #wugongmiji .jiuyang'))</span>

<span class="c"># 节点的类型</span>
<span class="c"># bs4.BeautifulSoup 根节点类型</span>
<span class="c"># bs4.element.NavigableString 连接类型</span>
<span class="c"># bs4.element.Tag 节点类型</span>
<span class="c"># bs4.element.Comment 注释类型</span>

<span class="c"># 查找子孙节点</span>
<span class="n">ul_list</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">'div'</span><span class="p">,</span><span class="n">class_</span><span class="o">=</span><span class="s">"content"</span><span class="p">)</span><span class="o">.</span><span class="n">descendants</span>
<span class="k">for</span> <span class="n">ul</span> <span class="ow">in</span> <span class="n">ul_list</span><span class="p">:</span>
	<span class="k">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">ul</span><span class="p">),</span><span class="nb">str</span><span class="p">(</span><span class="n">ul</span><span class="p">))</span>
	<span class="c"># if type(ul) == bs4.element.Tag:</span>
	<span class="c"># 	print(ul)</span>

<span class="c"># # 获取节点内容 -----------------------</span>
<span class="c"># node = soup.select('.content #wugongmiji .jiuyang')[0]</span>
<span class="c"># # 使用string</span>
<span class="c"># print(node.string)</span>
<span class="c"># # 使用get_text()</span>
<span class="c"># print(node.get_text())</span>
<span class="c"># # 使用attrs获取节点所有属性，返回 一个字典对象</span>
<span class="c"># print(node.attrs)</span>

<span class="c"># # 获取节点的单一属性值</span>
<span class="c"># print(node.attrs.get('age'))</span>
<span class="c"># print(node.get('age'))</span>
<span class="c"># print(node['age'])</span>


</pre></td></tr></tbody></table>
</div>
</div>

<p>案例二:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79</pre></td><td class="code"><pre><span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">urllib.request</span> <span class="kn">as</span> <span class="nn">request</span>
<span class="kn">import</span> <span class="nn">urllib.parse</span> <span class="kn">as</span> <span class="nn">parse</span>
<span class="kn">import</span> <span class="nn">json</span>


<span class="k">def</span> <span class="nf">request_data</span><span class="p">(</span><span class="n">location</span><span class="p">,</span> <span class="n">keyword</span><span class="p">,</span> <span class="n">page</span><span class="p">):</span>

    <span class="n">handler</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">HTTPHandler</span><span class="p">()</span>  <span class="c"># 定制handler</span>
    <span class="n">opener</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">build_opener</span><span class="p">(</span><span class="n">handler</span><span class="p">)</span>  <span class="c">#</span>
    <span class="n">url</span> <span class="o">=</span> <span class="s">'http://sou.zhaopin.com/jobs/searchresult.ashx?'</span>
    <span class="c"># url = 'http://sou.zhaopin.com/jobs/searchresult.ashx?jl=%E4%B8%8A%E6%B5%B7&amp;kw=%E7%88%AC%E8%99%AB&amp;p=1'</span>


    <span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">'jl'</span><span class="p">:</span><span class="n">location</span><span class="p">,</span>
        <span class="s">'kw'</span><span class="p">:</span><span class="n">keyword</span><span class="p">,</span>
        <span class="s">'p'</span><span class="p">:</span><span class="n">page</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="n">data</span> <span class="o">=</span> <span class="n">parse</span><span class="o">.</span><span class="n">urlencode</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">url</span> <span class="o">=</span> <span class="n">url</span><span class="o">+</span><span class="n">data</span>
    <span class="k">print</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

    <span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">'User-Agent'</span><span class="p">:</span> <span class="s">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2'</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="n">req</span> <span class="o">=</span> <span class="n">request</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
    <span class="n">resp</span> <span class="o">=</span> <span class="n">opener</span><span class="o">.</span><span class="nb">open</span><span class="p">(</span><span class="n">req</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">resp</span>

<span class="c"># print(resp.read().decode('utf-8'))</span>

<span class="c"># 使用 bs4 加载网页信息</span>

<span class="c"># 解析数据</span>
<span class="k">def</span> <span class="nf">parse_data</span><span class="p">(</span><span class="n">resp</span><span class="p">):</span>

    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">),</span> <span class="s">'lxml'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">soup</span><span class="p">))</span>

    <span class="c"># 在网页中先看源代码, 观察到需要找的职位的div 的 class 名字是 newlist_list</span>
    <span class="n">table_list</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">'.newlist_list &gt; .newlist_list_content table.newlist'</span><span class="p">)</span>
    <span class="c"># print(len(table_list))</span>

    <span class="n">datalist</span><span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">table_list</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>

        <span class="c"># print(type(node))</span>
        <span class="n">zwmc</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">'.zwmc div a'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span>
        <span class="c"># print(zwmc)</span>
        <span class="n">gsmc</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">'.gsmc a'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span>
        <span class="c"># print(gsmc)</span>
        <span class="c"># zwyx = node.find_all('td', class_='zwyx')[0].get_text()</span>
        <span class="n">zwyx</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">'.zwyx'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span>
        <span class="c"># print(zwyx)</span>
        <span class="n">gzdd</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">'.gzdd'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span>
        <span class="c"># print(gzdd)</span>
        <span class="n">dic</span> <span class="o">=</span> <span class="p">{</span><span class="s">'职位名称'</span><span class="p">:</span><span class="n">zwmc</span><span class="p">,</span><span class="s">'公司名称'</span><span class="p">:</span><span class="n">gsmc</span><span class="p">,</span><span class="s">'职位月薪'</span><span class="p">:</span><span class="n">zwyx</span><span class="p">,</span><span class="s">'工作地点'</span><span class="p">:</span><span class="n">gzdd</span><span class="p">}</span>
        <span class="n">datalist</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dic</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">datalist</span>


<span class="c"># 存储数据</span>
<span class="k">def</span> <span class="nf">save_data</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="nb">open</span><span class="p">(</span><span class="s">'text.json'</span><span class="p">,</span><span class="s">'w'</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">),</span><span class="n">ensure_ascii</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">lo</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s">'城市'</span><span class="p">)</span>
    <span class="n">kw</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s">'请输入关键字'</span><span class="p">)</span>
    <span class="n">pn</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s">'请输入页码'</span><span class="p">)</span>
    <span class="n">resp</span> <span class="o">=</span> <span class="n">request_data</span><span class="p">(</span><span class="n">lo</span><span class="p">,</span> <span class="n">kw</span><span class="p">,</span> <span class="n">pn</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">parse_data</span><span class="p">(</span><span class="n">resp</span><span class="p">)</span>
    <span class="n">save_data</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">'__main__'</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></td></tr></tbody></table>
</div>
</div>

<h2 id="selenium-模仿浏览器操作行为">selenium 模仿浏览器操作行为</h2>

<p>模拟浏览器, 可以执行网页中的js, 实现动态加载.</p>

<p>可以做一些代码无法实现的功能</p>

<p>安装方法:</p>

<p>第一步:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>pip3.7 install selenium
</pre></td></tr></tbody></table>
</div>
</div>

<p>第二步: 下载chrome 内核文件 <code class="language-plaintext highlighter-rouge">chromedriver</code></p>

<p>http://blog.csdn.net/huilan_same/article/details/51896672</p>

<p>http://chromedriver.storage.googleapis.com/index.html</p>

<p>第三步: 写代码进行测试:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31</pre></td><td class="code"><pre><span class="c"># Selenium 模拟浏览器行为</span>


<span class="kn">from</span> <span class="nn">selenium</span> <span class="kn">import</span> <span class="n">webdriver</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c"># 谷歌浏览器内核路径(全局路径,)</span>
<span class="c"># 注意, 绝对路径需要用 r''</span>
<span class="n">path</span> <span class="o">=</span> <span class="s">'/Users/dalong/code/python1702/spider/chromedriver'</span>

<span class="c"># 创建浏览器驱动对象</span>
<span class="c"># 传入的参数也需要是谷歌浏览器的驱动</span>
<span class="n">browser</span> <span class="o">=</span> <span class="n">webdriver</span><span class="o">.</span><span class="n">Chrome</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

<span class="n">url</span> <span class="o">=</span> <span class="s">'http://www.baidu.com'</span>
<span class="n">browser</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

<span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

<span class="c"># 查找百度首页的输入框</span>
<span class="n">input_box</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_element_by_id</span><span class="p">(</span><span class="s">'kw'</span><span class="p">)</span>
<span class="c"># 输入关键词</span>
<span class="n">input_box</span><span class="o">.</span><span class="n">send_keys</span><span class="p">(</span><span class="s">'美女'</span><span class="p">)</span>

<span class="c"># 点击按钮</span>
<span class="n">btn</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_element_by_id</span><span class="p">(</span><span class="s">'su'</span><span class="p">)</span>
<span class="n">btn</span><span class="o">.</span><span class="n">click</span><span class="p">()</span>

<span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="c"># 退出</span>
<span class="c"># browser.quit()</span>
</pre></td></tr></tbody></table>
</div>
</div>

<h2 id="phantomjs-配合-selenium-进行无界面浏览器的模拟浏览">phantomJS 配合 selenium 进行无界面浏览器的模拟浏览</h2>

<p>phantomJS 是一个无界面浏览器</p>

<p>支持网页元素查找, js的执行等</p>

<p>由于不进行css, 和 UI 渲染, 所以执行效率更高</p>

<p>phantomJS 已经停止更新了, 新的代替品马上出来.</p>

<p>安装:</p>

<p>http://phantomjs.org/download.html</p>

<p>案例一: 模拟百度输入关键词, 点击按钮后将搜索结果截图</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29</pre></td><td class="code"><pre><span class="kn">from</span> <span class="nn">selenium</span> <span class="kn">import</span> <span class="n">webdriver</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">path</span> <span class="o">=</span> <span class="s">'/Users/dalong/code/python1702/spider/phantomjs'</span>
<span class="n">browser</span> <span class="o">=</span> <span class="n">webdriver</span><span class="o">.</span><span class="n">PhantomJS</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

<span class="n">url</span> <span class="o">=</span> <span class="s">'http://www.baidu.com'</span>

<span class="n">browser</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

<span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="c"># 截图</span>
<span class="n">browser</span><span class="o">.</span><span class="n">save_screenshot</span><span class="p">(</span><span class="s">'baidu.png'</span><span class="p">)</span>

<span class="c"># # 查找百度首页的输入框</span>
<span class="n">input_box</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_element_by_id</span><span class="p">(</span><span class="s">'kw'</span><span class="p">)</span>
<span class="c"># 输入关键词</span>
<span class="n">input_box</span><span class="o">.</span><span class="n">send_keys</span><span class="p">(</span><span class="s">'美女'</span><span class="p">)</span>

<span class="c"># 点击按钮</span>
<span class="n">btn</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_element_by_id</span><span class="p">(</span><span class="s">'su'</span><span class="p">)</span>
<span class="c"># print(btn)</span>
<span class="n">btn</span><span class="o">.</span><span class="n">submit</span><span class="p">()</span>
<span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="c"># # 截图</span>
<span class="n">browser</span><span class="o">.</span><span class="n">save_screenshot</span><span class="p">(</span><span class="s">'girl.png'</span><span class="p">)</span>

<span class="n">browser</span><span class="o">.</span><span class="n">quit</span><span class="p">()</span>
</pre></td></tr></tbody></table>
</div>
</div>

<table>
  <thead>
    <tr>
      <th>Selenium 查找网页元素的方法如下:</th>
      <th>例子:</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>find_element_by_id</td>
      <td> </td>
    </tr>
    <tr>
      <td>find_elements_by_name</td>
      <td> </td>
    </tr>
    <tr>
      <td>find_elements_by_xpath</td>
      <td> </td>
    </tr>
    <tr>
      <td>find_elements_by_tag_name</td>
      <td> </td>
    </tr>
    <tr>
      <td>find_elements_by_class_name</td>
      <td> </td>
    </tr>
    <tr>
      <td>find_elements_by_css_selector</td>
      <td>browser.find_elements_by_css_selector(‘#su’)[0]</td>
    </tr>
    <tr>
      <td>find_elements_by_link_text</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<p>案例二: 将百度首页的源码获取, 并保存在本地</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19</pre></td><td class="code"><pre><span class="kn">from</span> <span class="nn">selenium</span> <span class="kn">import</span> <span class="n">webdriver</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">path</span> <span class="o">=</span> <span class="s">'/Users/dalong/code/python1702/spider/phantomjs'</span>
<span class="n">browser</span> <span class="o">=</span> <span class="n">webdriver</span><span class="o">.</span><span class="n">PhantomJS</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>

<span class="n">url</span> <span class="o">=</span> <span class="s">'http://www.baidu.com'</span>
<span class="n">browser</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

<span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">browser</span><span class="o">.</span><span class="n">save_screenshot</span><span class="p">(</span><span class="s">'bd.png'</span><span class="p">)</span>  <span class="c"># 截图</span>

<span class="c"># page_source 可以拿到网页源代码, 相当于urllib.request.urlopen()</span>
<span class="k">print</span><span class="p">(</span><span class="n">browser</span><span class="o">.</span><span class="n">page_source</span><span class="p">)</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'baidu.html'</span><span class="p">,</span><span class="s">'w'</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
    <span class="n">fp</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">browser</span><span class="o">.</span><span class="n">page_source</span><span class="p">)</span>

<span class="n">browser</span><span class="o">.</span><span class="n">quit</span><span class="p">()</span>
</pre></td></tr></tbody></table>
</div>
</div>

<p>案例三: 模拟ajax自动滚动效果查看今日头条</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25</pre></td><td class="code"><pre><span class="c"># 今日头条 ajax 请求</span>

<span class="kn">from</span> <span class="nn">selenium</span> <span class="kn">import</span> <span class="n">webdriver</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">from</span> <span class="nn">lxml</span> <span class="kn">import</span> <span class="n">etree</span>
<span class="kn">import</span> <span class="nn">ssl</span>

<span class="n">ssl</span><span class="o">.</span><span class="n">_create_default_https_context</span> <span class="o">=</span> <span class="n">ssl</span><span class="o">.</span><span class="n">_create_unverified_context</span>


<span class="n">path</span> <span class="o">=</span> <span class="s">'/Users/dalong/code/python1702/spider/phantomjs'</span>
<span class="n">browser</span> <span class="o">=</span> <span class="n">webdriver</span><span class="o">.</span><span class="n">PhantomJS</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">url</span> <span class="o">=</span> <span class="s">'https://www.toutiao.com/'</span>
<span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">browser</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="n">browser</span><span class="o">.</span><span class="n">save_screenshot</span><span class="p">(</span><span class="s">'jinri1.png'</span><span class="p">)</span>
<span class="c"># 模仿滚动, 再来张截图</span>
<span class="n">js</span> <span class="o">=</span> <span class="s">'document.body.scrollTop=10000'</span> <span class="c"># scrollTop=10000 是往下滚10000个像素点</span>
<span class="n">browser</span><span class="o">.</span><span class="n">execute_script</span><span class="p">(</span><span class="n">js</span><span class="p">)</span>
<span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">browser</span><span class="o">.</span><span class="n">save_screenshot</span><span class="p">(</span><span class="s">'jinri2.png'</span><span class="p">)</span>

<span class="n">browser</span><span class="o">.</span><span class="n">quit</span><span class="p">()</span>

</pre></td></tr></tbody></table>
</div>
</div>

<h2 id="jsonpath">jsonPath</h2>

<p><a href="http://blog.csdn.net/luxideyao/article/details/77802389">更多教程</a></p>

<p>和 xpath 类似的用法</p>

<p>安装: <code class="language-plaintext highlighter-rouge">pip install jsonpath</code></p>

<p>json 对象的转换:</p>

<ul>
  <li>json.loads()</li>
  <li>json.dumps()</li>
  <li>json.load()</li>
  <li>json.dump()</li>
</ul>

<p>todo 代码:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>#
</pre></td></tr></tbody></table>
</div>
</div>

<h2 id="requests-库">requests 库</h2>

<p>requests 可以认为是 urllib.request 的封装, 提供了简洁易用的API</p>

<p>功能更加完善</p>

<p>使用更多的是 requests</p>

<p>安装: pip3.6 install requests</p>

<p><a href="cn.python-requests.org/zh_CN/latest/">官方文档</a></p>

<p>案例一: 通过 requests 获取基本网页信息</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30</pre></td><td class="code"><pre><span class="c"># 使用 requests 模块</span>

<span class="kn">import</span> <span class="nn">requests</span>

<span class="n">url</span> <span class="o">=</span> <span class="s">'https://www.baidu.com'</span>

<span class="c"># 配置请求头信息</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'User-Agent'</span><span class="p">:</span> <span class="s">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2'</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
<span class="c"># 获取编码集</span>
<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">encoding</span><span class="p">)</span>
<span class="c"># 指定编码集</span>
<span class="n">resp</span><span class="o">.</span><span class="n">encoding</span> <span class="o">=</span> <span class="s">'utf-8'</span>
<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">encoding</span><span class="p">)</span>
<span class="c"># 获取源代码结果</span>
<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
<span class="c"># 获取二进制字节类型源代码</span>
<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>

<span class="c"># 获取URL</span>
<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">url</span><span class="p">)</span>

<span class="c"># 获取状态码</span>
<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">status_code</span><span class="p">)</span>

<span class="c"># 获取响应头信息</span>
<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">headers</span><span class="p">)</span>
</pre></td></tr></tbody></table>
</div>
</div>

<p>案例二: GET 方法传递多个参数</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26</pre></td><td class="code"><pre><span class="c"># 使用 requests 模块</span>

<span class="kn">import</span> <span class="nn">requests</span>

<span class="n">url</span> <span class="o">=</span> <span class="s">'https://www.baidu.com/?'</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'wd'</span><span class="p">:</span> <span class="s">'北京'</span>
<span class="p">}</span>

<span class="c"># 配置请求头信息</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'User-Agent'</span><span class="p">:</span> <span class="s">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2'</span><span class="p">,</span>
<span class="p">}</span>


<span class="c"># 注意, requests 中如果要给url增加多个参数, 使用 params</span>
<span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
<span class="c"># 指定编码集</span>
<span class="n">resp</span><span class="o">.</span><span class="n">encoding</span> <span class="o">=</span> <span class="s">'utf-8'</span>
<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
<span class="c"># 获取源代码结果</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'baidu2.html'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
    <span class="n">fp</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>

</pre></td></tr></tbody></table>
</div>
</div>

<p>案例三: requests 模拟 POST 请求</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19</pre></td><td class="code"><pre><span class="c"># 学习 requests 的 POST 请求</span>

<span class="kn">import</span> <span class="nn">requests</span>


<span class="n">url</span> <span class="o">=</span> <span class="s">'https://www.bing.com/ttranslationlookup?&amp;IG=4AF03420760D45238FD255B397E7AFC3&amp;IID=translator.5035.6'</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'text'</span> <span class="p">:</span> <span class="s">'dancer'</span><span class="p">,</span>
    <span class="s">'from'</span><span class="p">:</span> <span class="s">'en'</span><span class="p">,</span>
    <span class="s">'to'</span><span class="p">:</span> <span class="s">'zh-CHS'</span>
<span class="p">}</span>

<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'User-Agent'</span><span class="p">:</span> <span class="s">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2'</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
</pre></td></tr></tbody></table>
</div>
</div>

<p>案例四: requests 使用代理爬取数据</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25</pre></td><td class="code"><pre><span class="c"># 定制proxy</span>

<span class="kn">import</span> <span class="nn">requests</span>

<span class="n">url</span><span class="o">=</span><span class="s">'http://www.baidu.com/s?'</span>

<span class="n">data</span><span class="o">=</span><span class="p">{</span>
    <span class="s">'wd'</span><span class="p">:</span><span class="s">'ip'</span>
<span class="p">}</span>

<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'User-Agent'</span><span class="p">:</span> <span class="s">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2'</span><span class="p">,</span>
<span class="p">}</span>

<span class="c"># 注意: 这里如果是http, 那么 url 中的地址也需要是http</span>
<span class="c"># 不要一边是http, 另一边是 https</span>
<span class="n">proxies</span><span class="o">=</span><span class="p">{</span>
    <span class="s">'http'</span><span class="p">:</span> <span class="s">'124.88.84.154:8080'</span><span class="p">,</span>
<span class="p">}</span>

<span class="c"># 在参数中配置proxy 参数, 注意参数写法</span>
<span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span> <span class="n">proxies</span><span class="o">=</span><span class="n">proxies</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">status_code</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">'124.88.84.154'</span><span class="p">))</span>

</pre></td></tr></tbody></table>
</div>
</div>

<p>案例五: 用 requests 处理 session cookie , 模拟登录</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48</pre></td><td class="code"><pre>

<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">ssl</span>

<span class="n">ssl</span><span class="o">.</span><span class="n">_create_default_https_context</span> <span class="o">=</span> <span class="n">ssl</span><span class="o">.</span><span class="n">_create_unverified_context</span>

<span class="c"># 案例五: 用 requests 处理 cookie, 模拟登陆.</span>
<span class="c"># www.quanshuwang.com</span>
<span class="c"># 用户名:dancerpython</span>
<span class="c"># 密码: *****</span>



<span class="c"># 首页</span>
<span class="n">first_page_url</span> <span class="o">=</span> <span class="s">'http://www.quanshuwang.com/book_269.html'</span>
<span class="c"># 登录</span>
<span class="n">login_url</span> <span class="o">=</span> <span class="s">'http://www.qianshuwang.com/login.php?do=submit'</span>
<span class="c"># 登录成功后查看的收藏地址</span>
<span class="n">favorite_url</span> <span class="o">=</span> <span class="s">'http://www.quanshuwang.com/modules/article/bookcase.php'</span>

<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'User-Agent'</span><span class="p">:</span> <span class="s">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2'</span><span class="p">,</span>
<span class="p">}</span>

<span class="c"># 数据来自抓包工具</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'username'</span><span class="p">:</span> <span class="s">'dancerpython'</span><span class="p">,</span>
    <span class="s">'password'</span><span class="p">:</span> <span class="s">'123457'</span><span class="p">,</span>
    <span class="s">'action'</span><span class="p">:</span> <span class="s">'login'</span><span class="p">,</span>
<span class="p">}</span>

<span class="c"># 构建session 对象, 该对象可以自动保存于服务器的对话内容, 包括了 cookie信息</span>
<span class="n">session</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="c"># session 对象可以直对任何页面发起请求, 无论get还是post, session都可以得到会话内容.</span>
<span class="c"># session.get()</span>
<span class="c"># session.post()</span>

<span class="c"># 第一步, 登录收藏地址, 看看是否可以正常访问.</span>
<span class="n">resp</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">favorite_url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>
<span class="n">resp</span><span class="o">.</span><span class="n">encoding</span> <span class="o">=</span> <span class="s">'gbk'</span>
<span class="k">print</span><span class="p">(</span><span class="s">"请输入用户名"</span> <span class="ow">in</span> <span class="n">resp</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>  <span class="c"># 返回True, 因为还未登录, 所以结果是需要进行登录</span>

<span class="c"># 第二步: 获取cookie, 模拟登录</span>
<span class="n">resp</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">login_url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
<span class="n">resp</span><span class="o">.</span><span class="n">encoding</span> <span class="o">=</span> <span class="s">'gbk'</span>
<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>

</pre></td></tr></tbody></table>
</div>
</div>

<p>案例六: 模拟笑话网站的登录</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30</pre></td><td class="code"><pre>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="n">log_url</span> <span class="o">=</span> <span class="s">'http://www.jokeji.cn/user/c.asp?'</span>

<span class="n">member_center</span><span class="o">=</span> <span class="s">'http://www.jokeji.cn/User/MemberCenter.asp'</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'u'</span><span class="p">:</span><span class="s">'dancerpython'</span><span class="p">,</span>
    <span class="s">'p'</span><span class="p">:</span><span class="s">'123457abc'</span><span class="p">,</span>
    <span class="s">'t'</span><span class="p">:</span><span class="s">'big'</span>
<span class="p">}</span>

<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'User-Agent'</span><span class="p">:</span> <span class="s">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2'</span><span class="p">,</span>
<span class="p">}</span>

<span class="c"># 模拟登录</span>
<span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">log_url</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">headers</span> <span class="o">=</span> <span class="n">headers</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>


<span class="c"># 登录后普通访问无效</span>
<span class="n">member_resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">member_center</span><span class="p">,</span>  <span class="n">headers</span> <span class="o">=</span> <span class="n">headers</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">member_resp</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>

<span class="c"># 用 session 对象访问就可以了</span>
<span class="n">session</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">member_center</span><span class="p">,</span>  <span class="n">headers</span> <span class="o">=</span> <span class="n">headers</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
</pre></td></tr></tbody></table>
</div>
</div>

<p>案例七: 古诗文网  模拟验证码的登录</p>

<p><a href="http://www.chaorendama.com/">打码平台</a> 可以提供自动识别验证码的服务, 是付费服务.</p>

<p>用户名: dalong_co</p>

<p>密码: <strong>**</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52</pre></td><td class="code"><pre>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">urllib.request</span>

<span class="n">base_url</span> <span class="o">=</span> <span class="s">'http://so.gushiwen.org'</span>

<span class="n">favorite_url</span><span class="o">=</span> <span class="s">'http://so.gushiwen.org/user/login.aspx?form=http://so.gushiwen.org/user/collect.aspx'</span>

<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'User-Agent'</span><span class="p">:</span> <span class="s">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2'</span><span class="p">,</span>
<span class="p">}</span>


<span class="c"># 先从favorite_url 获取验证码图片</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">favorite_url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>

<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s">'lxml'</span><span class="p">)</span>
<span class="n">src</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">'#imgCode'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">attrs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'src'</span><span class="p">)</span>
<span class="c"># 验证码图片的全路径</span>
<span class="n">img_url</span> <span class="o">=</span> <span class="n">base_url</span><span class="o">+</span><span class="n">src</span>
<span class="c"># 下载图片</span>
<span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="n">img_url</span><span class="p">,</span> <span class="s">'yanzheng.png'</span><span class="p">)</span>
<span class="c"># 人工输入图片中的验证码</span>
<span class="n">yanzheng_code</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s">'请输入验证码数字'</span><span class="p">)</span>

<span class="n">login_url</span> <span class="o">=</span> <span class="s">'http://so.gushiwen.org/user/login.aspx?from=http</span><span class="si">%3</span><span class="s">a</span><span class="si">%2</span><span class="s">f</span><span class="si">%2</span><span class="s">fwww.gushiwen.org</span><span class="si">%2</span><span class="s">fdefault.aspx'</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">'#__VIEWSTATE'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">attrs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'value'</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s">'#__VIEWSTATEGENERATOR'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">attrs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">'value'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">yanzheng_code</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'__VIEWSTATE'</span><span class="p">:</span><span class="n">a</span><span class="p">,</span>
    <span class="s">'__VIEWSTATEGENERATOR'</span><span class="p">:</span><span class="n">b</span><span class="p">,</span>
    <span class="s">'from'</span><span class="p">:</span><span class="s">'http://so.gushiwen.org/'</span><span class="p">,</span>
    <span class="s">'email'</span><span class="p">:</span><span class="s">'37016175@qq.com'</span><span class="p">,</span>
    <span class="s">'pwd'</span><span class="p">:</span><span class="s">'ldl5506'</span><span class="p">,</span>
    <span class="s">'code'</span><span class="p">:</span><span class="n">yanzheng_code</span><span class="p">,</span>
    <span class="s">'denglu'</span><span class="p">:</span><span class="s">'登录'</span><span class="p">,</span>

<span class="p">}</span>

<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'User-Agent'</span><span class="p">:</span> <span class="s">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_3) AppleWebKit/604.5.6 (KHTML, like Gecko) Version/11.0.3 Safari/604.5.6'</span><span class="p">,</span>
<span class="p">}</span>


<span class="n">ret</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">login_url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">ret</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>

</pre></td></tr></tbody></table>
</div>
</div>

<p>案例: 内涵段子抓取</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19</pre></td><td class="code"><pre><span class="c"># 内涵段子 数据抓取 (xpath 配合 requests)</span>

<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">lxml</span> <span class="kn">import</span> <span class="n">etree</span>

<span class="c"># 获取网页内容</span>
<span class="n">url</span> <span class="o">=</span> <span class="s">'http://neihanshequ.com/'</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'User-Agent'</span><span class="p">:</span> <span class="s">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_3) AppleWebKit/604.5.6 (KHTML, like Gecko) Version/11.0.3 Safari/604.5.6'</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>


<span class="c"># 通过xpath 获取要抓取的数据</span>
<span class="n">xpath</span> <span class="o">=</span> <span class="s">'//ul[@id="detail-list"]/li//span[@class="name"]/text()'</span>
<span class="n">tree</span> <span class="o">=</span> <span class="n">etree</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span><span class="n">resp</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
<span class="n">name_list</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="n">xpath</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">name_list</span><span class="p">)</span>
</pre></td></tr></tbody></table>
</div>
</div>

<h2 id="scrapy">Scrapy</h2>

<p><a href="https://scrapy.org">官网</a></p>

<p><a href="http://scrapy-chs.readthedocs.io/zh_CN/0.24/intro/tutorial.html">中文文档</a></p>

<h3 id="概念与安装">概念与安装</h3>

<p>Scrapy 是一个为了怕去网站数据, 提取结构性数据而编写的框架.</p>

<p>安装:</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">pip3.6 install scrapy</code></p>
  </li>
  <li>
    <p>安装好后就可以在命令行使用 scrapy 命令了.</p>
  </li>
  <li>
    <p>命令使用方法:</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23</pre></td><td class="code"><pre># scrapy --help
Scrapy 1.5.0 - project: FirstSpi

Usage:
  scrapy &lt;command&gt; [options] [args]

Available commands:
  bench         Run quick benchmark test
  check         Check spider contracts
  crawl         Run a spider
  edit          Edit spider
  fetch         Fetch a URL using the Scrapy downloader
  genspider     Generate new spider using pre-defined templates
  list          List available spiders
  parse         Parse URL (using its spider) and print the results
  runspider     Run a self-contained spider (without creating a project)
  settings      Get settings values
  shell         Interactive scraping console
  startproject  Create new project
  version       Print Scrapy version
  view          Open URL in browser, as seen by Scrapy

Use "scrapy &lt;command&gt; -h" to see more info about a command
</pre></td></tr></tbody></table>
</div>
    </div>
  </li>
</ul>

<p>框架组成:</p>

<ul>
  <li>引擎</li>
  <li>下载器</li>
  <li>spiders ( 我们自己的代码主要放在这里 )</li>
  <li>调度器</li>
  <li>管道( Item Pipeline)</li>
</ul>

<p>工作原理:</p>

<p><img src="/Users/dalong/Library/Mobile Documents/com~apple~CloudDocs/python1702笔记/2018-03-26_14-30-33.jpg" alt="" /></p>

<p>创建项目:</p>

<ul>
  <li>cd 到 一个目录</li>
  <li><code class="language-plaintext highlighter-rouge">scrapy startproject FirstSpi</code> 就生成了一个项目目录</li>
  <li>目录结构如下:
<img src="/Users/dalong/Library/Mobile Documents/com~apple~CloudDocs/python1702笔记/2018-03-26_14-43-55.jpg" alt="" /></li>
</ul>

<p>创建爬虫命令:</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">scrapy genspider qiubai "www.qiushibaike.com"</code></p>
  </li>
  <li>注意, 爬虫名字不能和项目名字重名.</li>
  <li>命令执行后, 会生成一个新的目录 spiders , 目录中会有qiubai.py 文件</li>
  <li>接下来的代码编写主要围绕 qiubai.py 和 items.py 进行</li>
</ul>

<p>开始爬取 糗百: <code class="language-plaintext highlighter-rouge">scrapy crawl qiubai</code></p>

<ul>
  <li>代码写完后用就可以用爬取命令进行数据抓取.</li>
  <li>修改 qiubai.py 文件中的 parse 函数 , 然后重复执行上面的命令</li>
</ul>

<p>导出文件命令</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">scrapy crawl qiubai -o qiubai.csv</code></li>
</ul>

<h3 id="实战一-糗事百科-拿作者头像-名称和内容">实战一: 糗事百科, 拿作者头像, 名称和内容</h3>

<p>修改 items.py 文件</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20</pre></td><td class="code"><pre><span class="c"># -*- coding: utf-8 -*-</span>

<span class="c"># Define here the models for your scraped items</span>
<span class="c">#</span>
<span class="c"># See documentation in:</span>
<span class="c"># https://doc.scrapy.org/en/latest/topics/items.html</span>

<span class="kn">import</span> <span class="nn">scrapy</span>


<span class="c"># FirstspiItem 是一个字典类型, 需要用字典的方式访问这个类的数据</span>
<span class="k">class</span> <span class="nc">FirstspiItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>
    <span class="c"># define the fields for your item here like:</span>
    <span class="c"># name = scrapy.Field()</span>

    <span class="c"># 创建三个变量, 分别保存用户名和头像的图片链接和文本内容</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">content</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>

</pre></td></tr></tbody></table>
</div>
</div>

<p>修改 qiubai.py 文件</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53</pre></td><td class="code"><pre><span class="c"># -*- coding: utf-8 -*-</span>
<span class="kn">import</span> <span class="nn">scrapy</span>

<span class="c"># 这个文件就是 spider 文件. 是被  scrapy genspider qiubai "www.qiushibaike.com" 创建出来的</span>
<span class="c"># 此文件中除了parse 之外, 其他的预设的函数名, 类名, 变量名都不要修改.</span>
<span class="k">class</span> <span class="nc">QiubaiSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="c"># 爬虫名字, 运行爬虫命令时需要用到</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">'qiubai'</span>
    <span class="c"># 允许爬取的域名列表</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">'www.qiushibaike.com'</span><span class="p">]</span>
    <span class="c"># 起始的爬取URLs, 由spiders 主动提交给引擎开始爬取.</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">'http://www.qiushibaike.com/'</span><span class="p">]</span>

    <span class="c"># 解析函数, 是一个回调函数.</span>
    <span class="c"># 该解析函数必须返回一个可迭代对象, 不写不会报错, 但无法导出数据为文件</span>


    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="c"># print("=============")</span>
        <span class="c"># print(type(response))</span>
        <span class="c"># print(response.xpath())</span>
        <span class="c"># print("=============")</span>

        <span class="c"># response.xpath 获取到的并不是etree 一样的数据,而是一个 Selector 对象</span>
        <span class="c"># Selector 对象 可以使用 extract 方法进行解析, 获取到里面的数据</span>
        <span class="c"># Selector 对象也可以使用 xpath 函数</span>
        <span class="n">div_list</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//div[starts-with(@class, "author")]'</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"============="</span><span class="p">)</span>
        <span class="c"># items = []</span>
        <span class="k">for</span> <span class="n">div</span> <span class="ow">in</span> <span class="n">div_list</span><span class="p">:</span>
            <span class="n">item</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="c"># extract 函数可以对selector 的列表执行, 也可以对单个selector 执行.</span>
            <span class="c"># 获取图片url和作者名</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">div</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'.//h2/text()'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s">'</span><span class="se">\r\n</span><span class="s">'</span><span class="p">)</span>
            <span class="c"># print(name)</span>
            <span class="n">img</span> <span class="o">=</span> <span class="n">div</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'.//img/@src'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
            <span class="c"># print(img)</span>
            <span class="n">content</span> <span class="o">=</span> <span class="n">div</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'..//a/div[@class="content"]/span[1]/text()'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">content</span> <span class="o">=</span> <span class="n">content</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s">'</span><span class="se">\r\n</span><span class="s">'</span><span class="p">)</span>
            <span class="c"># item字典的数据来自items.py 中的属性定义</span>
            <span class="n">item</span><span class="p">[</span><span class="s">'name'</span><span class="p">]</span> <span class="o">=</span> <span class="n">name</span>
            <span class="n">item</span><span class="p">[</span><span class="s">'img'</span><span class="p">]</span> <span class="o">=</span> <span class="n">img</span>
            <span class="n">item</span><span class="p">[</span><span class="s">'content'</span><span class="p">]</span> <span class="o">=</span> <span class="n">content</span>
            <span class="c"># 使用 yield 可以优化内存开销, 建议使用 yield 代替 return </span>
            <span class="k">yield</span> <span class="n">item</span>
            <span class="c"># items.append(item)</span>

        <span class="c"># print(items)</span>
        <span class="c"># print("=============")</span>
        <span class="c"># return items</span>


</pre></td></tr></tbody></table>
</div>
</div>

<p>执行 <code class="language-plaintext highlighter-rouge">scrapy crawl qiubai -o qiubai.csv</code> 后会在目录中生成 qiubai.csv 文件, 也可以导出 json 或 xml 文件</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3</pre></td><td class="code"><pre>scrapy crawl qiubai -o qiubai.csv
scrapy crawl qiubai -o qiubai.xml
scrapy crawl qiubai -o qiubai.json
</pre></td></tr></tbody></table>
</div>
</div>

<h3 id="scrapy-shell-介绍">Scrapy Shell 介绍</h3>

<p>Scrapy 的命令行工具, 可以快速获取想要的爬取内容</p>

<p>查看百度首页</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4</pre></td><td class="code"><pre>mkdir ScrapyShell
<span class="nb">cd </span>ScrapyShell/

scrapy shell <span class="s2">"www.baidu.com"</span>
</pre></td></tr></tbody></table>
</div>
</div>

<p>进入ipython 命令行</p>

<h5 id="用-xpath-获取数据"><em>用 xpath 获取数据</em></h5>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4</pre></td><td class="code"><pre><span class="n">response</span><span class="o">.</span><span class="n">text</span>  <span class="c"># 查看百度首页所有返回的文本</span>
<span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//div[@id="lg"]/img/@src'</span><span class="p">)</span> <span class="c"># 查看百度logo 的xpath 元素</span>
<span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//div[@id="lg"]/img/@src'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span> <span class="c"># 获取百度 logo的 图片地址</span>

</pre></td></tr></tbody></table>
</div>
</div>

<p>查看视频首页的视频来源</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>scrapy shell <span class="s2">"365yg.com"</span>
</pre></td></tr></tbody></table>
</div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2</pre></td><td class="code"><pre><span class="n">response</span><span class="o">.</span><span class="n">text</span>  <span class="c"># 查看视频首页所有返回的文本</span>
<span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//li[starts-with(@class,"item")]//a[@target="_blank"]/text()'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</pre></td></tr></tbody></table>
</div>
</div>

<h5 id="用responsecss-定位数据"><em>用response.css 定位数据</em></h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>scrapy shell <span class="s2">"https://sou.zhaopin.com/jobs/searchresult.ashx?jl=%E4%B8%8A%E6%B5%B7&amp;kw=python&amp;sm=0&amp;p=1"</span>
</pre></td></tr></tbody></table>
</div>
</div>

<p>::text 是拿内容</p>

<p>::attr(“”) 是拿属性</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3</pre></td><td class="code"><pre><span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'table[class="newlist"] td[class="zwmc"]&gt;div&gt;a::text'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>

<span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s">'table[class="newlist"] td[class="zwmc"]&gt;div&gt;a::attr("href")'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</pre></td></tr></tbody></table>
</div>
</div>

<h3 id="pipelinespy-的作用">pipelines.py 的作用</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31</pre></td><td class="code"><pre><span class="c"># -*- coding: utf-8 -*-</span>

<span class="c"># Define your item pipelines here</span>
<span class="c">#</span>
<span class="c"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span>
<span class="c"># See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span>


<span class="c"># pipelines 用于处理及存储数据</span>
<span class="c"># 生命周期函数, 就是构造函数和解构函数等</span>
<span class="c"># 如果需要让 pipeline 生效, 必须开启 settings.py 中的 "ITEM_PIPELINES" 开关</span>

<span class="k">class</span> <span class="nc">FirstspiPipeline</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="c"># process_item 是必须实现的方法</span>
    <span class="c"># 每次获取到数据, 都会自动调用这个方法, 在此处对数据进行加工处理</span>
    <span class="k">def</span> <span class="nf">process_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">item</span>

    <span class="c"># 可选方法</span>
    <span class="c"># 开始执行spider 程序时, 自动触发这个方法. 相当于构造函数, 该函数只会被执行一次</span>
    <span class="c"># 一般用于初始化数据库, 打开文件等</span>
    <span class="k">def</span> <span class="nf">open_spider</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">spider</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="c"># 可选方法</span>
    <span class="c"># 爬虫结束时, 自动调用. 只会被调用一次</span>
    <span class="c"># 解构函数, 用于关闭数据库, 关闭文件等.</span>
    <span class="k">def</span> <span class="nf">colose_spider</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">spider</span><span class="p">):</span>
        <span class="k">pass</span>

</pre></td></tr></tbody></table>
</div>
</div>

<h4 id="实例分析--抓取百度首页的文字">实例分析 – 抓取百度首页的文字</h4>

<p>第一步: 创建项目和爬虫</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2</pre></td><td class="code"><pre>scrapy startproject baidu
scrapy genspider homepage <span class="s2">"www.baidu.com"</span>
</pre></td></tr></tbody></table>
</div>
</div>

<p>第二步: 修改配置文件settings.py, homepage.py, pipelines.py, items.py</p>

<p>settings.py</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22</pre></td><td class="code"><pre>
<span class="n">BOT_NAME</span> <span class="o">=</span> <span class="s">'baidu'</span>

<span class="n">SPIDER_MODULES</span> <span class="o">=</span> <span class="p">[</span><span class="s">'baidu.spiders'</span><span class="p">]</span>
<span class="n">NEWSPIDER_MODULE</span> <span class="o">=</span> <span class="s">'baidu.spiders'</span>


<span class="c"># Crawl responsibly by identifying yourself (and your website) on the user-agent</span>
<span class="n">USER_AGENT</span> <span class="o">=</span> <span class="s">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_3) AppleWebKit/604.5.6 (KHTML, like Gecko) Version/11.0.3 Safari/604.5.6'</span>

<span class="c"># Obey robots.txt rules</span>
<span class="n">ROBOTSTXT_OBEY</span> <span class="o">=</span> <span class="bp">False</span>


<span class="c"># Configure item pipelines</span>
<span class="c"># See https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span>
<span class="n">ITEM_PIPELINES</span> <span class="o">=</span> <span class="p">{</span>
   <span class="s">'baidu.pipelines.BaiduPipeline'</span><span class="p">:</span> <span class="mi">300</span><span class="p">,</span>
<span class="p">}</span>



</pre></td></tr></tbody></table>
</div>
</div>

<p>homepage.py</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19</pre></td><td class="code"><pre><span class="c"># -*- coding: utf-8 -*-</span>
<span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">HomepageSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">'homepage'</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">'www.baidu.com'</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">'http://www.baidu.com/'</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">item</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//map//@title'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'========='</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'========='</span><span class="p">)</span>
        <span class="n">item</span><span class="p">[</span><span class="s">'name'</span><span class="p">]</span> <span class="o">=</span> <span class="n">name</span>
        <span class="c"># 必须返回一个字典, 否则pipeline 无法获取输入数据</span>
        <span class="k">yield</span> <span class="n">item</span>

</pre></td></tr></tbody></table>
</div>
</div>

<p>pipelines.py</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27</pre></td><td class="code"><pre><span class="c"># -*- coding: utf-8 -*-</span>

<span class="c"># Define your item pipelines here</span>
<span class="c">#</span>
<span class="c"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span>
<span class="c"># See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span>


<span class="k">class</span> <span class="nc">BaiduPipeline</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="c"># process_item 是必须实现的方法</span>
    <span class="c"># 每次获取到数据, 都会自动调用这个方法, 在此处对数据进行加工处理</span>
    <span class="k">def</span> <span class="nf">process_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"=====process_item======"</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">item</span>

    <span class="c"># 可选方法</span>
    <span class="c"># 开始执行spider 程序时, 自动触发这个方法. 相当于构造函数, 该函数只会被执行一次</span>
    <span class="c"># 一般用于初始化数据库, 打开文件等</span>
    <span class="k">def</span> <span class="nf">open_spider</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">spider</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'==========open_spider========'</span><span class="p">)</span>

    <span class="c"># 可选方法</span>
    <span class="c"># 爬虫结束时, 自动调用. 只会被调用一次</span>
    <span class="c"># 解构函数, 用于关闭数据库, 关闭文件等.</span>
    <span class="k">def</span> <span class="nf">close_spider</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">spider</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'+++++++colose_spider+++++++'</span><span class="p">)</span>
</pre></td></tr></tbody></table>
</div>
</div>

<p>items.py</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9</pre></td><td class="code"><pre>
<span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">BaiduItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>
    <span class="c"># define the fields for your item here like:</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="c"># pass</span>

</pre></td></tr></tbody></table>
</div>
</div>

<p>第三步: 执行爬取命令</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>scrapy crawl homepage
</pre></td></tr></tbody></table>
</div>
</div>

<h4 id="案例二-抓取电影信息">案例二: 抓取电影信息</h4>

<p>创建项目和爬虫</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3</pre></td><td class="code"><pre>scrapy startproject filmProject
cd filmProject
scrapy genspider film "www.id97.com/movie"
</pre></td></tr></tbody></table>
</div>
</div>

<p>修改基本信息 settings.py</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26</pre></td><td class="code"><pre>
<span class="n">BOT_NAME</span> <span class="o">=</span> <span class="s">'filmProject'</span>

<span class="n">SPIDER_MODULES</span> <span class="o">=</span> <span class="p">[</span><span class="s">'filmProject.spiders'</span><span class="p">]</span>
<span class="n">NEWSPIDER_MODULE</span> <span class="o">=</span> <span class="s">'filmProject.spiders'</span>


<span class="c"># Crawl responsibly by identifying yourself (and your website) on the user-agent</span>
<span class="n">USER_AGENT</span> <span class="o">=</span> <span class="s">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_3) AppleWebKit/604.5.6 (KHTML, like Gecko) Version/11.0.3 Safari/604.5.6'</span>

<span class="c"># Obey robots.txt rules</span>
<span class="n">ROBOTSTXT_OBEY</span> <span class="o">=</span> <span class="bp">False</span>


<span class="n">DEFAULT_REQUEST_HEADERS</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'Accept'</span><span class="p">:</span> <span class="s">'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'</span><span class="p">,</span>
  <span class="c"># 'Accept-Language': 'en',</span>
<span class="p">}</span>


<span class="n">ITEM_PIPELINES</span> <span class="o">=</span> <span class="p">{</span>
   <span class="s">'filmProject.pipelines.FilmprojectPipeline'</span><span class="p">:</span> <span class="mi">300</span><span class="p">,</span>
<span class="p">}</span>



</pre></td></tr></tbody></table>
</div>
</div>

<p>items.py</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10</pre></td><td class="code"><pre><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">FilmprojectItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>
    <span class="c"># define the fields for your item here like:</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">img_url</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="n">director</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
    <span class="c"># pass</span>
</pre></td></tr></tbody></table>
</div>
</div>

<p>film.py</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53</pre></td><td class="code"><pre><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">FilmSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">'film'</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">'www.id97.com/movie'</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">'http://www.id97.com/movie/?page='</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">)]</span>
    <span class="k">print</span><span class="p">(</span><span class="n">start_urls</span><span class="p">,</span><span class="s">"================="</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="c"># 电影名 //div[contains(@class,"movie-item")]//a[@style]/@title</span>
        <span class="c"># 图片 //div[contains(@class,"movie-item")]//img/@data-original</span>
        <span class="c"># 评分 //div[contains(@class,"movie-item")]//div[@class="meta"]//em/text()</span>
        <span class="c"># div_list = response.xpath('//div[contains(@class,"movie-item-in")]')</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//div[contains(@class,"movie-item-in")]//a[@style]/@title'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="n">img_url</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//div[contains(@class,"movie-item-in")]//img/@data-original'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//div[contains(@class,"movie-item-in")]//div[@class="meta"]//em/text()'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="n">detail_url</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//div[contains(@class,"movie-item-in")]/a/@href'</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
        <span class="k">print</span><span class="p">(</span><span class="n">detail_url</span><span class="p">)</span>


        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">name</span><span class="p">)):</span>
            <span class="c"># 也可以使用 items中的类创建对象, 用字典对象也没有问题.</span>
            <span class="n">item</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">item</span><span class="p">[</span><span class="s">'name'</span><span class="p">]</span> <span class="o">=</span> <span class="n">name</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">item</span><span class="p">[</span><span class="s">'img_url'</span><span class="p">]</span> <span class="o">=</span> <span class="n">img_url</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">item</span><span class="p">[</span><span class="s">'score'</span><span class="p">]</span> <span class="o">=</span> <span class="n">score</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="c"># 导演名字在详情页, 需要去详情页抓取</span>
            <span class="c"># 返回一个request给引擎, 这个request负责请求电影详情页的导演信息. cllback 函数负责导演名字的解析</span>
            <span class="c"># meta参数, 是用来在此函数和自定义函数 parse_info 之间传递参数, 以字典形式设置</span>
            <span class="c"># call back 函数在引擎获得下载信息后被触发</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">detail_url</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse_director</span><span class="p">,</span> <span class="n">meta</span><span class="o">=</span><span class="p">{</span><span class="s">'item'</span><span class="p">:</span> <span class="n">item</span><span class="p">},</span> <span class="n">dont_filter</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="c"># 将数据返回给 pipelines.py</span>
            <span class="c"># print(item)</span>
            <span class="c"># yield item</span>



        <span class="c"># # 解析一页后, 把下一页再传给引擎</span>
        <span class="c"># next_url = 'http://www.id97.com/movie/' + '?page' + str(self.page)</span>
        <span class="c"># self.page = self.page+1</span>
        <span class="c"># yield scrapy.Request(url=next_url, callback=self.parse)</span>

    <span class="k">def</span> <span class="nf">parse_director</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="c"># 先从 response 中获取返回的item 对象</span>
        <span class="n">item</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">meta</span><span class="p">[</span><span class="s">'item'</span><span class="p">]</span>
        <span class="c"># response.text 是详情页的源代码</span>
        <span class="c"># 所以就可以用详情页的解析逻辑来解析导演名称</span>
        <span class="n">director</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//table/tbody/tr[1]/td[2]/a/text()'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
        <span class="c"># 拿了导演姓名, 就可以把信息写入 item 对象中了</span>
        <span class="n">item</span><span class="p">[</span><span class="s">'director'</span><span class="p">]</span> <span class="o">=</span> <span class="n">director</span>
        <span class="c"># 到此, item 就完整了.</span>
        <span class="k">yield</span> <span class="n">item</span>
</pre></td></tr></tbody></table>
</div>
</div>

<p>创建图片下载目录, 并执行爬虫</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2</pre></td><td class="code"><pre>mkdir imgs
scrapy crawl film
</pre></td></tr></tbody></table>
</div>
</div>

<h3 id="链接提取器-link-extractors">链接提取器 Link Extractors</h3>

<p><a href="http://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/link-extractors.html">文档</a></p>

<p>作用是在页面原地阿妈中提取链接, 既 a 标签的内容</p>

<p>每个LinkExtractor有唯一的公共方法是 <code class="language-plaintext highlighter-rouge">extract_links</code> ,它接收一个 <a href="http://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/request-response.html#scrapy.http.Response"><code class="language-plaintext highlighter-rouge">Response</code></a> 对象,并返回一个 <code class="language-plaintext highlighter-rouge">scrapy.link.Link</code> 对象｡Link Extractors,要实例化一次并且 <code class="language-plaintext highlighter-rouge">extract_links</code> 方法会根据不同的response调用多次提取链接｡</p>

<p>导入方法:</p>

<p><code class="language-plaintext highlighter-rouge">from scrapy.linkextractors import LinkExtractor</code></p>

<p>创建对象</p>

<p><code class="language-plaintext highlighter-rouge">link = LinkExtractor(提取规则)</code></p>

<p>提取规则参数: (建议使用 xpath )</p>

<ul>
  <li>allow 正则</li>
  <li>deny 不提取正则的规则</li>
  <li><strong>restrict_xpaths  用 xpath 提取链接</strong></li>
  <li>restrict_css 用 css 选择器提取链接</li>
</ul>

<p>返回的提取链接</p>

<p><code class="language-plaintext highlighter-rouge">links.extract_links(response)</code></p>

<p>例子: 电影天堂 提取国内电影的链接</p>

<p>使用 scrapy shell 进行爬去</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2</pre></td><td class="code"><pre>scrapy shell <span class="s2">"http://www.ygdy8.net/html/gndy/china/index.html"</span>

</pre></td></tr></tbody></table>
</div>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21</pre></td><td class="code"><pre><span class="kn">from</span> <span class="nn">scrapy.linkextractors</span> <span class="kn">import</span> <span class="n">LinkExtractor</span>

<span class="c"># 使用正则提取链接</span>

<span class="n">linkor</span> <span class="o">=</span> <span class="n">LinkExtractor</span><span class="p">(</span><span class="n">allow</span><span class="o">=</span><span class="s">r'list_4_</span><span class="err">\</span><span class="s">d+?.html'</span><span class="p">)</span>
<span class="n">linkor</span><span class="o">.</span><span class="n">extract_links</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
<span class="c"># 输入结果如是一个链接的数组:</span>


<span class="c"># 使用xpath 提取链接</span>
<span class="c"># 注意: xpaths 只需要提取到a 标签外层的元素即可. 就可以获得所有的链接</span>

<span class="n">links</span> <span class="o">=</span> <span class="n">LinkExtractor</span><span class="p">(</span><span class="n">restrict_xpaths</span><span class="o">=</span><span class="s">'//div[@class="x"]'</span><span class="p">)</span>
<span class="n">links</span><span class="o">.</span><span class="n">extract_links</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
<span class="c"># 输出结果和上面相同</span>

<span class="c"># 使用 css 访问链接</span>
<span class="n">linksl</span> <span class="o">=</span> <span class="n">LinkExtractor</span><span class="p">(</span><span class="n">restrict_css</span><span class="o">=</span><span class="s">'.x'</span><span class="p">)</span>
<span class="n">linksl</span><span class="o">.</span><span class="n">extract_links</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
<span class="c"># 输出结果同上</span>

</pre></td></tr></tbody></table>
</div>
</div>

<p>输出结果</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7</pre></td><td class="code"><pre><span class="o">[</span>Link<span class="o">(</span><span class="nv">url</span><span class="o">=</span><span class="s1">'http://www.ygdy8.net/html/gndy/china/list_4_2.html'</span>, <span class="nv">text</span><span class="o">=</span><span class="s1">'[2]'</span>, <span class="nv">fragment</span><span class="o">=</span><span class="s1">''</span>, <span class="nv">nofollow</span><span class="o">=</span>False<span class="o">)</span>,
 Link<span class="o">(</span><span class="nv">url</span><span class="o">=</span><span class="s1">'http://www.ygdy8.net/html/gndy/china/list_4_3.html'</span>, <span class="nv">text</span><span class="o">=</span><span class="s1">'[3]'</span>, <span class="nv">fragment</span><span class="o">=</span><span class="s1">''</span>, <span class="nv">nofollow</span><span class="o">=</span>False<span class="o">)</span>,
 Link<span class="o">(</span><span class="nv">url</span><span class="o">=</span><span class="s1">'http://www.ygdy8.net/html/gndy/china/list_4_4.html'</span>, <span class="nv">text</span><span class="o">=</span><span class="s1">'[4]'</span>, <span class="nv">fragment</span><span class="o">=</span><span class="s1">''</span>, <span class="nv">nofollow</span><span class="o">=</span>False<span class="o">)</span>,
 Link<span class="o">(</span><span class="nv">url</span><span class="o">=</span><span class="s1">'http://www.ygdy8.net/html/gndy/china/list_4_5.html'</span>, <span class="nv">text</span><span class="o">=</span><span class="s1">'[5]'</span>, <span class="nv">fragment</span><span class="o">=</span><span class="s1">''</span>, <span class="nv">nofollow</span><span class="o">=</span>False<span class="o">)</span>,
 Link<span class="o">(</span><span class="nv">url</span><span class="o">=</span><span class="s1">'http://www.ygdy8.net/html/gndy/china/list_4_6.html'</span>, <span class="nv">text</span><span class="o">=</span><span class="s1">'[6]'</span>, <span class="nv">fragment</span><span class="o">=</span><span class="s1">''</span>, <span class="nv">nofollow</span><span class="o">=</span>False<span class="o">)</span>,
 Link<span class="o">(</span><span class="nv">url</span><span class="o">=</span><span class="s1">'http://www.ygdy8.net/html/gndy/china/list_4_7.html'</span>, <span class="nv">text</span><span class="o">=</span><span class="s1">'[7]'</span>, <span class="nv">fragment</span><span class="o">=</span><span class="s1">''</span>, <span class="nv">nofollow</span><span class="o">=</span>False<span class="o">)</span>,
 Link<span class="o">(</span><span class="nv">url</span><span class="o">=</span><span class="s1">'http://www.ygdy8.net/html/gndy/china/list_4_101.html'</span>, <span class="nv">text</span><span class="o">=</span><span class="s1">'末页'</span>, <span class="nv">fragment</span><span class="o">=</span><span class="s1">''</span>, <span class="nv">nofollow</span><span class="o">=</span>False<span class="o">)]</span> 
</pre></td></tr></tbody></table>
</div>
</div>

<p>案例二:  读书网爬取</p>

<p>创建项目:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3</pre></td><td class="code"><pre>scrapy startproject dushuProject
<span class="nb">cd </span>dushuProject
scrapy genspider -t crawl <span class="nb">read</span> <span class="s2">"www.dushu.com/book/1081.html"</span>
</pre></td></tr></tbody></table>
</div>
</div>

<p>修改settings.py</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30</pre></td><td class="code"><pre>
<span class="n">BOT_NAME</span> <span class="o">=</span> <span class="s">'dushuProject'</span>

<span class="n">SPIDER_MODULES</span> <span class="o">=</span> <span class="p">[</span><span class="s">'dushuProject.spiders'</span><span class="p">]</span>
<span class="n">NEWSPIDER_MODULE</span> <span class="o">=</span> <span class="s">'dushuProject.spiders'</span>


<span class="c"># Crawl responsibly by identifying yourself (and your website) on the user-agent</span>
<span class="n">USER_AGENT</span> <span class="o">=</span> <span class="s">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_3) AppleWebKit/604.5.6 (KHTML, like Gecko) Version/11.0.3 Safari/604.5.6'</span>

<span class="c"># Obey robots.txt rules</span>
<span class="n">ROBOTSTXT_OBEY</span> <span class="o">=</span> <span class="bp">False</span>



<span class="c"># Override the default request headers:</span>
<span class="n">DEFAULT_REQUEST_HEADERS</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s">'Accept'</span><span class="p">:</span> <span class="s">'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'</span><span class="p">,</span>
  <span class="s">'Accept-Language'</span><span class="p">:</span> <span class="s">'en'</span><span class="p">,</span>
<span class="p">}</span>


<span class="c"># Configure item pipelines</span>
<span class="c"># See https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span>
<span class="n">ITEM_PIPELINES</span> <span class="o">=</span> <span class="p">{</span>
   <span class="s">'dushuProject.pipelines.DushuprojectPipeline'</span><span class="p">:</span> <span class="mi">300</span><span class="p">,</span>
<span class="p">}</span>



</pre></td></tr></tbody></table>
</div>
</div>

<p>修改 read.py</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38</pre></td><td class="code"><pre><span class="c"># -*- coding: utf-8 -*-</span>
<span class="kn">import</span> <span class="nn">scrapy</span>
<span class="c"># 链接提取器</span>
<span class="kn">from</span> <span class="nn">scrapy.linkextractors</span> <span class="kn">import</span> <span class="n">LinkExtractor</span>
<span class="c"># 导入 spider</span>
<span class="kn">from</span> <span class="nn">scrapy.spiders</span> <span class="kn">import</span> <span class="n">CrawlSpider</span><span class="p">,</span> <span class="n">Rule</span>

<span class="c"># 这里的类继承了 CrawlSpider 子类, 而CrawlSpider 继承自 scrapy.spider 基类</span>
<span class="k">class</span> <span class="nc">ReadSpider</span><span class="p">(</span><span class="n">CrawlSpider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">'read'</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">'www.dushu.com'</span><span class="p">]</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s">'https://www.dushu.com/book/1081.html'</span><span class="p">]</span>

    <span class="c"># 建议不要重写父类的parses方法</span>
    <span class="c"># 父类的逻辑</span>
    <span class="c"># def parse(self, response):</span>
    <span class="c">#    pass</span>


    <span class="c"># 子类实现一个 rules 元组, 框架会自动调用这个rules</span>
    <span class="c"># 包含了一个链接提取器对象.</span>
    <span class="c"># callback 是回调函数</span>
    <span class="c"># follow 指定是否跟进链接(继续爬取链接中的链接)</span>
    <span class="c"># LinkExtractor对象的提取规则需要我们制定</span>
    <span class="n">rules</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">Rule</span><span class="p">(</span><span class="n">LinkExtractor</span><span class="p">(</span><span class="n">allow</span><span class="o">=</span><span class="s">r'/book/1081_</span><span class="err">\</span><span class="s">d+?.html'</span><span class="p">),</span> <span class="n">callback</span><span class="o">=</span><span class="s">'parse_item'</span><span class="p">,</span> <span class="n">follow</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
    <span class="p">)</span>

    <span class="c"># 回调函数</span>
    <span class="k">def</span> <span class="nf">parse_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>

        <span class="n">book_list</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'//div[@class="bookslist"]/ul/li'</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">book</span> <span class="ow">in</span> <span class="n">book_list</span><span class="p">:</span>
            <span class="n">i</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">i</span><span class="p">[</span><span class="s">'title'</span><span class="p">]</span> <span class="o">=</span> <span class="n">book</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">'./div[@class="book-info"]/h3/a/@title'</span><span class="p">)</span><span class="o">.</span><span class="n">extract_first</span><span class="p">()</span>
            <span class="k">print</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">i</span>

</pre></td></tr></tbody></table>
</div>
</div>

<p>修改 pipelines.py</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22</pre></td><td class="code"><pre><span class="c"># -*- coding: utf-8 -*-</span>

<span class="c"># Define your item pipelines here</span>
<span class="c">#</span>
<span class="c"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span>
<span class="c"># See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="k">class</span> <span class="nc">DushuprojectPipeline</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">open_spider</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fp</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s">'read.json'</span><span class="p">,</span><span class="s">'w'</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">close_spider</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fp</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">process_item</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">,</span> <span class="n">spider</span><span class="p">):</span>
        <span class="n">string</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">item</span><span class="p">,</span><span class="n">ensure_ascii</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fp</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">string</span> <span class="o">+</span> <span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">item</span>


</pre></td></tr></tbody></table>
</div>
</div>

<h3 id="爬虫的日志信息">爬虫的日志信息</h3>

<p>级别:</p>

<ul>
  <li>严重 CRITICAL</li>
  <li>一般 ERROR</li>
  <li>警告 WORNING</li>
  <li>一般信息 DEBUG</li>
  <li>​</li>
</ul>

<p>settings.py 文件增加如下代码:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7</pre></td><td class="code"><pre><span class="c"># 设置日志登记</span>
<span class="c"># 不需要打印调试信息, 就可以调试完后关闭</span>
<span class="c"># 因为打印语句会比较消耗爬取效率和系统资源, 所以需要注意</span>
<span class="c">#LOG_LEVEL = "ERROR"</span>
<span class="n">LOG_LEVEL</span> <span class="o">=</span> <span class="s">"INFO"</span>

<span class="n">LOG_FILE</span> <span class="o">=</span> <span class="s">'read.log'</span>
</pre></td></tr></tbody></table>
</div>
</div>

<h3 id="post-请求-1">POST 请求</h3>

<p>创建项目</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3</pre></td><td class="code"><pre>scrapy startproject fanyiproject
<span class="nb">cd </span>fanyiproject
scrapy genspider fanyi <span class="s2">"fanyi.baidu.com"</span>
</pre></td></tr></tbody></table>
</div>
</div>

<p>修改 fenyi.py</p>

<div class="language-python highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32</pre></td><td class="code"><pre><span class="c"># -*- coding: utf-8 -*-</span>
<span class="kn">import</span> <span class="nn">scrapy</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="k">class</span> <span class="nc">FanyiSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">'fanyi'</span>
    <span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s">'fanyi.baidu.com'</span><span class="p">]</span>
    <span class="c"># start_urls = ['http://fanyi.baidu.com/']</span>

    <span class="c"># 默认是以 GET 方式提交请求, 引擎会自动把 start_urls 里面的url 封装成请求</span>
    <span class="c"># def parse(self, response):</span>
    <span class="c">#   pass</span>

    <span class="c"># POST 的请求就需要重写start_requests 方法</span>
    <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">post_url</span><span class="o">=</span><span class="s">'http://fanyi.baidu.com/sug'</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">'kw'</span><span class="p">:</span> <span class="s">'baby'</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="c"># 提交post 请求</span>
        <span class="c"># url post地址</span>
        <span class="c"># formdata post 的参数</span>
        <span class="c"># callback 回调函数, 引擎会把response 对象回传给这个指定的函数</span>
        <span class="c"># FormRequest 用于提交 POST 请求</span>
        <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">FormRequest</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">post_url</span><span class="p">,</span> <span class="n">formdata</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse_info</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse_info</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">response</span><span class="p">):</span>
        <span class="c"># 解析内容即可</span>
        <span class="n">obj</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span>
        <span class="n">string</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">string</span><span class="p">)</span>

</pre></td></tr></tbody></table>
</div>
</div>

<h4 id="小练习-爬取王者荣耀官网">小练习: 爬取王者荣耀官网</h4>

<p>需求: 将英雄信息和图片写到数据库中</p>


            </div>

            <!-- Rating -->
            
            <div class="rating mb-4 d-flex align-items-center">
                <strong class="mr-1">Rating:</strong> <div class="rating-holder">
<div class="c-rating c-rating--regular" data-rating-value="4.5">
  <button>1</button>
  <button>2</button>
  <button>3</button>
  <button>4</button>
  <button>5</button>
</div>
</div>
            </div>
            

            <!-- Post Date -->
            <p>
            <small>
                <span class="post-date"><time class="post-date" datetime="2018-09-24">24 Sep 2018</time></span>           
                
                </small>
            </p>

            <!-- Post Categories -->
            <div class="after-post-cats">
                <ul class="tags mb-4">
                    
                    
                    <li>
                        <a class="smoothscroll" href="/categories#Python">Python</a>
                    </li>
                    
                </ul>
            </div>
            <!-- End Categories -->

            <!-- Post Tags -->
            <div class="after-post-tags">
                <ul class="tags">
                    
                    
                </ul>
            </div>
            <!-- End Tags -->

            <!-- Prev/Next -->
            <div class="row PageNavigation d-flex justify-content-between font-weight-bold">
            
            <a class="prev d-block col-md-6" href="//Connect-DataBases-with-Python/"> &laquo; Python and Databases(Mysql, Redia, MongoDB) Basic</a>
            
            
            <a class="next d-block col-md-6 text-lg-right" href="//Flask-framework-for-Python/">Flask Framework for Python &raquo; </a>
            
            <div class="clearfix"></div>
            </div>
            <!-- End Categories -->

        </div>
        <!-- End Post -->

    </div>
</div>
<!-- End Article
================================================== -->

<!-- Begin Comments
================================================== -->

    <div class="container">
        <div id="comments" class="row justify-content-center mb-5">
            <div class="col-md-8">
                <section class="disqus">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        var disqus_shortname = 'demowebsite'; 
        var disqus_developer = 0;
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = window.location.protocol + '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>

            </div>
        </div>
    </div>

<!--End Comments
================================================== -->

<!-- Review with LD-JSON, adapt it for your needs if you like, but make sure you test the generated HTML source code first: 
https://search.google.com/structured-data/testing-tool/u/0/
================================================== -->

<script type="application/ld+json">
{
  "@context": "http://schema.org/",
  "@type": "Review",
  "itemReviewed": {
    "@type": "Thing",
    "name": "Python Crowler In Action"
  },
  "author": {
    "@type": "Person",
    "name": "Dalong"
  },
  "datePublished": "2018-09-24",
  "reviewRating": {
    "@type": "Rating",
    "ratingValue": "4.5",
    "bestRating": "5"
  }
}
</script>

</div>


    
</div>

<!-- Categories Jumbotron
================================================== -->
<div class="jumbotron fortags">
	<div class="d-md-flex h-100">
		<div class="col-md-4 transpdark align-self-center text-center h-100">
            <div class="d-md-flex align-items-center justify-content-center h-100">
                <h2 class="d-md-block align-self-center py-1 font-weight-light">Explore <span class="d-none d-md-inline">→</span></h2>
            </div>
		</div>
		<div class="col-md-8 p-5 align-self-center text-center">
            
            
                
                    <a class="mt-1 mb-1" href="/categories#Linux">Linux (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Python">Python (16)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Mysql">Mysql (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Redis">Redis (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#MongoDB">MongoDB (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Flask">Flask (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Django">Django (2)</a>
                
                    <a class="mt-1 mb-1" href="/categories#DjangoRest">DjangoRest (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Numpy">Numpy (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Panda">Panda (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Sklearn">Sklearn (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Jupyter">Jupyter (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#OpenCV">OpenCV (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#AI">AI (3)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Tensorflow">Tensorflow (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Microservice">Microservice (2)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Docker">Docker (3)</a>
                
                    <a class="mt-1 mb-1" href="/categories#NLP">NLP (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#AWS">AWS (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Architecture">Architecture (2)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Agile">Agile (2)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Scrum">Scrum (2)</a>
                
                    <a class="mt-1 mb-1" href="/categories#MLPS">MLPS (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#PIPL">PIPL (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Metaverse">Metaverse (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Togaf">Togaf (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#ChatGPT">ChatGPT (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#OpenAI">OpenAI (2)</a>
                
                    <a class="mt-1 mb-1" href="/categories#LLM">LLM (2)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Azure">Azure (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Data-Science">Data Science (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#ITIL">ITIL (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#IT">IT (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Jekyll">Jekyll (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Github">Github (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Liquid">Liquid (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Markdown">Markdown (1)</a>
                
            
            
		</div>
	</div>
</div>

<!-- Begin Footer
================================================== -->
<footer class="footer">
    <div class="container">
        <div class="row">
            <div class="col-md-6 col-sm-6 text-center text-lg-left">
                Copyright © 2023 Dalong's personal blog 
            </div>
            <div class="col-md-6 col-sm-6 text-center text-lg-right">    
                <a target="_blank" href="#">Designed</a> by Dalong.work
            </div>
        </div>
    </div>
</footer>
<!-- End Footer
================================================== -->

</div> <!-- /.site-content -->

<!-- Scripts
================================================== -->

<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script>

<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js" integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k" crossorigin="anonymous"></script>

<script src="/assets/js/mediumish.js"></script>



<script src="/assets/js/ie10-viewport-bug-workaround.js"></script> 


<script id="dsq-count-scr" src="//demowebsite.disqus.com/count.js"></script>


</body>
</html>
