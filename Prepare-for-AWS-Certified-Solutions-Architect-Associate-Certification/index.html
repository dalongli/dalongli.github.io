<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<link rel="icon" href="/assets/images/logo.png">

<title>Step by Step for AWS Certified Solutions Architect Associate | Dalong's personal blog</title>

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Step by Step for AWS Certified Solutions Architect Associate | Dalong’s personal blog</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="Step by Step for AWS Certified Solutions Architect Associate" />
<meta name="author" content="Dalong" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="想要快速了解 AWS 服务的最好方法就是去获得相关的证书. AWS 提供了各个方面的证书可以方便我们掌握提供不同方向的技能与服务能力, 包括 账户管理, 网络, 安全, 计算, 存储, 数据管理, 灾备迁移等. 我在本文中将把我自己获取 AWS Certified Solutions Architect Associate 证书过程中所积累的经验分享给大家, 让我们开始吧" />
<meta property="og:description" content="想要快速了解 AWS 服务的最好方法就是去获得相关的证书. AWS 提供了各个方面的证书可以方便我们掌握提供不同方向的技能与服务能力, 包括 账户管理, 网络, 安全, 计算, 存储, 数据管理, 灾备迁移等. 我在本文中将把我自己获取 AWS Certified Solutions Architect Associate 证书过程中所积累的经验分享给大家, 让我们开始吧" />
<link rel="canonical" href="http://localhost:4000/Prepare-for-AWS-Certified-Solutions-Architect-Associate-Certification/" />
<meta property="og:url" content="http://localhost:4000/Prepare-for-AWS-Certified-Solutions-Architect-Associate-Certification/" />
<meta property="og:site_name" content="Dalong’s personal blog" />
<meta property="og:image" content="http://localhost:4000/assets/images/awssaa.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-04-23T00:00:00+08:00" />
<script type="application/ld+json">
{"@type":"BlogPosting","headline":"Step by Step for AWS Certified Solutions Architect Associate","dateModified":"2022-04-23T00:00:00+08:00","datePublished":"2022-04-23T00:00:00+08:00","description":"想要快速了解 AWS 服务的最好方法就是去获得相关的证书. AWS 提供了各个方面的证书可以方便我们掌握提供不同方向的技能与服务能力, 包括 账户管理, 网络, 安全, 计算, 存储, 数据管理, 灾备迁移等. 我在本文中将把我自己获取 AWS Certified Solutions Architect Associate 证书过程中所积累的经验分享给大家, 让我们开始吧","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/assets/images/logo.png"},"name":"Dalong"},"image":"http://localhost:4000/assets/images/awssaa.jpg","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/Prepare-for-AWS-Certified-Solutions-Architect-Associate-Certification/"},"url":"http://localhost:4000/Prepare-for-AWS-Certified-Solutions-Architect-Associate-Certification/","author":{"@type":"Person","name":"Dalong"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
    
<link href="/assets/css/screen.css" rel="stylesheet">

<link href="/assets/css/main.css" rel="stylesheet">

<script src="/assets/js/jquery.min.js"></script>

</head>




<body class="layout-post">
	<!-- defer loading of font and font awesome -->
	<noscript id="deferred-styles">
		<link href="https://fonts.googleapis.com/css?family=Righteous%7CMerriweather:300,300i,400,400i,700,700i" rel="stylesheet">
		<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">
        <link rel="preconnect" href="https://fonts.googleapis.com"> 
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> 
        <link href="https://fonts.googleapis.com/css2?family=Carter+One&display=swap" rel="stylesheet">
    </noscript>


<!-- Begin Menu Navigation
================================================== -->
<nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top mediumnavigation nav-down">

    <div class="container pr-0">

    <!-- Begin Logo -->
    <a class="navbar-brand" href="/">
    <img src="/assets/images/logo.png" alt="Dalong's personal blog">
    </a>
    <!-- End Logo -->

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarMediumish" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarMediumish">

        <!-- Begin Menu -->

            <ul class="navbar-nav ml-auto">

                
                <li class="nav-item">
                
                <a class="nav-link" href="/index.html">Blog</a>
                </li>

                <li class="nav-item">
                <a class="nav-link" href="/about">About</a>
                </li>

<!-- 以后再加上相关链接

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://bootstrapstarter.com/bootstrap-templates/template-mediumish-bootstrap-jekyll/"> Docs</a>
                </li>

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://www.wowthemes.net/themes/mediumish-wordpress/"><i class="fab fa-wordpress-simple"></i> WP Version</a>
                </li>

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://www.wowthemes.net/themes/mediumish-ghost/"><i class="fab fa-snapchat-ghost"></i> Ghost Version</a>
                </li>
-->
                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://github.com/dalongli"><i class="fab fa-github"></i> Fork on Github</a>
                </li>

                <script src="/assets/js/lunr.js"></script>


<style>
    .lunrsearchresult .title {color: #d9230f;}
    .lunrsearchresult .url {color: silver;}
    .lunrsearchresult a {display: block; color: #777;}
    .lunrsearchresult a:hover, .lunrsearchresult a:focus {text-decoration: none;}
    .lunrsearchresult a:hover .title {text-decoration: underline;}
</style>


<form class="bd-search" onSubmit="return lunr_search(document.getElementById('lunrsearch').value);">
    <input type="text" class="form-control text-small launch-modal-search" id="lunrsearch" name="q" maxlength="255" value="" placeholder="Type and enter..."/>
</form>

<div id="lunrsearchresults">
    <ul></ul>
</div>

<script src="/assets/js/lunrsearchengine.js"></script>

            </ul>

        <!-- End Menu -->

    </div>

    </div>
</nav>
<!-- End Navigation
================================================== -->

<div class="site-content">

<div class="container">

<!-- Site Title
================================================== -->
<div class="mainheading">
    <h1 class="sitetitle">Dalong's personal blog</h1>
    <p class="lead">
        Record the bits and pieces of the technology big bang.
    </p>
</div>

<!-- Content
================================================== -->
<div class="main-content">
    <!-- Begin Article
================================================== -->
<div class="container">
    <div class="row">

        <!-- Post Share -->
        <div class="col-md-2 pl-0">
            <div class="share sticky-top sticky-top-offset">
    <p>
        Share
    </p>
    <ul>
        <li class="ml-1 mr-1">
            <a target="_blank" href="https://twitter.com/intent/tweet?text=Step by Step for AWS Certified Solutions Architect Associate&url=http://localhost:4000/Prepare-for-AWS-Certified-Solutions-Architect-Associate-Certification/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                <i class="fab fa-twitter"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://facebook.com/sharer.php?u=http://localhost:4000/Prepare-for-AWS-Certified-Solutions-Architect-Associate-Certification/" onclick="window.open(this.href, 'facebook-share', 'width=550,height=435');return false;">
                <i class="fab fa-facebook-f"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/Prepare-for-AWS-Certified-Solutions-Architect-Associate-Certification/" onclick="window.open(this.href, 'width=550,height=435');return false;">
                <i class="fab fa-linkedin-in"></i>
            </a>
        </li>

    </ul>
    
    <div class="sep">
    </div>
    <ul>
        <li>
        <a class="small smoothscroll" href="#disqus_thread"></a>
        </li>
    </ul>
    
</div>

        </div>

        <!-- Post -->
        

        <div class="col-md-9 flex-first flex-md-unordered">
            <div class="mainheading">

                <!-- Author Box -->
                
                <div class="row post-top-meta">
                    <div class="col-xs-12 col-md-3 col-lg-2 text-center text-md-left mb-4 mb-md-0">
                        
                        <img class="author-thumb" src="/assets/images/avatar_dl.png" alt="Dalong">
                        
                    </div>
                    <div class="col-xs-12 col-md-9 col-lg-10 text-center text-md-left">
                        <a target="_blank" class="link-dark" href="https://dalongli.github.io/about">Dalong</a><a target="_blank" href="https://dalongli.github.io." class="btn follow">Follow</a>
                        <span class="author-description">A profesional technical consultant and blogger.</span>
                    </div>
                </div>
                

                <!-- Post Title -->
                <h1 class="posttitle">Step by Step for AWS Certified Solutions Architect Associate</h1>

            </div>

            <!-- Adsense if enabled from _config.yml (change your pub id and slot) -->
            
            <!-- End Adsense -->

            <!-- Post Featured Image -->
            

            
            <img class="featured-image img-fluid" src="/assets/images/awssaa.jpg" alt="Step by Step for AWS Certified Solutions Architect Associate">
            

            
            <!-- End Featured Image -->

            <!-- Post Content -->
            <div class="article-post">
                <!-- Toc if any -->
                
                    
                    <div class="toc mt-4 mb-4 lead">
                        <h3 class="font-weight-bold">Summary</h3>
                        <ul>
  <li><a href="#aws-certified-solutions-architect-associate">AWS Certified Solutions Architect Associate</a>
    <ul>
      <li><a href="#well-architected-framework">Well-Architected Framework</a>
        <ul>
          <li><a href="#5个支柱">5个支柱</a>
            <ul>
              <li><a href="#卓越运营">卓越运营</a></li>
              <li><a href="#安全性">安全性</a></li>
              <li><a href="#可靠性">可靠性</a></li>
              <li><a href="#性能效率">性能效率</a></li>
              <li><a href="#成本优化">成本优化</a></li>
            </ul>
          </li>
          <li><a href="#几个定义">几个定义</a>
            <ul>
              <li><a href="#availability">Availability</a></li>
              <li><a href="#high-availability">High Availability</a></li>
              <li><a href="#fault-tolerance">Fault Tolerance</a></li>
              <li><a href="#几个例子">几个例子</a></li>
              <li><a href="#redundant">Redundant</a></li>
              <li><a href="#durability">Durability</a></li>
              <li><a href="#resilience">Resilience</a></li>
              <li><a href="#scalability">Scalability</a></li>
              <li><a href="#elasticity">Elasticity</a></li>
            </ul>
          </li>
          <li><a href="#sla">SLA</a></li>
          <li><a href="#aws-service-scope">AWS Service Scope</a>
            <ul>
              <li><a href="#az-scope">AZ Scope</a></li>
              <li><a href="#region-scope">Region Scope</a></li>
              <li><a href="#multi-region-scope">Multi-Region Scope</a></li>
              <li><a href="#edge-location">Edge Location</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#几个数字">几个数字</a>
        <ul>
          <li><a href="#传输率">传输率</a></li>
        </ul>
      </li>
      <li><a href="#账户管理">账户管理</a>
        <ul>
          <li><a href="#iam">IAM</a>
            <ul>
              <li><a href="#iam-1">IAM</a></li>
              <li><a href="#sts---security-token-service">STS - Security Token Service</a></li>
              <li><a href="#identity-federation">Identity Federation</a></li>
              <li><a href="#custom-identity-broker-application">Custom Identity Broker Application</a></li>
              <li><a href="#cognito">Cognito</a></li>
              <li><a href="#aws-directory-service">AWS Directory Service</a></li>
              <li><a href="#root-用户可以做-但是-administratoraccess-不能做的事情">Root 用户可以做， 但是 AdministratorAccess 不能做的事情：</a></li>
            </ul>
          </li>
          <li><a href="#org">Org</a>
            <ul>
              <li><a href="#organization">Organization</a></li>
              <li><a href="#在组织之间迁移账户">在组织之间迁移账户</a></li>
            </ul>
          </li>
          <li><a href="#ram">RAM</a>
            <ul>
              <li><a href="#resource-access-manager-ram">Resource Access manager (RAM)</a></li>
              <li><a href="#vpc-sharing-shared-service-vpc">VPC Sharing (<strong>Shared service VPC</strong>)</a></li>
            </ul>
          </li>
          <li><a href="#sso">SSO</a>
            <ul>
              <li><a href="#aws-single-sign-on">AWS Single Sign-on</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#网络边缘">网络边缘</a>
        <ul>
          <li><a href="#route53">Route53</a>
            <ul>
              <li><a href="#dns-概念">DNS 概念</a></li>
              <li><a href="#route-53">Route 53</a></li>
              <li><a href="#通过driect-connection-连接的on-premise-和-aws-vpc-之间互相之间解析dns-的方法">通过Driect Connection 连接的on-premise 和 AWS VPC 之间互相之间解析DNS 的方法</a></li>
              <li><a href="#希望route-53-可以在网站不可用的情况下跳到一个静态错误页面-需要的最简单可以实现的方案是">希望Route 53 可以在网站不可用的情况下跳到一个静态错误页面， 需要的最简单可以实现的方案是：</a></li>
            </ul>
          </li>
          <li><a href="#cloudfront">CloudFront</a>
            <ul>
              <li><a href="#cloudfront-1">CloudFront</a></li>
              <li><a href="#cloudfront-price-classes">CloudFront Price Classes</a></li>
              <li><a href="#cloudfront-和-global-accelerator的区别">CloudFront 和 Global Accelerator的区别</a></li>
              <li><a href="#cloudfront-和-s3-transfer-accelerator-的区别">CloudFront 和 S3 Transfer Accelerator 的区别</a></li>
              <li><a href="#cloudfront-和-vod-live-streaming-video">CloudFront 和 VOD, Live streaming video</a></li>
              <li><a href="#错题总结---cloudfront-的正确描述">错题总结 - Cloudfront 的正确描述：</a></li>
            </ul>
          </li>
          <li><a href="#aws-global-accelerator">AWS Global Accelerator</a>
            <ul>
              <li><a href="#aws-global-accelerator-1">AWS Global Accelerator</a></li>
              <li><a href="#cloudfront-和-global-accelerator的区别-1">CloudFront 和 Global Accelerator的区别</a></li>
              <li><a href="#案例">案例：</a></li>
            </ul>
          </li>
          <li><a href="#snow-family">Snow Family</a>
            <ul>
              <li><a href="#snow-family-1">Snow Family</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#网络">网络</a>
        <ul>
          <li><a href="#vpc">VPC</a>
            <ul>
              <li><a href="#vpc---virtual-private-cloud">VPC - Virtual Private Cloud</a></li>
              <li><a href="#vpc中需要付费的网络设备">VPC中需要付费的网络设备：</a></li>
              <li><a href="#vpc--regional-网络间的付费">VPC  regional 网络间的付费</a></li>
              <li><a href="#vpc-security-group">VPC security group</a></li>
              <li><a href="#cidr">CIDR</a></li>
              <li><a href="#subnet">subnet</a></li>
              <li><a href="#internet-gateway-igw">Internet Gateway (IGW)</a></li>
              <li><a href="#bastion-hosts-堡垒机">Bastion Hosts 堡垒机</a></li>
              <li><a href="#nat-instance---network-address-translation-这个过时了-nat-gateway-是代替者">NAT Instance - network address translation （这个过时了， NAT Gateway 是代替者）</a></li>
              <li><a href="#nat-gateway---natgw-老师上课讲的是这个">NAT Gateway - NATGW (老师上课讲的是这个)</a></li>
              <li><a href="#vpc中的dns解析">VPC中的DNS解析</a></li>
              <li><a href="#nacl-和-security-group">NACL 和 Security Group</a></li>
              <li><a href="#nacl-和-ephemeral-ports">NACL 和 Ephemeral Ports</a></li>
              <li><a href="#vpc-reachability-analyzer">VPC Reachability Analyzer</a></li>
              <li><a href="#vpc-peering">VPC Peering</a></li>
              <li><a href="#vpc-endpoints">VPC Endpoints</a></li>
              <li><a href="#vpc-flow-logs">VPC Flow Logs</a></li>
              <li><a href="#site-to-site-vpn">Site-to-Site VPN</a></li>
              <li><a href="#vpn-cloudhub">VPN CloudHub</a></li>
              <li><a href="#vpc-连-vpc-endpoint-service-">VPC 连 VPC (Endpoint Service )</a></li>
              <li><a href="#transit-gateway-交通枢纽-gateway">Transit Gateway 交通枢纽 Gateway</a></li>
              <li><a href="#vpc-traffic-mirroring-流量镜像">VPC Traffic Mirroring 流量镜像</a></li>
              <li><a href="#ipv6-in-vpc">IPV6 in VPC</a></li>
              <li><a href="#egress-only-internet-gateway-eigw">Egress-Only Internet Gateway （EIGW）</a></li>
              <li><a href="#vpc-console-wizard-支持的内容">VPC Console Wizard 支持的内容</a></li>
            </ul>
          </li>
          <li><a href="#elb">ELB</a>
            <ul>
              <li><a href="#elb-1">ELB</a></li>
              <li><a href="#target-group">target group</a></li>
              <li><a href="#sni-server-name-indication">SNI Server Name Indication</a></li>
              <li><a href="#connection-draining-deregistration-delay">Connection Draining (Deregistration Delay)</a></li>
              <li><a href="#asg-auto-scaling-group">ASG auto scaling group</a></li>
              <li><a href="#一个实例有问题但是没有被asg-terminate-掉的可能性">一个实例有问题，但是没有被ASG terminate 掉的可能性</a></li>
              <li><a href="#一个实例有问题alb-删了她但是asg-没有换一个新的上来的问题">一个实例有问题，ALB 删了她，但是ASG 没有换一个新的上来的问题：</a></li>
            </ul>
          </li>
          <li><a href="#direct-connect-dx">Direct Connect (DX)</a>
            <ul>
              <li><a href="#direct-connection-dx">Direct Connection (DX)</a></li>
              <li><a href="#direct-connect-gateway">Direct Connect Gateway</a></li>
            </ul>
          </li>
          <li><a href="#网络成本-xxx每gb">网络成本 （xxx$/每GB）</a></li>
        </ul>
      </li>
      <li><a href="#监控">监控</a>
        <ul>
          <li><a href="#cloudwatch">CloudWatch</a>
            <ul>
              <li><a href="#cloudwatch-1">CloudWatch</a></li>
              <li><a href="#cloudwatch-alarm">CloudWatch Alarm</a></li>
              <li><a href="#cloudwatch-event">CloudWatch Event</a></li>
            </ul>
          </li>
          <li><a href="#eventbridge">EventBridge</a>
            <ul>
              <li><a href="#eventbridge-1">EventBridge</a></li>
            </ul>
          </li>
          <li><a href="#cloudtrail">CloudTrail</a>
            <ul>
              <li><a href="#cloudtrail-1">CloudTrail</a></li>
              <li><a href="#cloudtrail-events">CloudTrail Events</a></li>
            </ul>
          </li>
          <li><a href="#aws-config">AWS Config</a>
            <ul>
              <li><a href="#aws-config-1">AWS Config</a></li>
              <li><a href="#cloudwatch-cloudtrail-config-的区别">CloudWatch, CloudTrail, Config 的区别</a></li>
            </ul>
          </li>
          <li><a href="#x-ray">X-Ray</a>
            <ul>
              <li><a href="#x-ray-x光">X-ray X光</a></li>
              <li><a href="#cloudtrail-cloudwatch-vpc-log-aws-config-x-ray-的区别">CloudTrail, CloudWatch, VPC Log, AWS Config, X-Ray 的区别</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#安全">安全</a>
        <ul>
          <li><a href="#kms">KMS</a>
            <ul>
              <li><a href="#kms-1">KMS</a></li>
              <li><a href="#kms-key-policy">KMS Key Policy</a></li>
              <li><a href="#kms-automatic-key-rotation">KMS Automatic Key Rotation</a></li>
              <li><a href="#分享encrypted-内容给其他account">分享Encrypted 内容给其他account</a></li>
            </ul>
          </li>
          <li><a href="#ssm-parameter-store">SSM Parameter Store</a>
            <ul>
              <li><a href="#ssm-parameter-store-1">SSM Parameter Store</a></li>
            </ul>
          </li>
          <li><a href="#secrets-manager">Secrets Manager</a>
            <ul>
              <li><a href="#secrets-manager-1">Secrets Manager</a></li>
            </ul>
          </li>
          <li><a href="#cloudhsm">CloudHSM</a>
            <ul>
              <li><a href="#cloudhsm---hardware-security-module">CloudHSM - Hardware Security Module</a></li>
            </ul>
          </li>
          <li><a href="#firewall-manager">Firewall Manager</a>
            <ul>
              <li><a href="#firewall-manager-1">Firewall Manager</a></li>
              <li><a href="#waf-shield-security-group-firewall-manager-的总结">WAF, Shield, Security Group, Firewall Manager 的总结</a></li>
            </ul>
          </li>
          <li><a href="#aws-shield">AWS Shield</a>
            <ul>
              <li><a href="#aws-shield-1">AWS Shield</a></li>
            </ul>
          </li>
          <li><a href="#waf">WAF</a>
            <ul>
              <li><a href="#aws-waf---web-application-firewall">AWS WAF - Web Application Firewall</a></li>
              <li><a href="#关于允许或者不允许某些国家的访问">关于允许或者不允许某些国家的访问</a></li>
              <li><a href="#关于block-一个国家但又需要允许这个国家的一个ip的访问">关于block 一个国家，但又需要允许这个国家的一个IP的访问</a></li>
            </ul>
          </li>
          <li><a href="#guardduty">GuardDuty</a>
            <ul>
              <li><a href="#guardduty---人工智能保安">GuardDuty - 人工智能保安</a></li>
            </ul>
          </li>
          <li><a href="#inspector">Inspector</a>
            <ul>
              <li><a href="#inspector-1">Inspector</a></li>
            </ul>
          </li>
          <li><a href="#macie">Macie</a>
            <ul>
              <li><a href="#macie-1">Macie</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#信息流">信息流</a>
        <ul>
          <li><a href="#sns">SNS</a>
            <ul>
              <li><a href="#sns-1">SNS</a></li>
              <li><a href="#fan-out-模式">fan out 模式</a></li>
            </ul>
          </li>
          <li><a href="#sqs">SQS</a>
            <ul>
              <li><a href="#sqs-1">SQS</a></li>
              <li><a href="#dead-letter-queue">Dead Letter Queue</a></li>
              <li><a href="#message-timer-message-level">Message timer (message level)</a></li>
              <li><a href="#delay-queue-producer-触发-queue-level">Delay Queue （producer 触发） (queue level)</a></li>
              <li><a href="#sqs-有-shot-polling-和-long-polling">SQS 有 shot polling 和 long polling.</a></li>
              <li><a href="#long-polling-consumer-触发">Long Polling （consumer 触发）</a></li>
              <li><a href="#sqs-temporary-queue">SQS Temporary Queue</a></li>
              <li><a href="#sqs-与-asg-的设计模式">SQS 与 ASG 的设计模式</a></li>
              <li><a href="#上游和下游个数需要匹配">上游和下游个数需要匹配</a></li>
            </ul>
          </li>
          <li><a href="#kinesis">Kinesis</a>
            <ul>
              <li><a href="#kinesis-1">Kinesis</a></li>
              <li><a href="#kinesis-data-stream">Kinesis Data Stream</a></li>
              <li><a href="#kinesis-enhanced-fan-out">Kinesis Enhanced Fan Out</a></li>
              <li><a href="#kinesis-data-firehose">Kinesis Data Firehose</a></li>
              <li><a href="#kinesis-data-streams-vs-firehose-的区别">Kinesis Data Streams vs Firehose 的区别</a></li>
              <li><a href="#kinesis-data-stream-和-sqs-的区别">Kinesis Data Stream 和 SQS 的区别</a></li>
              <li><a href="#cloudwatch-订阅过滤器-与-kinesis">Cloudwatch 订阅过滤器 与 Kinesis</a></li>
              <li><a href="#kinesis-data-analytics">Kinesis Data Analytics</a></li>
              <li><a href="#kinesis-data-analytics-和-athena-的区别">Kinesis Data Analytics 和 Athena 的区别</a></li>
              <li><a href="#kinesis-中的数据的排序">kinesis 中的数据的排序</a></li>
              <li><a href="#batch-messages">Batch messages</a></li>
            </ul>
          </li>
          <li><a href="#amazon-mq">Amazon MQ</a></li>
        </ul>
      </li>
      <li><a href="#计算">计算</a>
        <ul>
          <li><a href="#beanstalk">Beanstalk</a></li>
          <li><a href="#ec2">EC2</a>
            <ul>
              <li><a href="#ec2-1">EC2</a></li>
              <li><a href="#placement-group">placement group</a></li>
              <li><a href="#eni">ENI</a></li>
              <li><a href="#elastic-ip">Elastic IP</a></li>
              <li><a href="#ec2-instance-hibernate">ec2 instance hibernate</a></li>
              <li><a href="#ebs">EBS</a></li>
              <li><a href="#ec2-instance-store">EC2 instance store</a></li>
              <li><a href="#ami">AMI</a></li>
              <li><a href="#ec2-metadata">EC2 Metadata</a></li>
              <li><a href="#ec2-instance-auto-recovery">EC2 Instance Auto Recovery</a></li>
              <li><a href="#ec2-enhanced-networking-sr-iov">EC2 Enhanced Networking (SR-IOV)</a></li>
              <li><a href="#elastic-fabric-adapter-efa">Elastic Fabric Adapter (EFA)</a></li>
              <li><a href="#spot-fleet">Spot Fleet</a></li>
              <li><a href="#spot-有两种类型">spot 有两种类型</a></li>
              <li><a href="#spot-instance-spot-blocks-spot-fleets-的区别">Spot instance, Spot blocks, Spot Fleets 的区别</a></li>
              <li><a href="#ec2-实例的tenancy">EC2 实例的tenancy</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#容器">容器</a>
        <ul>
          <li><a href="#ecr">ECR</a></li>
          <li><a href="#aws-fargate">AWS Fargate</a></li>
          <li><a href="#ecs">ECS</a>
            <ul>
              <li><a href="#ecs-1">ECS</a></li>
              <li><a href="#ecs-和-alb">ECS 和 ALB</a></li>
              <li><a href="#ecs-和-aws-event-bridge">ECS 和 AWS Event Bridge</a></li>
              <li><a href="#ecs-scaling">ECS Scaling</a></li>
              <li><a href="#ecs-rolling-update">ECS Rolling Update</a></li>
              <li><a href="#ecs-访问-s3-的权限">ECS 访问 S3 的权限</a></li>
            </ul>
          </li>
          <li><a href="#eks">EKS</a></li>
        </ul>
      </li>
      <li><a href="#存储">存储</a>
        <ul>
          <li><a href="#s3">S3</a>
            <ul>
              <li><a href="#s3-1">S3</a></li>
              <li><a href="#s3-storage-classes">S3 Storage Classes</a></li>
              <li><a href="#s3-performance">S3 Performance</a></li>
              <li><a href="#s3-event-notification">S3 Event Notification</a></li>
              <li><a href="#文件锁-两种">文件锁， 两种</a></li>
              <li><a href="#s3-storage-gateway">S3 Storage Gateway</a></li>
              <li><a href="#s3-bucket-policy">S3 Bucket Policy</a></li>
              <li><a href="#s3-sync">S3 Sync</a></li>
              <li><a href="#s3-bucket-object-retention-文件的保留时间">S3 Bucket Object Retention (文件的保留时间)</a></li>
              <li><a href="#s3-的-consistent-一致性">S3 的 consistent （一致性）</a></li>
            </ul>
          </li>
          <li><a href="#efs">EFS</a>
            <ul>
              <li><a href="#efs-1">EFS</a></li>
              <li><a href="#efs-ia-infrequent-access">EFS IA (Infrequent Access)</a></li>
              <li><a href="#efs-ebs-s3-的价格对比">EFS, EBS, S3 的价格对比</a></li>
              <li><a href="#efs-performance-modes">EFS performance modes</a></li>
            </ul>
          </li>
          <li><a href="#fsx">FSx</a>
            <ul>
              <li><a href="#fsx-1">FSX</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#数据库">数据库</a>
        <ul>
          <li><a href="#elasticache">ElastiCache</a>
            <ul>
              <li><a href="#elasticash">ElastiCash</a></li>
              <li><a href="#elasticache-strategy">ElastiCache Strategy</a></li>
              <li><a href="#elasticache-cluster-mode">ElastiCache Cluster Mode</a></li>
            </ul>
          </li>
          <li><a href="#rds">RDS</a>
            <ul>
              <li><a href="#rds-1">RDS</a></li>
              <li><a href="#aurora">Aurora</a></li>
              <li><a href="#数据库端口">数据库端口</a></li>
              <li><a href="#应用程序访问rds-需要的临时认证权限">应用程序访问RDS 需要的临时认证权限</a></li>
            </ul>
          </li>
          <li><a href="#neptune">Neptune</a></li>
          <li><a href="#athena">Athena</a></li>
          <li><a href="#redshift">RedShift</a>
            <ul>
              <li><a href="#redshift-1">Redshift</a></li>
              <li><a href="#redshift-spectrum">Redshift Spectrum</a></li>
              <li><a href="#redshift-durability">Redshift durability</a></li>
              <li><a href="#redshift-enhanced-vpc-routing">Redshift Enhanced VPC Routing</a></li>
              <li><a href="#redshift-和-athena-的比较">Redshift 和 Athena 的比较</a></li>
            </ul>
          </li>
          <li><a href="#glue">Glue</a></li>
          <li><a href="#elasticsearchopensearch">ElasticSearch/OpenSearch</a></li>
        </ul>
      </li>
      <li><a href="#灾备和迁移">灾备和迁移</a>
        <ul>
          <li><a href="#灾备回复策略">灾备回复策略</a>
            <ul>
              <li><a href="#备份策略">备份策略</a></li>
              <li><a href="#rto--rpo">RTO &amp; RPO</a></li>
              <li><a href="#灾难发生后如何快速恢复">灾难发生后如何快速恢复</a></li>
            </ul>
          </li>
          <li><a href="#dms---data-migration-service">DMS - Data Migration Service</a></li>
          <li><a href="#sms---server-migration-service">SMS - Server Migration Service</a></li>
          <li><a href="#datasync">DataSync</a>
            <ul>
              <li><a href="#datasync-1">DataSync</a></li>
              <li><a href="#迁移大量数据的计算">迁移大量数据的计算</a></li>
            </ul>
          </li>
          <li><a href="#aws-backup">AWS Backup</a>
            <ul>
              <li><a href="#aws-backup-1">AWS Backup</a></li>
              <li><a href="#backup-plan--可以在不同维度设置backup-plan-的-policy">Backup Plan , 可以在不同维度设置backup plan 的 policy</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#无服务">无服务</a>
        <ul>
          <li><a href="#aws-cognito">AWS Cognito</a>
            <ul>
              <li><a href="#aws-cognito-1">AWS Cognito</a></li>
            </ul>
          </li>
          <li><a href="#api-gateway">API Gateway</a>
            <ul>
              <li><a href="#api-gateway-1">API Gateway</a></li>
              <li><a href="#三种方法来部署api-gateway---endpoint-type">三种方法来部署API Gateway - Endpoint type</a></li>
            </ul>
          </li>
          <li><a href="#lambda">Lambda</a>
            <ul>
              <li><a href="#lambda-1">Lambda</a></li>
              <li><a href="#lambda-edge">Lambda Edge</a></li>
              <li><a href="#lambda-最佳实践">Lambda 最佳实践</a></li>
              <li><a href="#lambda-runtime-支持的开发语言">Lambda runtime 支持的开发语言</a></li>
              <li><a href="#lambda-access-policy">Lambda access policy</a></li>
            </ul>
          </li>
          <li><a href="#dynamodb">DynamoDB</a>
            <ul>
              <li><a href="#dynamodb-1">DynamoDB</a></li>
              <li><a href="#dynamodb-pricing--readwrite-capacity-mode">DynamoDB pricing , Read/Write Capacity Mode</a></li>
              <li><a href="#dynamodb-accelerator-dax">DynamoDB Accelerator (DAX)</a></li>
              <li><a href="#dynamodb-streams">DynamoDB Streams</a></li>
              <li><a href="#dynamodb-global-tables">DynamoDB Global Tables</a></li>
              <li><a href="#dynamodb---ttl">DynamoDB - TTL</a></li>
              <li><a href="#dynamodb---transactions-事务">DynamoDB - Transactions （事务）</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#特色服务">特色服务</a>
        <ul>
          <li><a href="#cloudformation">CloudFormation</a>
            <ul>
              <li><a href="#cloudformation-1">CloudFormation</a></li>
              <li><a href="#cloudformation与beanstalk区别">CloudFormation与BeanStalk区别</a></li>
            </ul>
          </li>
          <li><a href="#step-function">Step Function</a></li>
          <li><a href="#swf---simple-workflow-service">SWF - Simple Workflow Service</a></li>
          <li><a href="#emr---elastic-map-reduce">EMR - Elastic Map Reduce</a></li>
          <li><a href="#opswork">OpsWork</a></li>
          <li><a href="#workspaces">WorkSpaces</a></li>
          <li><a href="#appsync">AppSync</a></li>
          <li><a href="#cost-explorer">Cost Explorer</a></li>
          <li><a href="#cicd">CICD</a>
            <ul>
              <li><a href="#cicd-1">CICD</a></li>
              <li><a href="#codedeploy">CodeDeploy</a></li>
            </ul>
          </li>
          <li><a href="#compute-optimizer">Compute optimizer</a></li>
          <li><a href="#trusted-advisor---可信的顾问">Trusted Advisor - 可信的顾问</a></li>
          <li><a href="#几个-advisor-的比较">几个 advisor 的比较</a>
            <ul>
              <li><a href="#trusted-advisor-account-level">Trusted Advisor (account level)</a></li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
                    </div>
                
                <!-- End Toc -->
                <p>想要快速了解 AWS 服务的最好方法就是去获得相关的证书. AWS 提供了各个方面的证书可以方便我们掌握提供不同方向的技能与服务能力, 包括 账户管理, 网络, 安全, 计算, 存储, 数据管理, 灾备迁移等. 我在本文中将把我自己获取 AWS Certified Solutions Architect Associate 证书过程中所积累的经验分享给大家, 让我们开始吧</p>

<h1 id="aws-certified-solutions-architect-associate">AWS Certified Solutions Architect Associate</h1>

<p>[TOC]</p>

<h2 id="well-architected-framework">Well-Architected Framework</h2>

<h3 id="5个支柱">5个支柱</h3>

<h4 id="卓越运营">卓越运营</h4>

<ul>
  <li>设计原则
    <ul>
      <li>执行运营即代码:在云中，您可以将用于应用程序代码的工程规范应用于整个环境。您可以将整个工作负 载(应用程序、基础设施)定义为代码，并使用该代码进行更新。您可以将运营流程写成代码(脚本)， 并通过事件触发来自动执行这些脚本。通过以代码形式执行操作，您可以减少人为错误并实现对事件的一 致响应。</li>
      <li>频繁进行可逆的小规模更改:将工作负载设计为支持组件定期更新。以较小增量进行失败时可逆的更改 (尽可能不影响客户)。</li>
      <li>经常优化运营流程:在使用运营程序时，要寻找机会改进它们。在改进工作负载的同时，您也要适当改进 一下流程。设置定期的实际演练，以检查并验证所有流程是否有效，以及团队是否熟悉这些流程。</li>
      <li>预测故障:执行“故障演练”，找出潜在的问题，以便消除和缓解问题。测试您的故障场景，并确认您了解 相应影响。测试您的响应流程以确保它们有效，并确保团队能够熟练执行。设置定期的实际演练，以测试 工作负载和团队对模拟事件的响应。</li>
      <li>从所有运营故障中吸取经验教训:从所有运营事件和故障中吸取的经验教训，推动改进。在多个团队乃至 组织范围中分享经验教训。</li>
    </ul>
  </li>
</ul>

<h4 id="安全性">安全性</h4>

<ul>
  <li>设计原则</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>在云中实现安全性有七个设计原则:
</pre></td></tr></tbody></table>
</div>
</div>

<ul>
  <li>
    <ul>
      <li>
        <p>健壮的身份验证体系:实施最小权限原则，并通过对每一次与 AWS 资源之间的交互进行适当授权来强制 执行职责分离。集中进行身份管理，并努力消除对长期静态凭证的依赖。</p>
      </li>
      <li>实现可追溯性:实时监控和审计对环境执行的操作和更改并发送警报。为系统集成日志和指标收集功能， 以自动调查并采取措施。</li>
      <li>在所有层面应用安全措施:利用多种安全控制措施实现深度防御。应用到所有层面(例如网络边 缘、VPC、负载均衡、每个实例和计算服务、操作系统、应用程序和代码)。</li>
      <li>自动实施安全最佳实践:借助基于软件的自动化安全机制，您能够以更为快速且更具成本效益的方式实现 安全扩展。创建安全架构，包括实施可在版本控制模板中以代码形式定义和管理的控制措施。</li>
      <li>保护动态数据和静态数据:将您的数据按敏感程度进行分类，并采用加密、令牌和访问控制等机制(如适 用)。</li>
      <li>限制对数据的访问:使用相关机制和工具来减少和消除直接访问或人工处理数据的需求。这样可以降低处 理敏感数据时数据处理不当、被修改以及人为错误的风险。</li>
      <li>做好应对安全性事件的准备:制定符合您组织要求的事件管理和调查策略和流程，做好应对事件的准备工 作。开展事件响应模拟演练并使用</li>
    </ul>
  </li>
</ul>

<h4 id="可靠性">可靠性</h4>

<ul>
  <li>设计原则</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>在云中实现可靠性有五个设计原则:
</pre></td></tr></tbody></table>
</div>
</div>

<ul>
  <li>
    <ul>
      <li>
        <p>自动从故障中恢复:通过监控工作负载的关键绩效指标 (KPI)，您可以在指标超过阈值时触发自动化功能。 这些 KPI 应该是对业务价值(而不是服务运营的技术方面)的一种度量。这包括自动发送故障通知和跟踪 故障，以及启动解决或修复故障的自动恢复流程。借助更高级的自动化功能，您可以在故障发生之前预测 和修复故障。</p>
      </li>
      <li>测试恢复过程:在本地环境中，经常会通过执行测试来证明工作负载能够在特定场景中正常运作。通常不 会利用测试来验证恢复策略。在云中，您可以测试工作负载的故障情况，并验证您的恢复程序。您可以采 用自动化方式来模拟不同的故障，也可以重新建立之前导致故障的场景。此方式可以在实际的故障发生以 前揭示您可以测试与修复的故障路径，从而降低风险。</li>
      <li>横向扩展以提高聚合工作负载的可用性:使用多个小型资源替换一个大型资源，以降低单个故障对整个工 作负载的影响。跨多个较小的资源分配请求，以确保它们不共用常见故障点。</li>
      <li>无需再预估容量:本地工作负载出现故障的常见原因是资源饱和，即对工作负载的需求超过该工作负载的 容量(这通常是拒绝服务攻击的目标)。在云中，您可以监控需求和工作负载利用率，并自动添加或删除 资源，以保持最佳水平来满足需求，而不会出现超额预置或预置不足的问题。虽然还有很多限制，但有些 配额是可控的，其他配额也可以管理(请参阅“管理Service Quotas与限制”)。</li>
      <li>管理自动化变更:应利用自动化功能对基础设施进行更改。需要管理的变更包括，对自动化的变更，可对 其进行跟踪与审查。</li>
    </ul>
  </li>
</ul>

<h4 id="性能效率">性能效率</h4>

<ul>
  <li>
    <p>设计原则</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>在云中实现性能效率包括五个方面的最佳实践:
</pre></td></tr></tbody></table>
</div>
    </div>

    <ul>
      <li>普及先进技术:通过将复杂的任务委派给云供应商，降低您的团队实施高级技术的难度。与要求您的 IT 团 队学习有关托管和运行新技术的知识相比，考虑将新技术作为服务使用是一种更好的选择。例如，NoSQL 数据库、媒体转码和机器学习都是需要专业知识才能使用的技术。在云中，这些技术会转变为团队可以使 用的服务，让团队能够专注于产品开发，而不是资源预置和管理。</li>
      <li>数分钟内实现全球化部署:您可以在全球多个 AWS 区域中部署工作负载，从而以最低的成本为客户提供 更低的延迟和更好的体验。</li>
      <li>使用无服务器架构:借助无服务器架构，您无需运行和维护物理服务器即可执行传统计算活动。例如，无 服务器存储服务可以充当静态网站(从而无需再使用 Web 服务器)，事件服务则可以实现代码托管。这 不仅能够消除管理物理服务器产生的运行负担，还可以借由以云规模运行的托管服务来降低业务成本。</li>
      <li>提升试验频率:利用虚拟和可自动化的资源，您可以快速利用各种类型的实例、存储或配置执行对比测 试。</li>
      <li>考虑软硬件协同编程:了解如何使用云服务，并始终使用最适合您工作负载目标的技术方法。例如，在选 择数据库或存储方法时考虑数据访问模式。</li>
    </ul>
  </li>
</ul>

<h4 id="成本优化">成本优化</h4>

<ul>
  <li>
    <p>设计原则</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>     在云中实现成本优化有五个设计原则:
</pre></td></tr></tbody></table>
</div>
    </div>
  </li>
  <li>
    <ul>
      <li>践行云财务管理:为获得财务上的成功并加速在云中实现业务价值，需要投资云财务管理/成本优化。您 的组织需要投入时间和资源增强自身在这个新的技术和使用情况管理领域中的能力。与安全性或卓越运营 能力类似，您的组织需要通过知识构建、计划、资源和流程来培养能力，从而成为一家具有成本效益的组 织。</li>
      <li>采用消费模型:仅为所需计算资源付费，并可根据业务需求而非复杂的预测增加或减少使用量。例如，开 发和测试环境通常只需要在每个工作日运行八个小时。您可以在不需要时停用这些资源，从而实现 75% 的 潜在成本节约(40 小时对比 168 小时)。</li>
      <li>衡量整体效率:衡量工作负载的业务产出及这些产出的实现成本。使用这种衡量方式了解您通过提高产出 和降低成本获得的收益。</li>
      <li>不再将资金投入到无差别的繁重任务上:AWS 会负责繁重的数据中心运营任务，例如安装、堆叠和驱动服 务器。它还消除了使用托管服务管理操作系统和应用程序的运营负担。因此，您可以集中精力处理客户和 业务项目而非 IT 基础设施。</li>
      <li>对支出进行分析和归因:使用云，您可以更轻松地确定系统的准确使用量和成本，从而将 IT 成本透明地分 摊到各个工作负载拥有者。这有助于衡量投资回报率 (ROI)，并让工作负载拥有者能够据此优化资源和降 低成本。</li>
    </ul>
  </li>
</ul>

<h3 id="几个定义">几个定义</h3>

<h4 id="availability">Availability</h4>

<ul>
  <li>determined by percentage uptime, in 9s
    <ul>
      <li>一堆9</li>
    </ul>
  </li>
  <li>例子：
    <ul>
      <li>S3 standard 是 4 9s</li>
      <li>S3 IA/ Inteligent tier  是 3 9s</li>
      <li>S3 OZ IA 是 2.5 9s</li>
    </ul>
  </li>
</ul>

<h4 id="high-availability">High Availability</h4>

<ul>
  <li>The system will continue to function despite the complete failure of any component of the architecture
    <ul>
      <li>部分组件挂了，系统继续用</li>
    </ul>
  </li>
</ul>

<h4 id="fault-tolerance">Fault Tolerance</h4>

<ul>
  <li>
    <p>The system will continue to function <strong>without degradation in performance</strong> despite the complete failure of any component of the architecture</p>

    <ul>
      <li>部分组件挂了，系统继续用，且性能不打折</li>
    </ul>
  </li>
  <li>
    <h4 id="几个例子">几个例子</h4>

    <ul>
      <li>不是FT（fault tolerance）的例子 (貌似都部署在了EC2上)
        <ul>
          <li>Virtual Private Gateway</li>
          <li>Nat Gateway</li>
          <li>ElastiCache</li>
          <li>RedShift</li>
          <li>EBS</li>
          <li>RDS Multi-AZ
            <ul>
              <li>包含了 Aurora</li>
            </ul>
          </li>
          <li>ECS on EC2</li>
          <li>EC2</li>
        </ul>
      </li>
      <li>符合 FT的例子
        <ul>
          <li>S3</li>
          <li>DynamoDB</li>
          <li>Aurora serverless</li>
          <li>API Gateway</li>
          <li>CloudFront</li>
          <li>Route53</li>
          <li>ELB</li>
          <li>Lambda
            <ul>
              <li>包含了 Lambda@Edge</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="redundant">Redundant</h4>

<ul>
  <li>multiple resources dedicated to performing the same task
    <ul>
      <li>多个资源干一个活</li>
    </ul>
  </li>
</ul>

<h4 id="durability">Durability</h4>

<ul>
  <li>数据在系统中保持，不会因为硬件的故障而丢失。</li>
  <li>可以通过备份，replica ， 跨AZ replica 方式提高 durability</li>
  <li>例子：
    <ul>
      <li>S3 standard 是 11 9s</li>
      <li>S1 OneZone IA 也是 11 9s</li>
    </ul>
  </li>
</ul>

<h4 id="resilience">Resilience</h4>

<ul>
  <li>使⽤⽹络资源的系统，或者被⽹络资源使能的系统在⾯对不利条件、压⼒、攻击或者损害的时候所展现出来的预测、承受、恢复和适应能⼒。</li>
  <li>统计的对象是 Availability 和 Durability</li>
</ul>

<h4 id="scalability">Scalability</h4>

<ul>
  <li>the ability of a system to increase resources to accommodate increased demand.This can be done vertically or horizontally, and is not necessarily automated.
    <ul>
      <li>有按需（水平or垂直）增加资源的能力，不一定非要自动的。</li>
      <li>比如：
        <ul>
          <li>EBS Volume, 只能加不能减</li>
          <li>其他的只要是能 Elastic 的， 一般都是Scalable</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="elasticity">Elasticity</h4>

<ul>
  <li>the ability of a system to <strong>increase</strong> and <strong>decrease</strong> resources allocated  (usually horizontally) to match demand, and implies automation.
    <ul>
      <li>有按需（通常是水平）<strong>自动</strong>增加或<strong>减少</strong>资源的能力</li>
      <li>比如：
        <ul>
          <li>EBS Volume IOPS  ， 可加可减</li>
          <li>只要是能 Elastic 的， 一般都是Scalable</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="sla">SLA</h3>

<ul>
  <li>到这个网址去找
    <ul>
      <li>aws.amazon.com/<service>/sla</service></li>
    </ul>
  </li>
</ul>

<h3 id="aws-service-scope">AWS Service Scope</h3>

<ul>
  <li>不同的服务在AWS 上有不同的scope</li>
</ul>

<h4 id="az-scope">AZ Scope</h4>

<ul>
  <li>EC2 instance</li>
  <li>EBS</li>
  <li>NAT Gateway</li>
  <li>RedShift Node</li>
  <li>RDS Instance</li>
  <li>以上这几个也同时满足 HA 但不是FT</li>
</ul>

<h4 id="region-scope">Region Scope</h4>

<ul>
  <li>S3 Bucket</li>
  <li>DynamoDB Table</li>
  <li>SNS Topic</li>
  <li>VPC</li>
  <li>CloudWatch Alarm</li>
  <li>以上这几个也是支持FT 的</li>
  <li>ELB</li>
  <li>EFS</li>
  <li>Security Group</li>
</ul>

<h4 id="multi-region-scope">Multi-Region Scope</h4>

<ul>
  <li>S3 Cross-region replication</li>
  <li>RDS Cross-region read replication</li>
  <li>DynamoDB Global Table</li>
</ul>

<h4 id="edge-location">Edge Location</h4>

<ul>
  <li>Route 53 Hosted Zone</li>
  <li>CloudFront Distribution</li>
  <li>WAF Filtering Rule</li>
  <li>Lambda@Edge</li>
</ul>

<h2 id="几个数字">几个数字</h2>

<h3 id="传输率">传输率</h3>

<p>100mbps 的传输速度 一天可以传输 1T 的数据
1Gbps = 10x100mbps 的传输速度 一天可以传输10T</p>

<h2 id="账户管理">账户管理</h2>

<h3 id="iam">IAM</h3>

<h4 id="iam-1">IAM</h4>

<ul>
  <li><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h20ax842qyj21kd0u0gok.jpg" style="zoom:50%;" /></li>
  <li>user/group</li>
  <li>policy 可以attahe 到user /group 上</li>
  <li>
    <p>policy</p>

    <ul>
      <li><strong>Policy Generator</strong> 可以帮助创建policy, 填写表格后帮你创建json 格式的policy</li>
      <li><strong>Policy simulator</strong> , mapping policy and services 验证policy 是否是你希望的那样。</li>
    </ul>
  </li>
  <li>
    <p>Policy JSON 里面的元素</p>

    <ul>
      <li>
        <p>Effect： Allow or Deny</p>
      </li>
      <li>
        <p>Action: 可以干啥， 比如访问S3的*</p>
      </li>
      <li>
        <p>NotAction: 啥都行，除了这个XXX</p>
      </li>
      <li>
        <p>Resource: 干谁， 指定一个S3 Bucket 的ARN</p>
      </li>
      <li>
        <p>Conditions： 约束条件，</p>

        <ul>
          <li>
            <p>比如限制某个IP段能不能访问</p>

            <ul>
              <li>aws:SourceIP</li>
            </ul>
          </li>
          <li>
            <p>限制可执行的区域，比如只有这个区域才能run instance</p>

            <ul>
              <li>aws:RequestedRegion</li>
            </ul>
          </li>
          <li>
            <p>限制只有数据部门的人有读写权限</p>

            <ul>
              <li>aws:PrincipalTag/Department:”data”</li>
            </ul>
          </li>
          <li>
            <p>不允许删除，除非打开了MFA Delete</p>

            <ul>
              <li>BoolIfExist:aws:MultiFactorAuthPresent:false</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>password policy</li>
  <li>MFA</li>
  <li>Access Key</li>
  <li>IAM Roles
    <ul>
      <li>IAM Roles 是临时 （temporary ）权限， 通过不同的方法进行使用，</li>
      <li>主要是给各种 AWS service 提供不同权限的临时访问授权</li>
    </ul>
  </li>
  <li>
    <p>Security Tools</p>

    <ul>
      <li><strong>credential tool</strong> (account level, audit 用途)</li>
      <li>列出该账号下所有用户和他们的credential 状态</li>
    </ul>
  </li>
  <li><strong>access advisor</strong> (user level)
    <ul>
      <li>可以看到有哪些服务权限授予了这个用户， 并且可以看到什么时候用户对这些服务进行了访问</li>
    </ul>
  </li>
  <li>
    <p>IAM Permission Boundaries 权限边界</p>

    <ul>
      <li>是在一个Policy 的JSON中设置两个Statement, 互相之间有约束。</li>
      <li>两个statement 是取交集， 没有交集就没有权限</li>
      <li>At this time, only IAM User supports permission boundaries, which does limit usage somewhat.</li>
      <li>如果两个statement 有冲突， 那么Deny&gt; Allow</li>
      <li>流程
        <ul>
          <li>先设置一个大的权限边界（Permission Boundary），比如拥有所有的S3, CloudWatch, Ec2 的任意操作权限。</li>
          <li>然后在设置一个给用户的小的边界（IAM policy），只可以创建用户的权限。</li>
          <li>两个权限没有交集， 所以这个用户最后就是没有任何权限</li>
        </ul>
      </li>
      <li>权限边界可以在User 和 role 使用，但不能在group 使用</li>
      <li>和 IAM Policy 的区别
        <ul>
          <li>Permission boundaries are limits, and IAM policies define actual tasks that can be allowed or denied.</li>
        </ul>
      </li>
      <li>案例：
        <ul>
          <li>说一个公司的新员工被赋予了 full access to DynamoDB， 而且还一不小心删了生产的一些表， 怎么解决才能避免以后在发生。
            <ul>
              <li>使用permission boundary 去限制给所有员工设置DynamoDB 最大的可以从IAM获得的权限 - 不允许删除生产的数据等</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="sts---security-token-service">STS - Security Token Service</h4>

<ul>
  <li>﻿给AWS资源授权临时和受限制的访问</li>
  <li>﻿可以理解成 sudo 命令</li>
  <li>﻿Token 有效期是1小时（需要refresh）</li>
  <li>
    <p>﻿AssumeRole 角色扮演</p>

    <ul>
      <li>﻿返回你的皮给请求者</li>
    </ul>
  </li>
  <li>
    <p>﻿AssumedRoleWithSAML</p>

    <ul>
      <li>﻿返回皮，带个SAML， 让用户可以拿着SAML 去登录</li>
    </ul>
  </li>
  <li>
    <p>﻿AssumedRoleWithIdentity</p>

    <ul>
      <li>﻿返回皮， 和第三方IdP(facebook login, Google login ….)</li>
      <li>﻿AWS不鼓励用这个，而是鼓励用Cognito</li>
    </ul>
  </li>
  <li>
    <p>﻿GetSessionToken</p>

    <ul>
      <li>﻿返回个带有session 的token,用来MFA 用。</li>
    </ul>
  </li>
  <li>
    <p>﻿考试</p>

    <ul>
      <li>﻿题中如果提到了跨账号访问, 提到了 AssumeRole, 那么答案就是 STS</li>
    </ul>
  </li>
</ul>

<h4 id="identity-federation">Identity Federation</h4>

<ul>
  <li>Federation 让外部用户可角色扮演一个role 访问AWS服务，不需要提前创建一个IAM user</li>
  <li>SAML 2.0 Federation
    <ul>
      <li>把SAML 和 Active Directory/ADFS 整合到一起的Federation</li>
    </ul>
  </li>
  <li>考试
    <ul>
      <li>题中如果提到你有一个移动应用, 想让用户访问他们自己的 S3, 那么最好的方式使用 Cognito Identify Federation .</li>
    </ul>
  </li>
</ul>

<h4 id="custom-identity-broker-application">Custom Identity Broker Application</h4>

<ul>
  <li>﻿如果提到了 on-premise identity provider, 但是不支持 SAML 2.0 , 那么就是 Broker</li>
</ul>

<h4 id="cognito">Cognito</h4>

<ul>
  <li>让移动，web 用户可以直接访问AWS 资源</li>
  <li>比如
    <ul>
      <li>让移动app用户可以通过登录Facebook 账号来访问S3 bucket</li>
    </ul>
  </li>
</ul>

<h4 id="aws-directory-service">AWS Directory Service</h4>

<ul>
  <li>
    <p>就是在AWS 上管理微软的AD</p>
  </li>
  <li>
    <p>三种</p>

    <ul>
      <li>
        <p>AWS Managed Microsoft AD,</p>

        <ul>
          <li>在AWS建一套AD, 让AWS 和 on-premise 进行trust沟通</li>
        </ul>
      </li>
      <li>
        <p>AD Connector</p>

        <ul>
          <li>AD 存在了On-premise 上， 通过proxy 的方式在AWS 和 on-premise 沟通</li>
        </ul>
      </li>
      <li>
        <p>Simple AD</p>

        <ul>
          <li>没有 on-premise, 只有AWS， 和AWS上创建的AD</li>
        </ul>
      </li>
      <li>
        <p>技巧：</p>

        <ul>
          <li>如果提到了on-premise 的 AD 账号访问 AWS 并支持 MFA, 那就是Managed AD</li>
          <li>如果提到了on-premise 的 AD 账号访问 AWS 并通过代理的形式访问, 那就是 AD Connector</li>
          <li>如果提到了直接用 AD 账号访问 AWS , 没有on-premise 的 AD 账号, 那就是 simple AD</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="root-用户可以做-但是-administratoraccess-不能做的事情">Root 用户可以做， 但是 AdministratorAccess 不能做的事情：</h4>

<ol>
  <li>change account name</li>
  <li>or root password</li>
  <li>or root email address,</li>
  <li>change AWS support plan,</li>
  <li>close AWS account,</li>
  <li>enable MFA on S3 bucket delete,</li>
  <li>create Cloudfront key pair,</li>
  <li>register for GovCloud</li>
</ol>

<h3 id="org">Org</h3>

<h4 id="organization">Organization</h4>

<ul>
  <li>可以管理多个account</li>
  <li>organization 只能有一个master accoutn ,多个 member account</li>
  <li>org 支持两种账户，
    <ul>
      <li>一种是master account 创建的账户，</li>
      <li>另一种是standalone 的账户</li>
    </ul>
  </li>
  <li>提供single payment method</li>
  <li>把所有账单算在一起来计算折扣
    <ul>
      <li>Consolidated Biling
        <ul>
          <li>多个账号都用的服务， 比如 Shield, 只要付一份钱就可以了</li>
          <li>Consolidated Billing across all accounts - single payment method</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Multi Account Strategies
    <ul>
      <li>给每个部门， 或者成本中心， 或者开发、测试、生产单独创建账号。 有效隔离资源</li>
    </ul>
  </li>
  <li>Organization Unit (OU) ，
    <ul>
      <li>是组织的下一级单位， 是member account 的组</li>
      <li>主账号管理多个OU, 每个OU 下面再分多个member 账号</li>
      <li>OU 里面可以套OU</li>
      <li>主要有三种类型
        <ul>
          <li>Business OU
            <ul>
              <li>分财务， IT,Sales 等</li>
            </ul>
          </li>
          <li>Env OU
            <ul>
              <li>分开发，测试，生产等</li>
            </ul>
          </li>
          <li>Project OU
            <ul>
              <li>分项目1， 项目2 等</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Service Control Policies (SCP)
    <ul>
      <li>让OU 下面的所有账号可以干什么事情或者不能干什么事情， 默认什么都不可以干， 必须设置一个 <strong>explicit Allow</strong></li>
      <li>Does not apply to the Master Account
        <ol>
          <li>通过SCP 可以限制org 中的每个account 中的用户和 role 访问特定AWS 服务、资源、API 。还可以设置特定的条件来缩小范围
            <ol>
              <li>SCPs 影响所有attached 到的账号的member account 的users和roles, 包括member account 的 root user</li>
              <li>如果一个user or role 有一个被赋予了具有特定访问能力的 IAM 权限， 这个权限没有被SCPs 允许或者明确拒绝了， 那么这个用户就不能执行这个特定访问权限</li>
            </ol>
          </li>
          <li>SCP 设置的 policy 可以 override 管理员账号的权限</li>
          <li>SCPs 不影响：
            <ol>
              <li>service-linked role (服务相关角色) 是直接链接到 AWS 服务的一种独特类型的 IAM 角色。service-linked role 由服务预定义，包括该服务代表您调用其他 AWS 服务所需的所有权限</li>
              <li>SCPs do not affect the root credentials, either console or API.</li>
            </ol>
          </li>
        </ol>
      </li>
      <li>比如：
        <ul>
          <li>限制这个OU下面所有账号不能使用 EMR这个AWS服务</li>
          <li>因为当地的个人信息保护法（PCI）, 所以要强制关闭某个服务</li>
        </ul>
      </li>
      <li>父子OU 有继承关系， 比如， 父OU 绑定的SCP 在子OU中会被继承
        <ul>
          <li><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h1u614o7myj21ls0u00va.jpg" alt="" /></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="在组织之间迁移账户">在组织之间迁移账户</h4>

<ul>
  <li>先删掉原来账户里的member account</li>
  <li>新组织给账户发送一个邀请</li>
  <li>接受新组织邀请</li>
  <li>删掉旧account(master account 才需要这一步)</li>
</ul>

<h3 id="ram">RAM</h3>

<h4 id="resource-access-manager-ram">Resource Access manager (RAM)</h4>

<ul>
  <li>RAM 的目的是让一个org 下的多个子账号分享资源， 避免浪费</li>
  <li>分享资源不需要额外付费</li>
  <li>把自己AWS的资源分享给其他AWS 账户， 几个账户可以共享资源，一起工作。</li>
  <li>可以是自己的org 的， 也可以是其他org 的</li>
  <li>网络是共享的， 多个账户的服务之间客户互相通信
    <ul>
      <li>需要使用private IP</li>
      <li>需要打开安全组的设置</li>
    </ul>
  </li>
  <li>可以分享的内容：
    <ul>
      <li>VPC Subnets
        <ul>
          <li>可以分享subnet内的所有的资源（比如同一个org 下几个子账号的所有EC2 实例）（只能分享给同一个ORG下的account）， 几个账户可以共享一个VPC 的Subnet， 在其中一起工作</li>
          <li>不包括Security 和 VPC</li>
          <li>participant 可以在subnet 下面创建和管理他们自己的资源， 比如在subnet 下面创建一个自己的S3bucket.</li>
          <li>participant 不能修改和删除不属于他自己的资源</li>
          <li>例子：一个org 下同一个region 的多个子账号分享EC2 实例
            <ul>
              <li>通过 RAM (Resource Access Manager)创建一个VPC -&gt; 分享它的一个或者多个subnet 给那些子账号-&gt; 子账号把EC2 都放在subnet 中，大家就可以公用EC2 了。</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Route53 Resolver Rules</li>
      <li>Transit Gateway</li>
      <li>License Manager Configurations</li>
    </ul>
  </li>
</ul>

<h4 id="vpc-sharing-shared-service-vpc">VPC Sharing (<strong>Shared service VPC</strong>)</h4>

<ul>
  <li>(Resource Access Manager 的一部分) 来 share 同一组织下的多个账号的一个或多个<strong>子网</strong> ，
    <ol>
      <li>VPC Sharing, 分享的是下面的Subnets, 而不是VPC 自己。</li>
      <li>RAM 就是在多个AWS账号之间分享AWS资源的，</li>
      <li>Transit Gateway 使用了 RAM 功能</li>
    </ol>
  </li>
</ul>

<h3 id="sso">SSO</h3>

<h4 id="aws-single-sign-on">AWS Single Sign-on</h4>

<ul>
  <li>单点登录， 多个网站/域名都是在一个点登录，登录后访问多个域名/应用不需要重复登录
    <ul>
      <li>案例：
        <ul>
          <li>IBM 一个账号登录就可以使用Slack, Box, Office365, Teams, Webex,</li>
          <li>客户已经有了AD, 客户的员工可以通过设置 AWS SSO 来访问客户在AWS 中的多个账户。</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>集中管理SSO 去访问多个账户和第三方应用</li>
  <li>和 Cognito （assumeRole/STS）的区别
    <ul>
      <li>Cognito 是登录AWS 实例提供的服务的时候使用第三方的账号登录， 比如用facebook 登录</li>
      <li>单点登录是一个点登录后就可以访问多个网站</li>
    </ul>
  </li>
  <li>集成和Organization</li>
  <li>支持
    <ul>
      <li>SAML 2。0</li>
      <li>Active Directory</li>
    </ul>
  </li>
  <li>集中了Permision 和 CloudTrail 的管理</li>
</ul>

<h2 id="网络边缘">网络边缘</h2>

<h3 id="route53">Route53</h3>

<h4 id="dns-概念">DNS 概念</h4>

<ul>
  <li>A, AAAA, CName, Alias</li>
  <li>Zone File: 存放DNS记录的地方</li>
  <li>100% up time
    <ul>
      <li>Route 53 has an uptime SLA of 100%</li>
    </ul>
  </li>
  <li>Domain Name Server (DNS Server) ： 解析域名服务器（官方，私人）</li>
</ul>

<h4 id="route-53">Route 53</h4>

<ul>
  <li>health check, for aws service（end point）
    <ul>
      <li>目的是做auto failover</li>
      <li>checker 是15个global 的 检查服务， 3个说健康就健康， 小于3个就不健康。</li>
      <li>返回 状态码200 、300是健康</li>
      <li>public resource only (有 public ip的service)
        <ul>
          <li>private hosted zone 的资源可以让 health check 检查 private host zone 的 资源的 cloud watch alarm</li>
        </ul>
      </li>
      <li>路由和防火墙需要允许 route 53 进来</li>
      <li><strong>Calculated Health Checks</strong> 是让health check 去检其他的健康检查结果的汇总， 父子关系的健康检查</li>
      <li><strong>private host zone</strong> 需要通过 clout watch alarm 来检查，然后把结果暴露给health checker</li>
      <li>当 Route 53 运行状况检查的主记录失败（并且配置了 DNS 故障转移）时，预期的行为是什么？
        <ul>
          <li>任何后续 DNS 记录都会返回辅助记录，直到主记录再次通过运行状况检查。</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>100% availability SLA</li>
  <li>Record Types （记录类型）
    <ul>
      <li>A – maps a hostname to IPv4</li>
      <li>AAAA – maps a hostname to IPv6</li>
      <li>CNAME – maps a hostname to another hostname
        <ul>
          <li>The target is a domain name which must have an A or AAAA record</li>
          <li>Can’t create a CNAME record for the top node of a DNS namespace (Zone Apex)， 比如abc.com就不行， www.abc.com 就可以。 Alias 可以解决这个问题</li>
        </ul>
      </li>
      <li>PTR - 你告诉我一个IP, 我告诉你一个域名</li>
      <li>Alias Record Target
        <ul>
          <li>将同一个 Route53 的 一个域名转到一个AWS 资源（包括域名）上去， 但是前提是域名必须是账号中的Route 53 自己管理的域名。 Alias 不能管理第三方的域名</li>
          <li>Alias target 支持除了EC2之外的很多服务 , ELB, Cloud Front, API Gateway, Beanstalk, S3, VPC, Global Accelerator.</li>
        </ul>
      </li>
      <li>NS - Name Server, 是AWS提供的DNS服务器列表， 让用户把自己的域名的Hosted Zone 里面设置这个列表，就可以找到自己在AWS里的服务</li>
    </ul>
  </li>
  <li>RecordsTTL (TimeTo Live)
    <ul>
      <li>记录被客户缓存的时间， 过期了客户又要去route 53再问一遍</li>
      <li>不能设置</li>
    </ul>
  </li>
  <li>Hosted Zone, 放记录的容器
    <ul>
      <li>public hosted zone, 告诉外部客户如何找到AWS里的服务（服务要含public ip）</li>
      <li>private hosted zone, 告诉aws 服务如何找到其他aws服务 (服务要含private ip)
        <ul>
          <li>DNS 中设置一个private hosted zone 就可以解析内网的域名， 将一个域名指向一个内网的IP地址</li>
          <li>一般会指向一个VPC
            <ul>
              <li>如果VPC 要能够接收流量， 就需要设置两个配置
                <ul>
                  <li>打开
                    <ul>
                      <li>VPC 的 <strong>DNS hostnames</strong> - 设置一个内部域名</li>
                      <li><strong>DNS resolution</strong> for private hosted zones. - 可以被解析</li>
                    </ul>
                  </li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>route policy （你告诉我域名， 我告诉你去哪个IP, 这里的IP可以是任何alias target）
    <ul>
      <li>simple - 你告诉我一个域名，我告诉你一个（或多个IP，客户随机挑一个）</li>
      <li>weighted - 转发给多个IP地址为不同的权重， 0% - 100%</li>
      <li>latency - 用户去哪个IP最快就给他哪个IP</li>
      <li>geolocation - 用户在那个国家， 就去这个国家的IP</li>
      <li>geoproximity
        <ul>
          <li>在 geolocation 的基础上， 给同一个国家内的多个IP设置 -99到99的权重， 越高半径范围越大。 用 Traffic Flow Policy 来记录</li>
          <li></li>
        </ul>
      </li>
      <li>multi-value - 一个域名可能会有多个IP, 请求说要多个 ， 那就返多个</li>
    </ul>
  </li>
  <li>用Route 53 解析从其他域名商买得域名
    <ol>
      <li>Create a Hosted Zone in Route 53</li>
      <li>Update NS Records on 3rd party website to use Route 53 Name Servers</li>
    </ol>
  </li>
</ul>

<h4 id="通过driect-connection-连接的on-premise-和-aws-vpc-之间互相之间解析dns-的方法">通过Driect Connection 连接的on-premise 和 AWS VPC 之间互相之间解析DNS 的方法</h4>

<ol>
  <li>在Route 53 上创建一个inbound endpoint, 在 on-premise 上的DNS 解析器 （resolvers）可以把DNS请求发送到53的 endpoint 上</li>
  <li>在Rout 53上创建一个 outbound endpoint, 53就可以通过这个endpoint 把 aws上的流量forward 到 on-premise 网络</li>
</ol>

<h4 id="希望route-53-可以在网站不可用的情况下跳到一个静态错误页面-需要的最简单可以实现的方案是">希望Route 53 可以在网站不可用的情况下跳到一个静态错误页面， 需要的最简单可以实现的方案是：</h4>

<ol>
  <li>设置Route 53的 <strong>active-passive</strong> (主动-被动) 的 failover routing policy. 当 Route 53 健康检查发现ALB 不健康， 流量会被转到静态错误页面（放在S3 bucket 上）</li>
</ol>

<h3 id="cloudfront">CloudFront</h3>

<h4 id="cloudfront-1">CloudFront</h4>

<ul>
  <li>CDN 网络, 加速边缘侧的下载</li>
  <li>216个 edge locations</li>
  <li>CloudFront + S3 的方案比纯S3 的方案有更低的成本（更省钱）</li>
  <li>安全
    <ul>
      <li>防DDOS攻击， 整合Shield, WAF</li>
      <li>外部暴露HTTPS, 内部HTTPS talk</li>
      <li><strong>OAI</strong> (Origin Access Identity) + S3 bucket policy 保证S3数据源的安全， 不会把源暴露出去
        <ul>
          <li>在CloudFront 上设置OAI ，不暴露S3源的真实地址</li>
          <li>设置S3 Policy, 只允许CloudFront 访问， 不允许外网直接访问</li>
        </ul>
      </li>
      <li>Field Level Encryption
        <ul>
          <li>在 edge 用非对称加密（有公钥私钥）用户的敏感数据， 比如信用卡数据</li>
          <li>最多加密10个字段</li>
          <li>公钥放在Edge location, 私钥放在EC2 实例上</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>TTL , 有个cache 的时间段， 过期了需要回到origin 去读</li>
  <li>Origins (CloudFront 的数据源)
    <ul>
      <li>S3 Bucket 中的文件</li>
      <li>Custom Origin (http) 自定义源 (必须有public ip, 切SG需要允许edge location 的IP进行访问)
        <ul>
          <li>EC2实例</li>
          <li>ALB</li>
          <li>S3 Website</li>
          <li>any http backend you want</li>
        </ul>
      </li>
      <li>Multi-origin
        <ul>
          <li>根据客户请求的path 不同而去不同的origin, 比如 /api/ <strong>就去ALB, /*就去S3</strong></li>
        </ul>
      </li>
      <li>Origin Group
        <ul>
          <li>为了HA, 比如两个EC2、 两个S3 都可以组成一个 Origin Group。</li>
          <li>CloudFront 访问的是Origin Group, 当一个Ec2 挂了也没事。</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Geo Restriction , 对某些发起请求的国家的用户进行限制（版权或者合规的原因）
    <ul>
      <li>white list</li>
      <li>black list</li>
      <li>“国家” 是使用第三方的 Geo-IP数据库</li>
    </ul>
  </li>
  <li><strong>S3 Cross Region Replica for CloudFront</strong>
    <ul>
      <li>想要最佳的效果， 必须要在你想做CDN的国家设置一个read only replica.</li>
    </ul>
  </li>
  <li><strong>Signed URL/ Signed Cookie</strong>
    <ul>
      <li>比如给付费用户下载视频的时候提供一个临时的URL, URL1分钟后就过期。
        <ul>
          <li>背后的逻辑： 想要创建一个signed URL 给客户且不允许客户访问源的方法有一下几个步骤
            <ol>
              <li>创建一个CloudFront 用户可以让CloudFront 调用 OAI 来访问S3 源</li>
              <li>配置S3 允许CloudFront 可以通过OAI 访问源的文件 （这时，还没有URL地址可以让外部用户访问）</li>
              <li>需要通过Lambda 来创建一个URL</li>
              <li>通过CloudFront signed URL 来限制只有付费用户可以访问文件</li>
            </ol>
          </li>
        </ul>
      </li>
      <li>过期时间可长可短（分钟到年）</li>
      <li>一个url 对应一个文件
        <ul>
          <li>用户通过signed URL只能访问一个文件</li>
        </ul>
      </li>
      <li>一个 cookie 对应多个文件
        <ul>
          <li>用户通过signed Cookie 能访问多个文件</li>
        </ul>
      </li>
      <li>对比S3 Pre-signed URL, 主要区别是场景不一样， 一个是为了加速下载并给特权账户使用， 一个是临时使用S3的一个文件。</li>
    </ul>
  </li>
</ul>

<h4 id="cloudfront-price-classes">CloudFront Price Classes</h4>

<ol>
  <li>Price Class All : 所有region 都打开，性能最好， 钱也是哗哗的</li>
  <li>Price Class 200: 去掉最贵的几个国家， 其他的都选 (最贵的往往是一些偏僻的地方， 比如印度)</li>
  <li>Price Class 100: 只选最便宜的几个国家（往往是最发达的几个国家）</li>
</ol>

<h4 id="cloudfront-和-global-accelerator的区别">CloudFront 和 Global Accelerator的区别</h4>

<ul>
  <li>有，没有Cache的区别</li>
  <li>静态和动态的区别</li>
  <li>HTTP 和UDP/TCP 的区别</li>
</ul>

<h4 id="cloudfront-和-s3-transfer-accelerator-的区别">CloudFront 和 S3 Transfer Accelerator 的区别</h4>

<ul>
  <li>他们都支持加速静态文件</li>
  <li>但是1G以内， CloudFront 效果更好</li>
  <li>1G 以上， S3 TA 效果更好</li>
</ul>

<h4 id="cloudfront-和-vod-live-streaming-video">CloudFront 和 VOD, Live streaming video</h4>
<ul>
  <li>You can use CloudFront to deliver video on demand (VOD) or live streaming video using any HTTP origin. One way you can set up video workflows in the cloud is by using CloudFront together with AWS Media Services.</li>
</ul>

<h4 id="错题总结---cloudfront-的正确描述">错题总结 - Cloudfront 的正确描述：</h4>

<ol>
  <li>CloudFront 可以基于文件类型来路由到多个oregion （Multi-origion）
    <ol>
      <li>比如图片类型就路由到 一个 S3地址， 其他文件路由到另一个地址</li>
    </ol>
  </li>
  <li>使用 field level encryption 保护敏感数据</li>
  <li>使用 origin group， 设置primary和secondary origins 来进行高可用和 failover</li>
</ol>

<h3 id="aws-global-accelerator">AWS Global Accelerator</h3>

<h4 id="aws-global-accelerator-1">AWS Global Accelerator</h4>

<ul>
  <li>让一个全球化的应用可以被世界各地的用户访问</li>
  <li>提升了应用的 performance 和 availability</li>
  <li>利用Edge Location 到应用实例之间的AWS 内部网络加速， 让全球客户可以快速访问到应用。</li>
  <li>可以降低AWS 客户网络的复杂性</li>
  <li>可以被加速的对象
    <ul>
      <li>Elastic IP,</li>
      <li>EC2 instance,</li>
      <li>ALB, NLB</li>
    </ul>
  </li>
  <li>AGA 和 ELB配合
    <ul>
      <li>ELB 是region scope. 如果需要跨region ,需要借助于Aws Global Accelerator (AGA) 的 跨region 能力；在AGA中创建endpoint group， 把每个region 的 ALB 包含进去。</li>
      <li>ELB provides load balancing within one Region, AWS Global Accelerator provides traffic management across multiple Regions […] AWS Global Accelerator complements ELB by extending these capabilities beyond a single AWS Region, allowing you to provision a global interface for your applications in any number of Regions. If you have workloads that cater to a global client base, we recommend that you use AWS Global Accelerator. If you have workloads hosted in a single AWS Region and used by clients in and around the same Region, you can use an Application Load Balancer or Network Load Balancer to manage your resources.</li>
    </ul>
  </li>
  <li>加速原理
    <ul>
      <li>AWS Global Accelerator 提供了两个静Anycast IP (公共IP) (所有服务器用同一个IP, 客户会路由到<strong>最近的一个/延迟最低的那个</strong>) 给到了应用</li>
      <li>客户请求的域名会被翻译成这个IP, 给到客户， 客户找到最近的一个Anycast IP</li>
      <li>Anycast IP 将流量转给Edge location</li>
      <li>Edge location 通过AWS 内网将数据转给应用。</li>
    </ul>
  </li>
  <li>因为Anycast IP不会变， 所以不影响客户的缓存。</li>
  <li>Health Check , 可实现全球的灾难恢复</li>
  <li>Security
    <ul>
      <li>只有两个公共IP需要暴露</li>
      <li>AWS Shield 可以防止DDos 攻击</li>
    </ul>
  </li>
  <li>场景
    <ul>
      <li>游戏， VOIP电话， 蓝绿测试，UDP, MQTT, IOT,</li>
      <li>需要静态IP地址，</li>
      <li>需要全球的快速 failover</li>
      <li>两个IP</li>
      <li>Anycast IP</li>
    </ul>
  </li>
</ul>

<h4 id="cloudfront-和-global-accelerator的区别-1">CloudFront 和 Global Accelerator的区别</h4>

<ul>
  <li>有，没有Cache的区别</li>
  <li>静态和动态的区别</li>
  <li>HTTP 和UDP/TCP 的区别</li>
</ul>

<h4 id="案例">案例：</h4>

<p><strong>一个国际应用的一个region 的 ELB 挂了， 降低网络延迟并提供automitic failover cross aws region 的方案是：</strong></p>

<ol>
  <li>设置 AWS Global Accelerator ， 增加 endpoint 去 让用户访问其他地理位置
    <ol>
      <li>AGA 有两个IP地址， 可以让你增加或删除 origins, AZ, Region是， 且不会降低应用的availibility.</li>
      <li>通过手动调整endpoint 路由的流量和权重，如果一个endpoint 有failure  , AGA 马上几秒钟就会自动的将流量redirect 到一个健康的 endpoint 上</li>
      <li>通过AGA 你可以：
        <ol>
          <li>整合AGA的两个静态IP地址与AWS服务（NLB, ALB, EC2, Elastic IP, ） 加速</li>
          <li>把endpoints在AZ/region 之间移动， 不需要修改DNS 和 应用 （两个IP是同一个IP地址）</li>
          <li>通过给 endpoint group 配置一个 traffic deal percentage 来 dial (拨叫) trafic up/down 到一个指定的region, 可以实现测试性能和发布一个更新 （蓝绿部署）</li>
          <li>控制流量权重分配到每个endpoint。</li>
        </ol>
      </li>
    </ol>
  </li>
</ol>

<h3 id="snow-family">Snow Family</h3>

<h4 id="snow-family-1">Snow Family</h4>

<ul>
  <li>type
    <ul>
      <li>Snowcone
        <ul>
          <li>8TB</li>
        </ul>
      </li>
      <li>Snowball
        <ul>
          <li>80TB</li>
          <li>Snowball Edge Compute Optimized 和Snowball Edge Storage Optinmized 都支持 Storage Clustering (存储集群).</li>
        </ul>
      </li>
      <li>Snowmobile
        <ul>
          <li>100PB = 100 * 1024TB</li>
          <li>AWS 建议 10 PB以上的数据用Snowmobile 来传输</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Challenge
    <ul>
      <li>无宽带， 低带宽， 网费贵，网络不稳定</li>
    </ul>
  </li>
  <li>场景
    <ul>
      <li>把数据运回来</li>
      <li>边缘计算（人工智能，数据分析等）， 算好了把结果拿回来
        <ul>
          <li>用EC2 或者 Lambda计算</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>使用流程
    <ul>
      <li>console上申请Snowball, 快递到你家</li>
      <li>安装 <strong>snowball client/AWS OpsHub</strong> 到自己的服务器上
        <ul>
          <li>AWS OpsHub, 安装在客户电脑上的软件， 用于管理Snow 设备</li>
        </ul>
      </li>
      <li>连接snowball, 开始拷贝数据</li>
      <li>快递回AWS</li>
      <li>创建一个 <strong>snowball job</strong> 数据先导入到S3, (不能直接到Glacier) , 在用lifecycle rule 把数据搞到glacier 中 (同一天)</li>
    </ul>
  </li>
  <li>AWS DataSync
    <ul>
      <li>Snowball/Snowcone 连上网了，就可以AWS DataSync 来把数据导入到AWS</li>
    </ul>
  </li>
  <li>Edge Computing
    <ul>
      <li>All: Can run EC2 Instances &amp; AWS Lambda functions (using AWS IoT Greengrass)</li>
      <li>Long-term deployment options: 1 and 3 years discounted pricing</li>
    </ul>
  </li>
</ul>

<h2 id="网络">网络</h2>

<h3 id="vpc">VPC</h3>

<h4 id="vpc---virtual-private-cloud">VPC - Virtual Private Cloud</h4>

<ul>
  <li>﻿每个region 最多5个VPCs</li>
  <li>
    <p>﻿每个VPC 最多5个 Cidr</p>

    <ul>
      <li>﻿每个Cidr 最小范围 /28 (16个IP)</li>
      <li>﻿每个Cidr 最大范围 /16 (65536个IP)</li>
    </ul>
  </li>
  <li>﻿VPC 只支持IPV4</li>
  <li>﻿VPC 如果跨多个AZ， 那么需要支付额外的az间流量通信费</li>
</ul>

<h4 id="vpc中需要付费的网络设备">VPC中需要付费的网络设备：</h4>

<ul>
  <li>EIP</li>
  <li>NAT Gateway
    <ul>
      <li>按小时和流量付费</li>
    </ul>
  </li>
  <li>VPN Gateway
    <ul>
      <li>按小时和流量付费</li>
    </ul>
  </li>
  <li>Peering connection
    <ul>
      <li>按小时和流量付费</li>
    </ul>
  </li>
  <li>interface endpoint
    <ul>
      <li>按小时和流量付费</li>
      <li>(gateway endpoint 免费)</li>
    </ul>
  </li>
  <li>Transit gateway
    <ul>
      <li>按小时和流量付费</li>
      <li>更贵一点</li>
    </ul>
  </li>
  <li>Trafic mirroring
    <ul>
      <li>按照对应连接的的ENI 个数按小时付费</li>
    </ul>
  </li>
  <li>VPC flow  logs
    <ul>
      <li>按照流量付费</li>
    </ul>
  </li>
</ul>

<h4 id="vpc--regional-网络间的付费">VPC  regional 网络间的付费</h4>

<ul>
  <li>同一个AZ 之间的流量传递，除了public IP 之外都不要钱。</li>
  <li>AZ 之间的数据传输需要付费</li>
  <li>Egress （访问互联网）需要付费</li>
  <li>Ingress 免费</li>
  <li>Region 之间传输数据需要付费</li>
  <li>使用 CloudFront 来优化S3 可以省钱
    <ul>
      <li>S3 到 CloudFront 这部分的通信免费</li>
    </ul>
  </li>
</ul>

<h4 id="vpc-security-group">VPC security group</h4>

<ul>
  <li>使用VPC 安全组可以控制网络流量访问你的文件系统 （EFS 等）</li>
</ul>

<h4 id="cidr">CIDR</h4>

<ul>
  <li>IP 地址段
    <ul>
      <li>/32 代表1个IP（2^0）=1</li>
      <li>/31 代表2个IP （2^1）=2</li>
      <li>/n 代表 (2^n)</li>
      <li>/24 代表最后一个地址段可用, 256 个IP</li>
      <li>/16 代表最后两个地址段可用 , 256x25个IP</li>
      <li>/8 代表最后三个地址段可用</li>
      <li>/0 代表全地址段可用</li>
    </ul>
  </li>
  <li>https://www.ipaddressguide.com/cidr 可以帮忙计算Cidr 的IP个数</li>
  <li>Private IP 可以用的地址段
    <ul>
      <li>10.0.0.0/8</li>
      <li>172.16.0.0/12 (AWS VPC 默认地址段范围)</li>
      <li>192.168.0.0/16</li>
    </ul>
  </li>
</ul>

<h4 id="subnet">subnet</h4>

<ul>
  <li>subnet 绑定到某个AZ上， 定义一段CIDR</li>
  <li>每个subnet 会有5个IP地址被预留
    <ul>
      <li>Subnet CIDR 中的前4个和后1个 (以10.0.0.0/24为例)
        <ul>
          <li>10.0.0.0 - subnet 网络地址</li>
          <li>10.0.0.1 - VPC 的 Router</li>
          <li>10.0.0.2 - Mapping AWS 提供的DNS</li>
          <li>10.0.0.3 - 保留位，未来可能会用</li>
          <li>10.0.0.225 - Network Broadcase Address 广播地址。 因为AWS 不支持广播， 所以也是保留位。</li>
        </ul>
      </li>
      <li>比如：
        <ul>
          <li>需要29个IP 地址， 需要用/26 ， 因为/26 有64 -5 = 59 个； 而/27 是32-5 = 27 ，不够
            <ul>
              <li>27 = 27</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>区分public subnet 和 private subnet
    <ul>
      <li>pri sub - 这个subnet 中的资源通过绑定的route table 没有被连接到internet gateway, 那就是 private subnet</li>
      <li>pub sub - 这个subnet 中的资源通过绑定的route table 被连接到internet gateway, 那就是 public subnet
        <ul>
          <li>还需要让EC2 实例有public IP, 并且实例所在的AG 允许， pub sub 下面的实例才能访问互联网</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="internet-gateway-igw">Internet Gateway (IGW)</h4>

<ul>
  <li>在VPC level</li>
  <li>让VPC 内的资源 （e.g. EC2 实例） 可以访问互联网</li>
  <li>是AWS managed service, 自动伸缩， 高可用， 容灾， 不用我们管</li>
  <li>IGW 是的最佳描述是 Fault Tolerant
    <ul>
      <li>An Internet gateway is a fault-tolerant virtualized resource with no visibility from the customer perspective.</li>
    </ul>
  </li>
  <li>IGW 是完全免费的
    <ul>
      <li>The Internet gateway, while it does not accrue any charges directly, does allow traffic to reach outside networks, and that throughput can possibly be charged based on the destination.</li>
    </ul>
  </li>
  <li>一个VPC 只能对应一个IGW</li>
  <li>需要配置Route Table ， 让Public subnet 在Route Table 中指向IGW 才能连接互联网</li>
  <li>Internet Gateway 有两个作用
    <ol>
      <li>作为route table 的目标， 让流量可以访问互联网</li>
      <li>进行网络地址翻译 （Network Address Translation （NAT））
        <ol>
          <li>public subnet 下面的实例通过路由连接IG， 先被IG 进行了 NAT， 然后连接互联网。</li>
          <li>private subnet 下面的实例先连接pub subnet 下面的NAT 设备进行NAT, 然后再连到pub subnet 下的IG 连接互联网</li>
        </ol>
      </li>
    </ol>
  </li>
  <li>IGW 没有啥安全功能
    <ul>
      <li>The Internet Gateway has no built-in features for monitoring, whitelisting, or blacklisting traffic that passes through it.</li>
    </ul>
  </li>
</ul>

<h4 id="bastion-hosts-堡垒机">Bastion Hosts 堡垒机</h4>

<ul>
  <li>IGW 解决了public subnet 应用可以访问互联网的问题</li>
  <li>但是外网用户无法访问（ssh） Private subnet 中的资源(ec2 实例) , 需要一个堡垒机/跳板机 （放在public subnet ）作为跳板， 跳到private subnet 中来访问资源</li>
  <li>安全组配置
    <ul>
      <li>Bastion Host的安全组需要打开（开放给外网访问者的IP , 端口是22）</li>
      <li>私有子网的实例的安全组需要允许bastion host 访问</li>
    </ul>
  </li>
  <li>高可用的堡垒机方案是：
    <ol>
      <li>创建一个public NLB，该 NLB 链接到由 ASG 管理的堡垒主机所在的 EC2 实例上
        <ol>
          <li>Create a public Network Load Balancer that links to EC2 instances that are bastion hosts managed by an ASG</li>
        </ol>
      </li>
    </ol>
  </li>
</ul>

<h4 id="nat-instance---network-address-translation-这个过时了-nat-gateway-是代替者">NAT Instance - network address translation （这个过时了， NAT Gateway 是代替者）</h4>

<ul>
  <li>
    <p>用来让private subnet 的实例可以访问外网（但是外网无法访问private subnet 中的资源）</p>
  </li>
  <li>
    <p>底层是EC2</p>
  </li>
  <li>
    <p>NAT 必须放在public subnet 中</p>
  </li>
  <li>
    <p>需要在EC2中关闭 Source/Destination Check</p>
  </li>
  <li>
    <p>NAT 需要绑一个 Elastic IP</p>
  </li>
  <li>
    <p>private subnet 的 route table 需要配置， 让private subnet traffic 流向 NAT</p>
  </li>
  <li>
    <p>NAT 访问外网时， 会隐藏掉 EC2 的IP, 而是把NAT 的 Elastic IP 暴露了给外网</p>
  </li>
  <li>
    <p>缺点</p>

    <ul>
      <li>
        <p>NAT instance 没有高可用/伸缩功能</p>
      </li>
      <li>
        <p>和外网通信的带宽依赖于EC2的类型</p>
      </li>
      <li>
        <p>需要手动设置Security Group.</p>

        <ul>
          <li>Inbound: 允许private subnet 的 HTTP, HTTPS , SSH 访问</li>
          <li>Outbound: 允许HTTP/HTTPS 访问 internet</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>优点/特色</p>

    <ul>
      <li>NAT instance 支持 port forwarding</li>
      <li>安全组可以和一个NAT instance 关联（NAT instance 是一个EC2 ， 所以外面可以套一个SG）</li>
      <li>NAT instance 可以做堡垒机（hastion server）</li>
    </ul>
  </li>
</ul>

<h4 id="nat-gateway---natgw-老师上课讲的是这个">NAT Gateway - NATGW (老师上课讲的是这个)</h4>

<ul>
  <li>是NAT Instance的代替者</li>
  <li>The NAT gateway is charged by the hour and for traffic throughput.</li>
  <li>IPV4 only, IPV6 是用Egress-only internet gateway 实现</li>
  <li>让private subnet 中的EC2 实例可以通过NATGW 访问 internet</li>
  <li>支持更高的带宽， HA, 容灾， 不需要管理 ， serverless</li>
  <li>NATGW 在指定AZ中创建， 使用EIP</li>
  <li>NAT 必须放在public subnet 中</li>
  <li>NATGW 不能被与它在同一个subnet 中的EC2 连接， 只允许非自己的subnet 的EC2访问</li>
  <li>需要先有一个IGW, (private subnet → NATGW → IGW)</li>
  <li>无需安全组</li>
  <li>private subnet 的 route table 需要配置， 让private subnet traffic 流向 NATGW</li>
  <li>NATGW 访问外网时， 会隐藏掉 EC2 的IP, 而是把NAT 的 Elastic IP 暴露了给外网</li>
  <li>NATGW 默认在一个AZ中是高可用的， 如果需要 支持 容灾 （fault-tolerance）, 需要在多个AZ中创建 NATGW</li>
  <li>NATGW和 NAT Instance 的区别</li>
</ul>

<p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h0no83keugj20gm07adfy.jpg" alt="img" /></p>

<ol>
  <li>NAT gateway 不支持 port forwarding</li>
  <li>NAT gateway不能作为堡垒机</li>
  <li>NAT gateway没有安全组</li>
  <li>NAT instance 可以作为堡垒机, 因为他是一个 EC2 实例</li>
  <li>NAT instance 可以有安全组,</li>
  <li>NAT instance 支持port forwarding</li>
  <li>NAT Gateway 是high availible, 但不是fault tolerant.
    <ol>
      <li>The NAT gateway is replaced by AWS if it fails, but there is a short disruption of service during the replacement.</li>
    </ol>
  </li>
</ol>

<h4 id="vpc中的dns解析">VPC中的DNS解析</h4>

<ul>
  <li>比如public subnet 的一个 EC2 需要请求 google.com , 需要AWS提供域名解析服务。</li>
  <li>决定 VPC 的 DNS 解析是否需要通过 Route 53 进行
    <ul>
      <li>是 （默认）
        <ul>
          <li>请求 Amazon DNS Server 169.254.169.253 或者 VPC 预留的DNS 解析IP地址 xxx.xxx.xxx.2</li>
        </ul>
      </li>
      <li>否
        <ul>
          <li>需要自己创建一个costom DNS server , 用来解析</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>DNS Hostname
    <ul>
      <li>EC2 实例的域名 ，有private 和 public
        <ul>
          <li>如果需要让EC2 有一个 public DNS Hostname, 需要在创建VPC 的时候打开 enableDnsSupport = true 的选项
            <ul>
              <li>不开启的话实例只有一个私有DNS Hostname</li>
              <li>开启后， 每个EC2 实例都会带两个DNS Hostname, 一个 public hostname, 一个 private hostname</li>
            </ul>
          </li>
          <li>如果是要解析私有域名， 需要在Route53上同时打开enableDnsSupport = true 和 enableDnsHostname = true的选项
            <ul>
              <li>比如
                <ul>
                  <li>当EC2 实例想访问 web.mycompany.private的时候， 如果Route53 的 Private Hosted Zone 记录了这个域名对应的内网IP, 会就返回这个IP 给EC2实例， EC2 就可以访问内网中的这个IP （另一个EC2 实例）了</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="nacl-和-security-group">NACL 和 Security Group</h4>

<ul>
  <li>
    <p>NACL - Network Access Control List</p>

    <ul>
      <li>
        <p>可以理解成Subnet 这一层的安全组</p>
      </li>
      <li>
        <p>每个NACL 对应一个Subnet</p>
      </li>
      <li>
        <p>NACL 对应的rule 会应用到所有subnet 中的ec2中， 不管EC2 如何设置SG</p>
      </li>
      <li>
        <p>和 SG 的区别</p>

        <ul>
          <li>
            <p>NACL 是 stateless （能进来不一定能出去；能出去不一定能回得来）</p>
          </li>
          <li>
            <p>SG 只有 Allow 没有Deny, NACL 既有allow 也有 deny</p>
          </li>
          <li>
            <p>SG 是 stateful (只要能进来，就能出去； 能出去，就能进来)</p>
          </li>
          <li>
            <p>例子：</p>

            <ul>
              <li>通过EC2实例 http访问某个外网IP地址; 这个外网IP 通过SSH访问我们的EC2实例
                <ul>
                  <li>NACL inbound rule 和 outbound rule 都需要单独设置允许。比如SG 更加严格</li>
                  <li>SG 只要设置inbound rule 或者 outbound rule 就可以了；</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>NACL Rule</p>

        <ul>
          <li>每个rule 就是一个allow/deny 一个CIDR 的规则</li>
          <li>每个rule 有一个 号码（1-32766）， 数字越小优先级越高</li>
          <li>如果两个规则有冲突，那么数字小的那个胜出</li>
          <li>建议每条rule 的number 间隔是100</li>
          <li>刚创建的NACL 默认Deny 一切地址
            <ul>
              <li>因为新创建的NACL 有一条 number 是 * 的 deny rule , deny 了 0.0.0.0/0</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>Default NACL</p>

        <ul>
          <li>这个Default NACL 是在创建VPC 的时候系统自动创建的default subnet 自带的NACL</li>
          <li>Default NACL 允许一切 inboound 和 outbound 的访问的</li>
          <li>不要修改它</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="nacl-和-ephemeral-ports">NACL 和 Ephemeral Ports</h4>

<ul>
  <li>
    <p>Ephemeral Ports 是当客户端与一个目标服务进行通信的时候，客户端对应的操作系统临时创建的一个端口， 目的是可以让目标服务返回信息时可以把这个端口号带回来， 让操作系统把response 和 request 对应起来。</p>
  </li>
  <li>
    <p>当两个subnet 之间的服务相互调用的时候， 那么request 和 response 都要分别通过2个 NACL .</p>

    <ul>
      <li>比如EC2的web 调用 Mysql ,
        <ul>
          <li>request 的 target port 是 3306, src port 会带一个随机的端口号（1024-65535）。</li>
          <li>response 的 target port是1024-65535 ， src 就是mysql 的 3306</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="vpc-reachability-analyzer">VPC Reachability Analyzer</h4>

<ul>
  <li>
    <p>网络诊断工具， 用来诊断VPCs 两个 endpoint 之间的网络连接性</p>
  </li>
  <li>
    <p>它通过网络配置信息建立一个模型， 然后模型判断是否连通 （不会真的发送信息）</p>
  </li>
  <li>
    <p>比如两个EC2之间的通信需要经过Instance A → ENI A →SG A →SGB →ENI B →Instane B.</p>

    <ul>
      <li>Reachability Analyzer 会找出失败的环节并图像化的展示出来。</li>
    </ul>
  </li>
</ul>

<h4 id="vpc-peering">VPC Peering</h4>

<ul>
  <li>
    <p>两VPC的对等互联 (CIDR 不能重叠)</p>

    <ul>
      <li>可以跨账户</li>
      <li>可以跨Region</li>
    </ul>
  </li>
  <li>
    <p>连接后效果是感觉两个VPC 就是一个VPC</p>
  </li>
  <li>
    <p>按照流量带宽，按小时计费。</p>
  </li>
  <li>
    <p>A，B，C 三个VPC ， 需要三个Peering</p>
  </li>
  <li>A VPC peering connection is a networking connection between two VPCs that enables you to route traffic between them using private IPv4 addresses or IPv6 addresses. Instances in either VPC can communicate with each other as if they are within the same network. You can create a VPC peering connection between your own VPCs, or with a VPC in another AWS account.
    <ul>
      <li>The （VPC Peering Connection） traffic remains in the private IP space. All inter-region traffic is <strong>encrypted with no single point of failure, or bandwidth bottleneck.</strong></li>
    </ul>
  </li>
  <li>
    <p>两个 VPC Peering 完成后， 还需要设置两个 subnet 下面的 Route Table 可以让VPC下面的EC2之间互相通信</p>

    <ul>
      <li>不同账号的VPC peering 完成后， 在一个VPC 下面的EC2 安全组中可以设置allow 另一个VPC 的账号下的服务直接访问自己</li>
    </ul>

    <p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h0nrlh47eij20e303g744.jpg" alt="img" /></p>
  </li>
</ul>

<h4 id="vpc-endpoints">VPC Endpoints</h4>

<ul>
  <li>允许您向其他 AWS 客户公开私有应用程序，而无需将应用程序公开到互联网，也无需建立 VPC 对等连接。</li>
  <li>通过 Private Link 实现</li>
  <li>AWS 对外的服务都会有一个Public url。</li>
  <li>只支持在 region level， 不能跨region. 如果想跨region , 需要 peering connection</li>
  <li>Fault tolerant
    <ul>
      <li>The VPC endpoint resource is defined as a horizontally scaled, redundant resource, which means it is fault tolerant.</li>
    </ul>
  </li>
  <li>Endpoint 用于让EC2 实例可以通过内网直接访问DynamoDB, S3， CloudWatch , SNS 等AWS服务， 而不是通过EC2 →NATGW → IGW → DynameDB public url 的方式</li>
  <li>好处是节省公网流量， 提高网络响应速度</li>
  <li>EC2 → VPC Endpoint (Private Link) → DynameDB</li>
  <li>需要设置 route table</li>
  <li>确保DNS 解析设置没问题</li>
  <li>有两种VPC Endpoint
    <ul>
      <li>Interface Endpoint
        <ul>
          <li>给Endpoint 帮一个 ENI 网卡（带private IP）, 两个服务通过IP 通信</li>
          <li>支持EC2 访问大部分AWS 服务 （除了S3 和 DynamoDB）</li>
        </ul>
      </li>
      <li>Gateway Endpoint.
        <ul>
          <li>在VPC Endpoint上提供一个gateway,且需要在route table 中设置这个gateway 作为一个tag.</li>
          <li>只支持 S3 和DynameDB</li>
        </ul>
      </li>
      <li>不管是interface 还是 gateway endpoint , 都是通过proxy 把流量连接到API endpoint上的</li>
    </ul>
  </li>
  <li>案例
    <ul>
      <li>公司希望通过SQS 解耦底层应用， 但是担心通过internet 访问SQS 底层绑定的组件有风险。
        <ul>
          <li>解决方案是： 用VPC endpoint 访问SQS</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="vpc-flow-logs">VPC Flow Logs</h4>

<ul>
  <li>获取进入IP 的流量， 包括
    <ul>
      <li>VPC Flow Logs</li>
      <li>Subnet Flow Logs</li>
      <li>ENI Flow Logs</li>
      <li>还会收集 ELB, RDS, ElastiCache , RedShift, NATGW, Transit Gateway 等的网络信息</li>
    </ul>
  </li>
  <li>Flow logs 发送到两个地方
    <ul>
      <li>S3 - 用Athena 查看</li>
      <li>CloudWatch Logs - 用CloudWatch Logs Insights 查看</li>
    </ul>
  </li>
  <li>Flow logs 语法主要部分
    <ul>
      <li>Versioin</li>
      <li>srcaddr &amp; dstaddr 源和目标地址</li>
      <li>srcport &amp; distport 源和目标端口</li>
      <li>action (allow or deny)</li>
    </ul>
  </li>
  <li>题目案例 -（通过Flow Log 的 Action字段（allow /deny） 来troubleshooting 判断是 SG 的问题还是NACL 的问题）
    <ul>
      <li>Incoming request (to EC2)
        <ul>
          <li>如果inbound 被 reject 了， 那么 NACL or SG 都可能有问题</li>
          <li>如果inbound accept ， outbound reject 了， 那一定是NACL 的问题（因为SG 是stateless， 不会阻止outbound）</li>
        </ul>
      </li>
      <li>outcomming request (from EC2)
        <ul>
          <li>如果outbound 被 reject 了， 那么 NACL or SG 都可能有问题</li>
          <li>如果outbound accept ， inbound reject 了， 那一定是NACL 的问题（因为SG 是stateless， 不会阻止inbound）</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="site-to-site-vpn">Site-to-Site VPN</h4>

<ul>
  <li>当客户私有Data center 需要连接VPC 的时候，就需要建立一个 s2s VPN connection
    <ul>
      <li>客户的DC 需要部署一个 Customer Gateway (CGW)
        <ul>
          <li>可以是软件应用或者是硬件设备
            <ul>
              <li>CGW （with public IP）可以直连VGW</li>
              <li>CGW (with private IP) 可以线连接客户的NAT (public IP)， 再连VGW</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>VPC 需要部署一个VPN Gateway (VGW)
        <ul>
          <li>需要设置Subnet 的Route Table ,允许CGW 的IP访问</li>
          <li>需要设置EC2 的 SG ， allow ICMP protocol 的inbound 访问, 才能在on-premise 的机器上ping EC2 instance</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>关键词
    <ul>
      <li>IPSec</li>
    </ul>
  </li>
</ul>

<h4 id="vpn-cloudhub">VPN CloudHub</h4>

<ul>
  <li>客户有多个数据中心，每个数据中心都建立了VPN /DX连接</li>
  <li>客户的多个 VPN /DX 连接到 AWS 的同一个(Virtual Private Gateway )VGW , 就是VPN CloudHub</li>
  <li>好处
    <ul>
      <li>多个数据中心可以互联了</li>
      <li>一条VPN不稳定，可以通过其他VPN 进行弥补， 提高整体稳定性</li>
    </ul>
  </li>
  <li>需要设置VPC 的 dynamic routing 和 route table</li>
  <li>题目：
    <ul>
      <li>客户有多个DC, 都连了 VPN 到 AWS, VPN 供应商不稳定， 需要创建一个backup connection, 通过公网连接多个DCs ， 方案就是 AWS CouldHub
        <ul>
          <li>理由： CloudHub 是多个VPN 连接到同一个VPC , 并且让多个VPN之间也可以互相访问， 有效解决了某个VPN网络不稳定的问题。</li>
        </ul>
      </li>
      <li>总部用了Direct Connection 连接到AWS VPC, 分公司用 site-to-site VPN 连接到AWS VPC, 如何让总部和分公司互联互通。方法是AWS VPN CloudHub
        <ul>
          <li>CloudHub 让 多个通过site to site VPN, direct connection 连接同一个VPC 的 on-premises环境可以互通</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="vpc-连-vpc-endpoint-service-">VPC 连 VPC (Endpoint Service )</h4>

<ul>
  <li>暴露你的VPC 中的服务给其他的VPC</li>
  <li>Peer 是对等双向的； Endpoint 是单向的
    <ul>
      <li>方案3： 通过Endpoint Service 实现
        <ul>
          <li>建立一个Private LINk,</li>
          <li>访问端的VPC 建一个<strong>ENI</strong></li>
          <li>服务端的VPC 建一个<strong>NLB</strong>, 两端 就可以通过VPC Endpoint 来进行访问。</li>
        </ul>
      </li>
      <li>方案1 ： 将服务暴露到外网， 谁都能访问。
        <ul>
          <li>比较复杂， 且会有额外流量费用</li>
        </ul>
      </li>
      <li>方案2 ： VPC之间建立 VPC Peering connection. （Peer 是对等双向的； Endpoint 是单向的）
        <ul>
          <li>一旦VPC 比较多， 要建立的Peering 数字会大幅增加</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="transit-gateway-交通枢纽-gateway">Transit Gateway 交通枢纽 Gateway</h4>

<ul>
  <li>
    <p>如果多个VPC 需要整合到一起， 需要建立多条Peering connection , 比较复杂，</p>
  </li>
  <li>
    <p>可以用过Transit Gateway 作为交通枢纽， 所有VPC、DXGW, VPN connection 都连到 Transit Gateway</p>

    <ul>
      <li>hub-and-spoke (start) 星型结构</li>
    </ul>
  </li>
  <li>
    <p>cross region</p>
  </li>
  <li>
    <p>VPC transit gateway are charged hourly and for traffic throughput ， 挺贵的</p>
  </li>
  <li>
    <p>Cross account sharing</p>

    <ul>
      <li>做了Transit Gateway 还不够， 想要分享资源， 需要通过 RAM 做一个 shared service VPC</li>
      <li>Resource Access manager (RAM) 将一个账号下的资源通过Transit Gateway 分享给其他账号， 具体请看 Resource Access manager 的介绍</li>
    </ul>
  </li>
  <li>
    <p>需要设置路由表来决定到底谁（vpc）和谁(vpc)可以沟通</p>
  </li>
  <li>
    <p>关键词</p>

    <ul>
      <li>IP Multicast
        <ul>
          <li>IP 组播， 将IP数据包传输到一个组播群（Transit Gateway）中，所有该组的成员都可以收到这个数据包的信息。</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h0ocn1afu5j20n80e0q3j.jpg" alt="img" /></p>

<h4 id="vpc-traffic-mirroring-流量镜像">VPC Traffic Mirroring 流量镜像</h4>

<ul>
  <li>
    <p>是VPC 的一个服务， 建立一个Traffic Mirroring,</p>
  </li>
  <li>
    <p>将 VPC 中通过 ENI 的流量， 通过 Traffic Mirroring （可以过滤filter traffic）把流量镜像到一个 NLB 或者 ENI</p>

    <ul>
      <li>NLB 下面 是 Auto Scalling Group , 下面是EC2</li>
    </ul>
  </li>
  <li>
    <p>获取流量</p>

    <ul>
      <li>源： ENI</li>
      <li>目的地： <strong>ENI 或者是 NLB</strong></li>
    </ul>
  </li>
  <li>
    <p>源和目的地 可以是同一个VPC ，也可以是不同的VPC ,</p>

    <ul>
      <li>VPC之间镜像， 需要建立Peering</li>
    </ul>
  </li>
  <li>
    <p>场景：</p>

    <ul>
      <li>流量内容检查</li>
      <li>网络风险监控</li>
      <li>trouble shooting</li>
    </ul>
  </li>
  <li>
    <p>题目：</p>

    <ul>
      <li>问如何获取VPC 内通过IP 的流量
        <ul>
          <li>答案是 VPC Flow Logs, traffic Mirroring,</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="ipv6-in-vpc">IPV6 in VPC</h4>

<ul>
  <li>IPV4 默认打开（关不掉）， IPV6 默认不打开
    <ul>
      <li>打开后EC2 实例最少拥有一个Pirvate IPV4 和 public IPV6</li>
    </ul>
  </li>
  <li>IPV6 都是public IP 地址</li>
  <li>题目：
    <ul>
      <li>如果没有办法launch EC2 实例， 是因为IPV4 被用光了， 解决方法就是给subnet 增加一个新的Cidr IPV4 地址段</li>
    </ul>
  </li>
</ul>

<h4 id="egress-only-internet-gateway-eigw">Egress-Only Internet Gateway （EIGW）</h4>

<ul>
  <li>只出不进的、针对IPV6 的Internet Gateway</li>
  <li>Egress-only internet gateway 是在VPC level， 并不是在public subnet 里面</li>
  <li>类似NAT Gateway ， 帮助private subnet 中的有IPV6 的instance 访问外网用的
    <ul>
      <li>IPV 4 的 instance 还是访问 Nat gateway 去访问外网</li>
    </ul>
  </li>
  <li>需要更新Route Table, 让private subnet 将流量转到Egress-only internet gateway 上
    <ul>
      <li>::/0 表示所有外网的IPV6 的地址</li>
    </ul>
  </li>
</ul>

<p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h0og846v57j20oy0dfq3j.jpg" alt="img" /></p>

<h4 id="vpc-console-wizard-支持的内容">VPC Console Wizard 支持的内容</h4>

<ol>
  <li>VPC with a single public subnet</li>
  <li>VPC with public and private subnets (NAT)</li>
  <li>VPC with public and private subnets and AWS Site-to-Site VPN access</li>
  <li>These three options are valid configurations supported by the Amazon VPC console wizard.
    <ol>
      <li>不支持 VPC with a private subnet only and AWS Site-to-Site VPN acces</li>
      <li>不支持 VPC with public subnet only and site-to-site VPN</li>
    </ol>
  </li>
</ol>

<h3 id="elb">ELB</h3>

<h4 id="elb-1">ELB</h4>

<ul>
  <li>
    <p>暴露唯一的入口 - DNS给下游的target group (EC2 instance, IPs, container, ALB(上游需要是NLB)) . NLB 多提供一个static IP</p>

    <ul>
      <li>要想让实例看到客户的IP 需要通过header 的 X-Forwarded-For 来透ALB传递过来</li>
    </ul>
  </li>
  <li>
    <p>health check (特定端口和网页路径（router），检查200)</p>
  </li>
  <li>
    <p>stickiness (CLB and ALB only)</p>

    <ul>
      <li>cookies
        <ul>
          <li>别用 AWSALB, AWSALBAPP, AWSALBTG</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>ELB 流量分配：</p>

    <ul>
      <li>ELB 可以分配流量给同一个AZ下面的4个实例</li>
      <li>ELB 不能分配流量给不同的两个 region 西面的4个实例（每个region 两个实例）</li>
      <li>ELB 可以分配流量给同一个region 下面两个AZ的实例 （每个AZ 两个实例）</li>
    </ul>
  </li>
  <li>
    <p>cross-zone (cross az)</p>

    <ul>
      <li>打开cross-zone功能的LB ,不管每个az有多少个instance, 都可以让每个instance 获得同样的流量分配</li>
      <li>没有cross az的LB, 每个az均匀分配， 但是下面的instance 就不均匀了</li>
      <li>ALB 默认开启， NLB和CLB默认关闭</li>
    </ul>
  </li>
  <li>cross-region
    <ul>
      <li>ELB 是region scope. 如果需要跨region ,需要借助于Aws Global Accelerator (AGA) 的 跨region 能力；在AGA中创建endpoint group， 把每个region 的 ALB 包含进去。</li>
    </ul>
  </li>
  <li>
    <p>Security Group</p>
  </li>
  <li>
    <p>Type</p>

    <ul>
      <li>
        <p>CLB (classic) L4&amp;7</p>
      </li>
      <li>
        <p>ALB L7 ,</p>

        <ul>
          <li>
            <p>对外暴露的是一个DNS (URL)</p>
          </li>
          <li>
            <p>用二级域名、路径、参数来路由</p>
          </li>
          <li>
            <p>port mapping for dynamic port</p>
          </li>
          <li>
            <p>ALB 可以通过Cognito 来给要访问你的应用的用户做安全认证</p>

            <ul>
              <li>Cognito User Pool 可以让用户通过知名的社交应用的账号（idPs）来登录我们的应用</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>NLB L4</p>

        <ul>
          <li>对外暴露的是一个public IP 地址，允许外部应用访问这个IP地址</li>
          <li>one static ip per az, support assign elastic ip</li>
          <li>NLB 后面可以是Instance ID 作为target
            <ul>
              <li>流量通过被primary network interface 指定的 primary private IP 地址被路由到实例</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>GLB(gateway ) L3</p>

        <ul>
          <li>流量需要进到AWS的第三方应有跑一圈， 然后再出AWS</li>
        </ul>
      </li>
      <li>
        <p>keyword in the exam: GENEVE, Port 6081, Transparent network gateway</p>
      </li>
    </ul>
  </li>
</ul>

<h4 id="target-group">target group</h4>

<ul>
  <li>可以是EC2实例、容器task、Lambda、private ip
    <ul>
      <li>这里的IP 一定是 Private IP</li>
    </ul>
  </li>
  <li>ALB health check 是在 target group level</li>
</ul>

<h4 id="sni-server-name-indication">SNI Server Name Indication</h4>

<ul>
  <li>解决了一个LB下面有多个web 服务需要提供多域名证书的问题。</li>
  <li>方法是在SSL握手的时候就要客户提供域名， 然后根据域名找到对应的SSL证书</li>
  <li>ALB，NLB only</li>
</ul>

<h4 id="connection-draining-deregistration-delay">Connection Draining (Deregistration Delay)</h4>

<ul>
  <li>可以设置当一个实例被发现不健康之后 或者 被terminate 之前， 是否还转流量给他，以及要等多久在terminate</li>
  <li>1 and 3,600 seconds (the default is 300 seconds)</li>
  <li>案例：</li>
</ul>

<ol>
  <li>一个税务软件运行在EC2 实例+CLB + ASG 上， 软件需要花费10分成才能给出请求者答案。 当ASG scale-in 的时候，如何做才能不中断请求者？， 答案是设置 Deregistration delay (connection draining) 为10分钟，让ELB在实例终止前停止发送请求，确保实例有时间可以完成所有未计算完的税务任务。
    <ul>
      <li>默认当ASG 要scale-in 并下线一个实例的时候， ELB 会在实例终止前300秒（5分钟）就不会发送请求给他了， 但是这个例子可能还有一个没完成的计算（10分钟）在运行中</li>
      <li>通过把 Deregistration delay 设置成10分钟， CLB 就会在实例terminate 的10分钟之前停止发送请求给实例。 10分钟后ASG terminate 这个实例。</li>
    </ul>
  </li>
</ol>

<h4 id="asg-auto-scaling-group">ASG auto scaling group</h4>

<ul>
  <li>设置 min, max, actual size 来让实例个数随着请求的多少来增减</li>
  <li>Unified ASG 可以管理的服务包括：
    <ul>
      <li>EC2</li>
      <li>Spot fleets</li>
      <li>DynamoDB</li>
      <li>Aurora Read Replica</li>
      <li>ECS on Fargate
        <ul>
          <li>不包括RDS, RedShift</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>launch configuration/template 负责提前预设好需要加载的实例的配置信息</p>

    <ul>
      <li>Launch Configuration (旧的): 如果需要update ASG, 需要重新建一个launch configuration. 原来的改不了了。</li>
      <li>Launch Template (新的)
        <ul>
          <li>可以有多个版本</li>
          <li>可以建on-demand or spot instance</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>通过CloudWatch alarm 监控 ASG 的实例的性能指标 比如CPU 来决定scale out/in</li>
  <li>ASG的IAM roles 也会分配给它创建的新的EC2实例</li>
  <li>LB 把一个实例设置成了unhealthy, ASG就会terminate 这个实例</li>
  <li>ASG下的实例，不管什么原原因被terminate 掉了， ASG都会自动创建一个和原来的实例一样的新实例</li>
  <li>
    <p>Scaling policy</p>

    <ul>
      <li>Dynamic Scaling policy
        <ul>
          <li>Target Tracking Scaling, 保持CPU40%, or 保持1000个请求数
            <ul>
              <li>擅长处理突然的大流量导致的实例性能下降</li>
            </ul>
          </li>
          <li>Simple/Step Scaling, CPU大于70%加两个， 小于30%减一个</li>
          <li>Step scaling applies “step adjustments” which means you can set multiple actions to vary the scaling depending on the size of the alarm breach. When you create a step scaling policy, you can also specify the number of seconds that it takes for a newly launched instance to warm up.</li>
          <li>Scheduled Actions, 周五10点加10个实例
            <ul>
              <li>设置 desired capacity 的数量为10</li>
              <li>也可以设置 range 为 max=xxx, min=xxx. 但如果题目指定的是固定数字，就需要用 desired capacity.</li>
            </ul>
          </li>
          <li>如果两个policy 都触发了， 会 launch 实例数量最大的那个 policy ，不管是 scall-out 还是 scall-in</li>
        </ul>
      </li>
      <li>Predictive Scaling , AWS AI 帮你增减
        <ul>
          <li>AWS recommends leaving Predictive Auto Scaling in forecast-only mode for at least <strong>48 hours</strong> , but each application is unique, and some applications might require longer.</li>
          <li>案例：
            <ul>
              <li>EC2 实例带有ASG,  后面是DynamoDB, 因为每周2次但是不定期的高流量，需要如何设置ASG
                <ul>
                  <li>Predictive Scaling, 可以帮组我们学习流量曲线，自动伸缩</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Metrics 参数</p>

    <ul>
      <li>CPUUtilization ; CPU使用率</li>
      <li>RequestCountsPerTarget: 每个ect2 Group 的请求数</li>
      <li>Average Network In/Out, IO 是否平均</li>
      <li>Custom metric ， 客户自定义的监控指标， 比如应用请求数据库的次数等。</li>
    </ul>
  </li>
  <li>Scaling Cooldowns .发生scaling 之后需要个冷静的时间， 这个时间内不要再做scaling</li>
  <li>
    <p>ASG Default Termination Policy :</p>

    <ul>
      <li>如果有多个AZ，从最多的实例的那个AZ下手</li>
    </ul>
  </li>
  <li>在最多实例的AZ中挑一个 launch configuration 最老的那个下手</li>
  <li>
    <p>对于不健康的实例的处理逻辑</p>

    <ul>
      <li>ASG 启动了一个新的 saling activity, terminate 掉不健康的实例，然后再创建一个新的实例代替被terminate 掉的实例
        <ol>
          <li>有一个不健康了， 那么就干掉他，然后换个新的</li>
          <li>ASG 干活是一个一个来的（顺序是先干掉，再增加），不会同时进行</li>
        </ol>
      </li>
    </ul>
  </li>
  <li>
    <p>对于rebalancing的处理逻辑(对人为干预的情况进行rebalancing)</p>

    <ul>
      <li>当有人手动删除了实例，就会造成unbalancing</li>
      <li>因为AZ unbalanced, ASG 会自动补偿（compensate）重新平衡（rebalancing），ASG 会launch 两个新的实例，不会在performance or availability 这块妥协。
        <ol>
          <li>因为2个实例被devops团队干掉了， 所以补充两个新的</li>
          <li>Rebalancing 的顺序是 先增加， 再干掉，不会同时进行。</li>
        </ol>
      </li>
    </ul>
  </li>
  <li>Lifecycle Hooks： 当正在进行scale in/out 的时候， 可以设置一个hook, hook 可以调用额外的程序， 比如对意外被terminate 的实例在删掉之前写一些日志来trouble shooting</li>
  <li>
    <p>ASG的 HA</p>

    <ol>
      <li>就算ASG 跨了3个 AZ，最小的HA 依然是2个实例。</li>
      <li>当我们设置ASG 最小的 capacity 是2 时， ASG 会将两个实例分到不同的AZ中。 当流量上升，ASG 会将第3个实例放到第3个AZ中， 当流量下降后，还是会保持2个实例。</li>
    </ol>
  </li>
</ul>

<h4 id="一个实例有问题但是没有被asg-terminate-掉的可能性">一个实例有问题，但是没有被ASG terminate 掉的可能性</h4>

<ul>
  <li>
    <p>Grace period</p>

    <ul>
      <li>ASG 在启动一个新的实例时， 会用 HealthCheckGracePeroid 设置一个时间段，让ELB 不要检查这个实例的健康状态， 直到grace peroid 过期</li>
      <li>grace period 的目的是让实例启动过程中可以把所有的服务启动起来后，再接收ELB的流量</li>
      <li>Grace Period 这段时间内，就算实例的状态不正常， 被ELB 检查出来了， 也不会被terminate 掉</li>
    </ul>
  </li>
  <li>
    <p>Impaired status</p>

    <ul>
      <li>如果一个实例在 impaired status( 受损状态，需要时间自我修复 ) 状态， ASG 不会马上terminate 掉它， 会等几分钟， 等待它自我修复。</li>
    </ul>
  </li>
  <li>
    <p>实例未通过 ELB 运行状况检查状态 （The instance has failed the E</p>

    <p>LB health check</p>

    <p>status）</p>

    <ul>
      <li>ASG 默认情况是使用CloudWatch Alarm 监控 target group 的 健康情况 . 不会使用ELB 的 health check 结果去terminate 一个实例。 因此，ASG 不会终止未通过 ELB 运行状况检查的实例。</li>
    </ul>
  </li>
</ul>

<h4 id="一个实例有问题alb-删了她但是asg-没有换一个新的上来的问题">一个实例有问题，ALB 删了她，但是ASG 没有换一个新的上来的问题：</h4>

<ul>
  <li>ASG 在用基于EC2 的健康检查， ALB 在用基于ALB的健康检查。
    <ul>
      <li>想要避免题目中的问题，<strong>就需要把ALB 和 ASG 都设置成 ALB Based health check</strong></li>
    </ul>
  </li>
</ul>

<h3 id="direct-connect-dx">Direct Connect (DX)</h3>

<h4 id="direct-connection-dx">Direct Connection (DX)</h4>

<ul>
  <li>客户有钱，有混合环境， 且需要高带宽、稳定的网络连接</li>
  <li>1Gb and 10Gb throughput</li>
  <li>AWS 在一些国家地区提供了有专线（当地电信供应商提供）的 location ,比如香港有1个，台湾有2个</li>
  <li>在客户的私有网络和AWS VPC 之间建立一个独享的私有网络
    <ul>
      <li>网络需要建立在 特定的 Location 上</li>
    </ul>
  </li>
  <li>通过DX, 可以同时访问AWS上的public 和 private resource</li>
  <li>需要在VPC 上建立一个 VGW (Virtual Private Gateway)
    <ul>
      <li>virtual private gateway 是一个 highly available 的服务 ，有 n个9s. 通过硬件backup 在同一个region 的两个data center, 符合HA，但是不是 fault tolerant</li>
    </ul>
  </li>
  <li>支持IPV4 和 IPV6</li>
</ul>

<p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h0ntx778btj20o90ddq3i.jpg" alt="img" /></p>

<ul>
  <li>
    <p>DX type</p>

    <ul>
      <li>Dedicated connection （1-10G 的带宽）
        <ul>
          <li>向AWS 提交申请， AWS再去找当地电信合作伙伴完成</li>
        </ul>
      </li>
      <li>Hosted Connection （50m， 500m … 10g 选项）
        <ul>
          <li>向电信商提交申请</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>建设好DX 一般要1个月以上， 等不急的就不要用了</p>
  </li>
  <li>
    <p>Encryption</p>

    <ul>
      <li>DX 因为是专线内网连接，默认不加密传输数据</li>
      <li>可以通过 DX + VPN 的方案来给传输的数据进行加密</li>
    </ul>
  </li>
  <li>
    <p>DX Resiliency</p>

    <ul>
      <li>支持客户data center 数量 增长
        <ul>
          <li>每个date center 可以建立一个新的 DX 去连接所在的Region 的同一个AWS VPC</li>
        </ul>
      </li>
      <li>支持DX 的高可用
        <ul>
          <li>同一个DX location可以建设两个connection ， 互相backup</li>
        </ul>
      </li>
      <li>最大化的resiliency
        <ul>
          <li>设置两条DX, 与多于一个DX location 的不同设备进行终端连接
            <ol>
              <li>Opt for two separate DX connections terminating on separate devices in more than one DX location.</li>
            </ol>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="direct-connect-gateway">Direct Connect Gateway</h4>

<ul>
  <li>让客户的date center 通过DX 连接不同Region 的多个VPC ， 需要使用Direct Connect Gateway</li>
  <li>多个VPC 之间设置了Direct Connect Gateway
    <ul>
      <li>客户先通过DX 访问到第一个VPC ,然后再通过DX Gateway 访问其他region的VPC</li>
    </ul>
  </li>
</ul>

<p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h0nu3p3431j20nk0aydg8.jpg" alt="img" /></p>

<h3 id="网络成本-xxx每gb">网络成本 （xxx$/每GB）</h3>

<ul>
  <li>
    <p>同一个AZ下的实例间内网进行通信 free</p>
  </li>
  <li>
    <p>不同AZ下的实例通信</p>

    <ul>
      <li>内网 0.01</li>
      <li>外网 0.02</li>
    </ul>
  </li>
  <li>
    <p>不同 Region 的实例通信</p>

    <ul>
      <li>外网 0.02</li>
    </ul>
  </li>
  <li>
    <p>Egress &amp; Ingress (出口流量/进口流量)</p>

    <ul>
      <li>
        <p>AWS 只对Engress 计费。 Ingress 基本上是free</p>
      </li>
      <li>
        <p>尽量减少engress 的流量</p>

        <ul>
          <li>比如用户要从AWS RDB请求100M的数据到客户端进行计算， 优化方法是把计算在AWS内部做完， 把结果返回给客户端
            <ul>
              <li>把能预先做的在VPC内部做掉， 只把结果发出去</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>S3</p>

        <ul>
          <li>Ingress 0 ,</li>
          <li>Egress 0.09
            <ul>
              <li>S3 transfer Acceleration +0.04 ~ 0.08</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>S3 Cross Region Replication</p>

        <ul>
          <li>Egress 0.02</li>
        </ul>
      </li>
      <li>
        <p>S3TA （Transfer Acceleration） 只有成功了才收钱， 不成功不收钱</p>
      </li>
      <li>
        <p>CloudFront</p>

        <ul>
          <li>Egress 0.085</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>省钱方法</p>

    <ul>
      <li>尽量用 private IP 通信</li>
      <li>尽量在同一AZ中用内网处理大流量的数据通信（但会有HA的问题），不要跨AZ</li>
      <li>EC2 访问 S3/Dynamo DB的时候要通过 Endpoints， 不要走公网（EC2→nat gateway → internet gateway → internet → S3）</li>
      <li>把数据计算在内部做完， 把结果发出去</li>
    </ul>
  </li>
</ul>

<h2 id="监控">监控</h2>

<h3 id="cloudwatch">CloudWatch</h3>

<h4 id="cloudwatch-1">CloudWatch</h4>

<ul>
  <li><strong>必须装了CloudWatch agent 才能监控</strong></li>
  <li>
    <p>CloudWatch 给每个AWS服务都设置了 Metrics</p>
  </li>
  <li>
    <p>需要在每个AWS服务（比如EC2）上安装一个CloudWatch Agent, 才能把日志传回来</p>
  </li>
  <li>
    <p>Metric</p>

    <ul>
      <li>是一些变量， 比如CPUUtilization, Networkin …</li>
      <li>属于某个 Namespace</li>
      <li>Demension 是 Metric的属性(最多10个)， 比如
        <ul>
          <li>instance id</li>
          <li>environment</li>
          <li>…</li>
        </ul>
      </li>
      <li>标准Metric
        <ul>
          <li>监控频率
            <ul>
              <li>默认5分钟刷一次standard Metrics</li>
              <li>开启 Detail Monitoring 可以每1分钟刷一次标准Metrics</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Custom Metrics 自定义指标
        <ul>
          <li>比如监控内存，磁盘，登录用户数等非标准Metrics</li>
          <li>使用 API <strong>PutMetricData 来设置</strong></li>
          <li>监控频率 （间隔时间）
            <ul>
              <li>可以使用 StorageResolution API 设置， 两个参数
                <ul>
                  <li>标准60秒</li>
                  <li>high resolution: 1 秒</li>
                </ul>
              </li>
              <li>需要确保EC2的时间是正确的</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Metrics filter expression (过滤表达式) 可以触发 CloudWatch Alarm , 比如发现error 就报警</li>
    </ul>
  </li>
  <li>
    <p>Dashboard</p>

    <ul>
      <li>CloudWatch 是 global service, 所以可以设置dashboard 看多个account 和 region 的数据</li>
      <li>可以设置dashboard的时区</li>
      <li>可以设置刷新间隔10s 到 15m</li>
      <li>可以分享给非AWS账户， 但需要通过Cognito SSO 登录查看</li>
    </ul>
  </li>
  <li>
    <p>CloudWatch Logs ,</p>

    <ul>
      <li>通过监控、收集其他服务产生了日志</li>
      <li>Log Groups</li>
      <li>Log Stream</li>
      <li>可以定义Log 失效时间， （永不过期， 30天等）</li>
      <li><strong>Subscription Filter</strong>
        <ul>
          <li>一个用于过滤日志的 instance, 通过Metrics filter expression (过滤表达式) 进行过滤。</li>
        </ul>
      </li>
      <li><strong>CloudWatch Logs Aggregation</strong> (日志整合)
        <ul>
          <li>可以把不同region 的账号产生的cloudwatch logs 进行整合。 整合后再发给下游服务</li>
        </ul>
      </li>
      <li>上游（被监控对象）
        <ul>
          <li>EC2 (log默认不会发送到CloudWatch, 需要安装CloudWatch Agent, 并设置EC2权限)</li>
          <li>SDK</li>
          <li>CloudWatch Logs Agent （old）</li>
          <li>CloudWatch <strong>Unified Agent</strong> (new 支持更多的Metrics)</li>
          <li>Beanstalk</li>
          <li>ECS</li>
          <li>Lambda</li>
          <li>VPC Flow Logs</li>
          <li>API Gateway</li>
          <li>CloudTrail</li>
          <li>Route53</li>
        </ul>
      </li>
      <li>下游 （CloudWatch logs 可以发送给:）
        <ul>
          <li>S3</li>
          <li>Kinesis Data Stream</li>
          <li>Kinesis Data Firehose</li>
          <li>Lambda</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="cloudwatch-alarm">CloudWatch Alarm</h4>

<ul>
  <li>用于触发报警， 单位包括
    <ul>
      <li>抽样 sampling</li>
      <li>%</li>
      <li>Max</li>
      <li>Min</li>
      <li>etc.</li>
    </ul>
  </li>
  <li>3个主要的目标
    <ul>
      <li>EC2</li>
      <li>EC2 Autoscaling</li>
      <li>SNS</li>
    </ul>
  </li>
  <li>CLoud Watch Alarm直接就可以重启，停止， 启动， terminate EC2， 不需要额外其他服务参与。</li>
  <li>Cloud Watch （Alarm） 直接就可以调用SNS 给管理员发通知， 不需要调用Lambda 服务。</li>
</ul>

<h4 id="cloudwatch-event">CloudWatch Event</h4>

<ul>
  <li>可以被触发的事件 (夹到AWS 服务当中)</li>
  <li>比如：
    <ul>
      <li>EC2实例启动，CodeBuild失败，</li>
      <li>可以和CloudTrail 集成来夹到 API call 当中</li>
    </ul>
  </li>
  <li>可以放到Cron 中， 定时启动</li>
  <li>事件触发后， 会有一个Json文件发送到target 服务中
    <ul>
      <li>Target 服务包括
        <ul>
          <li>Lambda, ECS task</li>
          <li>SQS, SNS, Kinesis,</li>
          <li>Step Functions, CodePipeline, CodeBuild</li>
          <li>SSM, EC2 Action</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="eventbridge">EventBridge</h3>

<h4 id="eventbridge-1">EventBridge</h4>

<ul>
  <li>
    <p>是CloudWatch Event 的升级版</p>
  </li>
  <li>
    <p>触发来源</p>

    <ul>
      <li>
        <p>Default event bus : 默认事件总线， 就是CloudWatch Event （AWS 服务）触发events</p>
      </li>
      <li>
        <p>Custom Event bus: 定制事件总线，我们自己的应用触发Event</p>
      </li>
      <li>
        <p>Partner Events： 第三方事件， 从 SaaS 服务或第三方应用接收events</p>

        <ul>
          <li>第三方应用包括
            <ul>
              <li>Zendesk</li>
              <li>DataDog</li>
              <li>Segment</li>
              <li>Auth0</li>
              <li>…</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>EventBridge Schema Registry</p>
  </li>
  <li>
    <p>EventBridge 是唯一可以和第三方SaaS partner 整合的 event-based 服务，是SaaS 和 AWS 服务的沟通桥梁</p>

    <ol>
      <li>AWS 服务包括 SNS, Lambda, SQS， Kynesis KDS KDF等等</li>
    </ol>
  </li>
  <li>
    <p>考试：</p>

    <ul>
      <li>看到有SaaS， 第三方 ，feed, 要解耦， 那么就选Event Bridge</li>
    </ul>
  </li>
</ul>

<h3 id="cloudtrail">CloudTrail</h3>

<h4 id="cloudtrail-1">CloudTrail</h4>

<ul>
  <li>
    <p>如果有人删了一个资源， 就去CloudTrail 查</p>
  </li>
  <li>
    <p>CloudTrail 为AWS账户提供 治理，审计， 合规</p>
  </li>
  <li>
    <p>可以查看账户的历史事件，包括</p>

    <ul>
      <li>Console</li>
      <li>SDK/API</li>
      <li>CLI</li>
      <li>IAM User/IAM Role (AWS服务的调用)</li>
    </ul>
  </li>
  <li>
    <p>可以把log 发到 CloudWatch Log or S3</p>
  </li>
  <li>
    <p>跨Region</p>
  </li>
  <li>
    <p>默认保留90天</p>
  </li>
  <li>
    <p>上游</p>

    <ul>
      <li>CloudTrail Events</li>
    </ul>
  </li>
  <li>
    <p>下游</p>

    <ul>
      <li>展示在<strong>Console</strong> 让管理员看到(只 能保存90天）</li>
      <li>存到<strong>S3</strong>（怕删，就放这， 用Athena）, or CloudWatch log</li>
      <li>发到<strong>Event Bridge</strong> 中 （让别人知道）</li>
    </ul>
  </li>
</ul>

<h4 id="cloudtrail-events">CloudTrail Events</h4>

<ul>
  <li>CloudTrail Event 是 Cloud 的上游，最终会将Event 传给CloudTrail 。 分三种
    <ul>
      <li>Management Events, 管理型事件
        <ul>
          <li>对服务进行的操作， 比如删除S3 Bucket</li>
          <li>默认会被记录</li>
        </ul>
      </li>
      <li>Data Events, 数据型事件
        <ul>
          <li>对数据进行的操作， 比如删除S3 Bucket 中的一个object.</li>
          <li>默认不会被记录</li>
        </ul>
      </li>
      <li>Insights Events
        <ul>
          <li>帮助我们检查账户中的不寻常的操作记录， 尤其是Write Events</li>
          <li>发现不正常就触发<strong>CloudTrail Insight Events</strong></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="aws-config">AWS Config</h3>

<h4 id="aws-config-1">AWS Config</h4>

<ul>
  <li>查看所有AWS服务的配置信息和历史记录</li>
  <li>给AWs资源做审计和合规
    <ul>
      <li>是验证配置的合规， 而不是人的合规。</li>
    </ul>
  </li>
  <li>记录所有的配置和变化</li>
  <li>一些常问的问题
    <ul>
      <li>是否有没有限制的SSH访问安全组</li>
      <li>bucket 是否有外网访问</li>
      <li>ALB 之前的配置变化是什么</li>
    </ul>
  </li>
  <li>可以设置将变化发给SNS</li>
  <li>可以跨Region</li>
  <li>可以将配置数据存到S3中， 通过Athena分析</li>
  <li>Config Rule,
    <ul>
      <li>是验证规则</li>
      <li>利用AWS 对超过75个服务的config 设定规则
        <ul>
          <li>比如
            <ul>
              <li>验证是否所有的EC2 都用了t2.micro</li>
              <li>验证EC2 的 84端口是否对外暴露</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>不会阻止action 的发生</li>
      <li>Config Rules- Remediation
        <ul>
          <li>config rule 虽然不能阻止action, 但可以将发现的问题发送给 <strong>Auto-Remediation Action</strong> 处理， 将配置改回原来正确的样子</li>
        </ul>
      </li>
      <li>Config Rules - Notification
        <ul>
          <li>可以将发现的问题发送给 EventBridge/ SNS 进行处理</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Pricing: no free tier
    <ul>
      <li>$0.003 per configuration item recorded per region</li>
      <li>$0.001 per config rule evaluation per region</li>
    </ul>
  </li>
</ul>

<h4 id="cloudwatch-cloudtrail-config-的区别">CloudWatch, CloudTrail, Config 的区别</h4>

<ul>
  <li>CloudWatch 基本上是监控系统性能指标</li>
  <li>CloudTrail 是对人的监督。 是监控AWS账号在Console, CLI, SDK/API 对AWS服务操作的跟踪记录。</li>
  <li>Config, 是对服务的配置信息的监督。 记录配置的变化， 通过rule 来检查资源的合规性， 是对资源的检查， 不是对人。</li>
  <li>例子 （ALB）
    <ul>
      <li>CloudWatch 监控ALB 的连接进程数</li>
      <li>CloudTrail 监控谁通过API call 修改了ALB 的配置</li>
      <li>Config 通过rule 监控ALB 的配置是否被修改</li>
    </ul>
  </li>
</ul>

<h3 id="x-ray">X-Ray</h3>

<h4 id="x-ray-x光">X-ray X光</h4>

<ul>
  <li>可以跨账户调试和跟踪数据， 并在一个账户中集中可视化</li>
  <li>AWS X-Ray 可帮助开发人员分析和调试生产、分布式应用程序，例如使用微服务架构构建的应用程序。 使用 X-Ray，您可以了解您的应用程序及其底层服务的执行情况，以识别和排除性能问题和错误的根本原因。 X-Ray 在请求通过您的应用程序时提供端到端的视图，并显示应用程序底层组件的地图。</li>
  <li>您可以使用 X-Ray 跨 AWS 账户收集数据。 X-Ray 代理可以承担将数据发布到与其正在运行的帐户不同的帐户的角色。 这使您能够将数据从应用程序的各个组件发布到中央帐户。</li>
  <li>案例：
    <ul>
      <li>提到一个多业务部门的公司， 每个部门以自己的AWS账户， 希望可以跨账户调试和跟踪数据， 并在一个账户中集中可视化， 最好的方案是 ： X-ray （x射线） ， 跨账号跟踪调试数据</li>
    </ul>
  </li>
</ul>

<h4 id="cloudtrail-cloudwatch-vpc-log-aws-config-x-ray-的区别">CloudTrail, CloudWatch, VPC Log, AWS Config, X-Ray 的区别</h4>

<ol>
  <li>CloudTrail 是跟踪人的行为的；</li>
  <li>CloudWatch 是监控AWS服务的性能指标的；</li>
  <li>VPC log 是跟踪进出VPC的网络IP的</li>
  <li>AWS Config, 是对服务的配置信息的监督。 记录配置的变化， 通过rule 来检查资源的合规性， 是对资源的检查， 不是对人。</li>
  <li>X-ray - 跨账号跟踪调试数据， Debug。</li>
</ol>

<h2 id="安全">安全</h2>

<h3 id="kms">KMS</h3>

<h4 id="kms-1">KMS</h4>

<ul>
  <li>
    <p>提供 Encryption 服务</p>
  </li>
  <li>
    <p>每次请求KMS 只能加密4k的数据， 如果需要加密更大的数据， 需要使用 <strong>Envelope Encryption</strong></p>
  </li>
  <li>
    <p>两种类型的Key,</p>
  </li>
  <li>
    <p>第一种：Aws Managed Service keys</p>

    <ul>
      <li>AWS 已经创建好的key, 不需要我们知己创建， 直接就可以用来去加密EBS, S3, RDS 等</li>
    </ul>
  </li>
  <li>
    <p>第二种：Customer Master Key (CMK)</p>

    <ul>
      <li>
        <p>自建的Key</p>

        <ul>
          <li>CMK 不能直接被删掉，会进入pending deletion 状态。 7 days up to a maximum of 30 days. The default waiting period is 30 days。 误删除可以找回来</li>
        </ul>
      </li>
      <li>
        <p>分如下两种</p>
      </li>
      <li>
        <p>Symmetric （AES-256 keys） 对称加密</p>

        <ul>
          <li>
            <p>一个key 进行加密和解密</p>
          </li>
          <li>
            <p>只能通KMS API 来使用这个key</p>
          </li>
          <li>
            <p>场景：</p>

            <ul>
              <li>AWS 内部不需要外部用户访问的数据，可以用对称加密</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>Asymmetric (RSA &amp; ECC key pairs) 非对称加密</p>

        <ul>
          <li>两个key, 一个公钥，一个私钥</li>
          <li>加密用公钥， 解密用私钥</li>
          <li>公钥可以下载，私钥通过KMS API 访问</li>
          <li>场景：
            <ul>
              <li>在外部的用户不能使用KMS API, 就需要用对称加密， 下载个公钥加密， 然后到了AWS 再用私钥解密</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="kms-key-policy">KMS Key Policy</h4>

<ul>
  <li>控制访问KMS Keys,</li>
  <li>类型
    <ul>
      <li>default KMS key Policy
        <ul>
          <li></li>
        </ul>
      </li>
      <li>custom KMS key policy
        <ul>
          <li>定义可以访问KMS Key 的用户和角色</li>
          <li>定义谁可以管理key</li>
          <li>在跨账号访问KMS Key的时候可以用</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="kms-automatic-key-rotation">KMS Automatic Key Rotation</h4>

<ul>
  <li>自动key 刷新
    <ul>
      <li>只在客户管理的CMK 使用</li>
      <li>开启后，每隔1年刷新一次</li>
      <li>刷新后Key ID 保持不变</li>
      <li>老的key不会被删掉， 还会保留， 可以解密原来用老的key 加密过的内容</li>
    </ul>
  </li>
  <li>手动key 刷新
    <ul>
      <li>刷新时间自己定</li>
      <li>新的key 有另一个不同的ID
        <ul>
          <li>最好新老key 使用同一个 alias , 避免修改代码</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="分享encrypted-内容给其他account">分享Encrypted 内容给其他account</h4>

<ul>
  <li>分享了用KMS (CMK)加密过的内容给其他账号， 也需要把 KMS CMK 分享给人家</li>
  <li>场景
    <ul>
      <li>EBS</li>
    </ul>
  </li>
</ul>

<h3 id="ssm-parameter-store">SSM Parameter Store</h3>

<h4 id="ssm-parameter-store-1">SSM Parameter Store</h4>

<ul>
  <li>用于存储机密信息
    <ul>
      <li>最简单的方法： 也可以通过把用户名密码放在环境变量中加密保存，然后在通过run time 来读取并解密。</li>
      <li>Parameter Store 是更高级的保存方法</li>
    </ul>
  </li>
  <li>是serverless 服务</li>
  <li>使用KMS 进行加密</li>
  <li>有version 功能</li>
  <li>可以给CloudWatch 发 Notifiction</li>
  <li>存放方式 例子展示
    <ul>
      <li>/my-department/
        <ul>
          <li>my-app/
            <ul>
              <li>dev/
                <ul>
                  <li>db-url</li>
                  <li>db-password</li>
                </ul>
              </li>
              <li>prod/
                <ul>
                  <li>db-url</li>
                  <li>db-password</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Parameters Policies （针对高级参数）
    <ul>
      <li>可以设置TTL, 过期后提醒需要对机密信息进行更新</li>
      <li>会发送notification 给 cloudWatch Event</li>
    </ul>
  </li>
</ul>

<h3 id="secrets-manager">Secrets Manager</h3>

<h4 id="secrets-manager-1">Secrets Manager</h4>

<ul>
  <li>存放机密信息， 比如数据库的用户名密码等明文配置信息</li>
  <li>比 Parameter Store 更适合存放数据库的密码</li>
  <li>和 SSM Parameter Store 很像，区别是
    <ul>
      <li>强制在xx天后进行更新</li>
      <li>帮你自动更新机密（用Lamdba）</li>
      <li>已经整合了RDS (mysql, postgresql, aurora)</li>
      <li>使KMS 加密</li>
    </ul>
  </li>
  <li>考试关键字
    <ul>
      <li>如果考试中问到RDS 的密码需要保密管理， 那么就是 Secrets Manager</li>
    </ul>
  </li>
</ul>

<h3 id="cloudhsm">CloudHSM</h3>

<h4 id="cloudhsm---hardware-security-module">CloudHSM - Hardware Security Module</h4>

<ul>
  <li>KMS 使用软件进行加密</li>
  <li>CloudHSM 是AWS提供的， 使用专用的硬件模块来管理加密密钥并完全控制它们</li>
  <li>让客户通过CloudHSM 硬件来完全自助的管理自己的加密key</li>
  <li>客户的应用需要安装<strong>CloudHSM client softward</strong></li>
  <li>对应的AWS 加密服务是 <strong>SSE-C</strong>, 因为CloudHSM 是管理自己的key , 而不是自己加密，加密解密还是在AWS上用SSE-C</li>
  <li>ClouHSM 可以和其他AWS 存储服务集成，比如EBS, EFS 等</li>
  <li>complete control of encryption key lifecycle management.</li>
  <li>immediately remove the key material and audit key usage independently of AWS CloudTrail</li>
  <li>should integrate with other storage services that will be used on AWS</li>
  <li>CloudHSM HA
    <ul>
      <li>一个CloudHCS client, 两个CloudHCM (服务端)</li>
    </ul>
  </li>
</ul>

<h3 id="firewall-manager">Firewall Manager</h3>

<h4 id="firewall-manager-1">Firewall Manager</h4>

<ul>
  <li>AWS Firewall Manager 是一项安全管理服务</li>
  <li>允许您跨 AWS org 中的账户和应用程序集中配置和管理防火墙规则。</li>
  <li>它与 AWS org集成</li>
  <li>支持的服务
    <ul>
      <li>AWS WAF</li>
      <li>AWS Shield Advanced 保护</li>
      <li>VPC 安全组</li>
      <li>AWS Network Firewalls (网络防火墙规则)</li>
      <li>Amazon Route 53 Resolver DNS Firewall rules</li>
    </ul>
  </li>
</ul>

<h4 id="waf-shield-security-group-firewall-manager-的总结">WAF, Shield, Security Group, Firewall Manager 的总结</h4>

<ul>
  <li>WAF 为 ALB, API Gateway, CloudFront设置规则</li>
  <li>Shield 为 ALB, CLB, EIP, CloudFront 防止DDOS</li>
  <li>Security Group 为VPC 内 EC2, 带ENI 的资源 提供 inbound outbound 的限制（allow）</li>
  <li><strong>FirewallManager 是在org level 对整个公司的防火墙做统一配置管理</strong></li>
</ul>

<h3 id="aws-shield">AWS Shield</h3>

<h4 id="aws-shield-1">AWS Shield</h4>

<ul>
  <li>防止DDos 攻击的工具</li>
  <li>分两种
    <ul>
      <li>AWS Shield Standard
        <ul>
          <li>免费， 可以防御网络层 Layer3, Layer4 的 SYN/UDP 攻击</li>
        </ul>
      </li>
      <li>AWS Shield Advanced
        <ul>
          <li>3000刀每月， 可以针对EC2, ELB, CloudFront, Global Accelerator, Rout53进行重点防御</li>
          <li>可以和AWS 的 DDOS Response Team 直接联系</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>可防御对象包括
    <ul>
      <li>Route53</li>
      <li>CloudFront</li>
      <li>ALB</li>
      <li>CLB</li>
      <li>EIP</li>
    </ul>
  </li>
</ul>

<h3 id="waf">WAF</h3>

<h4 id="aws-waf---web-application-firewall">AWS WAF - Web Application Firewall</h4>

<ul>
  <li>
    <p>保护web 应用避免恶意攻击（layer 7 for http ）</p>
  </li>
  <li>
    <p>web应用层保护</p>
  </li>
  <li>
    <p>WAF 可以部署在</p>

    <ul>
      <li>ALB</li>
      <li>API Gateway</li>
      <li>CloudFront</li>
    </ul>
  </li>
  <li>
    <p>定义了 Web ACL</p>

    <p>(Access Control List)</p>

    <ul>
      <li>ACL 是WAF 部署在服务上的具体配置</li>
      <li>ACL 的 Rule 包含了
        <ul>
          <li>IP 地址</li>
          <li>HTTP Header</li>
          <li>HTTP Body</li>
          <li>URI String</li>
        </ul>
      </li>
      <li>可以预防的攻击包括
        <ul>
          <li>SQL Injection</li>
          <li>Cross=site scripting (XSS)</li>
          <li></li>
        </ul>
      </li>
      <li>通过 <strong>Geo_match</strong> 来blok 一些国的访问</li>
      <li>通过 <strong>Rate-based Rule</strong> 防止DDOS 攻击 （overwhelming attack ((过载攻击))）（通过统计并发的事件）</li>
    </ul>
  </li>
  <li>
    <p>例题：</p>

    <ul>
      <li>应用部署在了EC2上， 包含了敏感个人信息， 需要防范各种恶意攻击。 公司选用了 WAF. 正确使用 WAF 的方案是？
        <ol>
          <li>创建一个CloudFront distribution for EC2, 部署 WAF 到 CloudFront 来提供必要的安全保证
            <ol>
              <li>WAF 可以在 edge 端就完成安全防护，危险不会触及到实例。</li>
              <li>WAF 也可以运行在ALB 和 API Gateway 上面s</li>
            </ol>
          </li>
        </ol>
      </li>
    </ul>
  </li>
</ul>

<h4 id="关于允许或者不允许某些国家的访问">关于允许或者不允许某些国家的访问</h4>

<ul>
  <li>需要block 掉某些国家的访问， 用WAF, 和 CloudFront Geo Restriction ， NACL 都可以
    <ul>
      <li>WAF 是从VPC 的角度来block, 通过IP的方式 block 某个国家， 通过白名单允许某个国家。</li>
      <li>Geo Restriction 是从edge 的角度block . 不属于VPC. 如果题目中没有提到CloudFront 、edge 之类的字眼， 那就选WAF 吧</li>
      <li>NACL 是禁止IP地址进入</li>
    </ul>
  </li>
</ul>

<h4 id="关于block-一个国家但又需要允许这个国家的一个ip的访问">关于block 一个国家，但又需要允许这个国家的一个IP的访问</h4>

<p>公司的应用跑在AWS上 ALB + EC2 + WAF ,  希望可以block 两个国家的访问应用， 但还需要其中一个国家的一个开发人员可以访问应用。 可以捆绑的两个解决方案是：</p>

<ol>
  <li>Use <strong>WAF geo match</strong> statement listing the countries that you want to block</li>
  <li>Use <strong>WAF IP set</strong> statement that specifies the IP addresses that you want to allow through</li>
  <li>解释：
    <ol>
      <li>WAF geo match - 把想要block 的国家名字放进去就可以了</li>
      <li>WAF IP set - 把想要允许的IP放进去就可以了</li>
    </ol>
  </li>
</ol>

<h3 id="guardduty">GuardDuty</h3>

<h4 id="guardduty---人工智能保安">GuardDuty - 人工智能保安</h4>

<ul>
  <li>人工智能的的威胁发现， 保护AWS account</li>
  <li>主要监控网络层的用户访问</li>
  <li>需要输入数据源包括
    <ul>
      <li>CloudTrail Logs</li>
      <li>VPC Flow Logs</li>
      <li>DNS Logs
        <ul>
          <li>好记的方法就是进大门(DNS log)， 进小门(VPC log)， 进房间（CloudTrail Events）</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>发现异常后， 通过CloudWatch Event rule 发送notification 给 SNS 或者 Lambda 处理</li>
  <li>可以保护 加密货币–<strong>Cryptourrency</strong> Attacks</li>
</ul>

<h3 id="inspector">Inspector</h3>

<h4 id="inspector-1">Inspector</h4>

<ul>
  <li>针对EC2 实例的应用安全分析工具</li>
  <li>应用实例层的安全保护</li>
  <li>可以分析OS 漏洞, 网络访问</li>
  <li>需要在instance 上安装 Inspector agent</li>
  <li>分析后，会得到一个report , 列出所有的弱点</li>
  <li>可以发送通知给SNS</li>
  <li>Inspector 的 security assessments 可以检查 EC2 上的 vulnerabilities (弱点/漏洞)</li>
</ul>

<h3 id="macie">Macie</h3>

<h4 id="macie-1">Macie</h4>

<ul>
  <li>人工智能产品， 发现隐私数据并对数据进行保护</li>
  <li>数据层面的安全保护</li>
  <li>PII (personal identifiable information)</li>
  <li>主要服务对象是S3 Bucket</li>
</ul>

<h2 id="信息流">信息流</h2>

<h3 id="sns">SNS</h3>

<h4 id="sns-1">SNS</h4>

<ul>
  <li>
    <p>通过订阅模式把一个消息发给多个接收者</p>
  </li>
  <li>
    <p>pub (Topic) &amp; sub</p>
  </li>
  <li>
    <p>Topic 是 SNS 消息发送者</p>

    <ul>
      <li>可以有10万个topic</li>
      <li>类型
        <ul>
          <li>standard</li>
          <li>FIFO
            <ul>
              <li>进入topic 的消息是按顺序进入， 出去也是按顺序被订阅者接收到</li>
              <li>主要目的是为了让SQS FIFO 作为订阅者可以按顺序处理消息</li>
              <li>Standard SQS 不能订阅 FIFO SNS</li>
              <li>SNS Fifo <strong>有去重功能</strong>， 两种方法
                <ul>
                  <li>由publisher 给每个消息指定deduplication ID</li>
                  <li>由SNS FIFO 通过MD5 message content 来自动生成deduplication ID</li>
                </ul>
              </li>
              <li>关键字：
                <ul>
                  <li>Odering</li>
                  <li>Deduplication (去重)</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Sub</p>

    <ul>
      <li>
        <p>可以有1千万个订阅者，</p>
      </li>
      <li>
        <p>会一次性拿走所有在SNS中的消息</p>
      </li>
      <li>
        <p><strong>Message Filtering</strong></p>

        <p>可以帮助订阅者过滤掉不需要的消息</p>

        <ul>
          <li>场景： 发送订单到SNS, 后面接fan out 到SQS, 每个SQS 通过Message Filtering 获取不同类型的订单分别进行不同类型的处理</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>上游（发送信息给SNS）</p>

    <ul>
      <li>CloudWatch Alarm</li>
      <li>ASG notification</li>
      <li>S3 bucket event</li>
      <li>CloudFormation state change</li>
      <li>etc..</li>
    </ul>
  </li>
  <li>
    <p>下游 （订阅者）</p>

    <ul>
      <li>SQS</li>
      <li>http/https</li>
      <li>lambda</li>
      <li>email</li>
      <li>SMS</li>
      <li>mobile notification</li>
      <li>如果使用SNS来解耦，最 appropriate 的 订阅者是：
        <ul>
          <li>SQS</li>
          <li>http/https</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Encription</p>

    <ul>
      <li>in-flight HTTPS API</li>
      <li>at-rest KMS, client-side encription</li>
    </ul>
  </li>
  <li>
    <p>Security</p>

    <ul>
      <li>IAM plolicy 控制访问SNS API (user leve)</li>
      <li>SNS Access Policies ( 和 S3 Access Policy 一个原理) （service level）
        <ul>
          <li>支持跨账号访问SNS</li>
          <li>控制其他服务发送信息给SNS Topic的权限</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="fan-out-模式">fan out 模式</h4>

<ul>
  <li>原理
    <ul>
      <li>一个SNS 后面接一堆SQS</li>
      <li>每个SQS 接收到同样的消息， 但是每个SQS 负责处理不同的任务</li>
    </ul>
  </li>
  <li>好处
    <ul>
      <li>完美的decoupled 模型</li>
      <li>把一个工作分解成不同任务， 并行处理， 加快速度</li>
      <li>防止数据丢失
        <ul>
          <li>没用Fan out 模式， SDK 发送信息给多个SQS 是轮询方式， 没轮询完挂了，就会造成有的SQS 没收到信息。</li>
          <li>用了Fan out 模式， SDK 发个信息给SNS, 所有SQS 都会收到SNS的推送， 不会丢数据。</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>需要让SQS access policy允许 SNS 发送信息给它</li>
  <li>Enhanced Fan Out 模式
    <ul>
      <li>Kinesis + SNS + SQS</li>
    </ul>
  </li>
</ul>

<h3 id="sqs">SQS</h3>

<h4 id="sqs-1">SQS</h4>

<ul>
  <li>capacity
    <ul>
      <li>自动伸缩， 不需要担心吞吐量</li>
      <li>SQS 可以支持对不同吞吐量的微服务，不同处理速度的微服务进行解耦， 增加了 failt tolerance</li>
    </ul>
  </li>
  <li>pricing
    <ul>
      <li>请求次数+数据传输量 按月收费
        <ul>
          <li>次数：100万个以后按次收费，越多单价越便宜</li>
          <li>传输量：进不收费，出在10T以后收费，越多单价越便宜</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Producer &amp; Consumer 发送者、接收者
    <ul>
      <li>可以增加Consumer 的数量来增加处理的吞吐量， 比如用ASG 里面的EC2 作为 consumer 处理SQS中的消息。</li>
      <li>通过CloudWatch (Queue Length Metric &amp; Alarm) 通知ASG 自动添加EC2</li>
    </ul>
  </li>
  <li>decouple applications</li>
  <li>API
    <ul>
      <li>SendMessage API</li>
      <li>DeleteMessage API</li>
    </ul>
  </li>
  <li>类型
    <ul>
      <li>Standard Queue
        <ul>
          <li>消息默认保存4天， 最多保存14天</li>
          <li>最大消息size 256K</li>
          <li>不限消息个数和吞吐量</li>
          <li>消费者一次最多取10条</li>
          <li>标准SQS不能直接修改成为FIFO， 只能删掉，建个新的FIFO</li>
          <li>只有Standard SQS 支持 S3 Events, Fifo 不支持 S3 Events</li>
        </ul>
      </li>
      <li>FIFO
        <ul>
          <li>first in first out</li>
          <li>吞吐量限制在300/s</li>
          <li>但如果使用批量（batch）的方法，可以每秒做10次（max）批量操作, 就可以达到3000/s
            <ul>
              <li>假设需求是要每秒1000次， 那么就设置4个批量（300*4=1200) 就可以满足需求了。</li>
            </ul>
          </li>
          <li>以.fifo 结尾</li>
          <li>如果要把standard queue 改成 Fifo 需要先把原来的删了，建个新的fifo</li>
          <li>场景：
            <ul>
              <li>需要顺序处理的消息</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Encryption
    <ul>
      <li>in-flight , 使用 HTTPS API</li>
      <li>at-rest, 使用KMS keys,也接受客户的Client-side encryption</li>
    </ul>
  </li>
  <li>Security
    <ul>
      <li>IAM policies 让用户访问 SQS API （user level）</li>
      <li>SQS Access Policy (类似S3 bucket policy) （service level)
        <ul>
          <li>允许其他服务（SNS, S3 …）访问SQS</li>
          <li>可以允许跨账号访问SQS</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Message Visibility Timeout
    <ul>
      <li>consumer获取消息后，默认30秒内其他人看不到，30秒后没处理完会被其他consumer 看到。 可以考虑用ChangeMessageVisibility API延长 timeout 时间</li>
      <li>timeout 时间太短可能会造成同一个消息被处理两次</li>
    </ul>
  </li>
  <li>场景：
    <ul>
      <li>处理流程很长的程序， 可以解耦， 分成前后端两部分， 中间用SQS处理</li>
      <li>比如视频处理应用</li>
    </ul>
  </li>
</ul>

<h4 id="dead-letter-queue">Dead Letter Queue</h4>

<ul>
  <li>相当于queue垃圾桶</li>
  <li>消息保存在DLQ的时间可以设置成14天比较好</li>
  <li>场景
    <ul>
      <li>一个message 被处理多次没有成功， 达到阈值（MaximumReceives）次数后会被扔到DLQ中</li>
      <li>用于debug 一些特殊消息</li>
    </ul>
  </li>
</ul>

<h4 id="message-timer-message-level">Message timer (message level)</h4>

<ul>
  <li>可以设置某个message 到了queue之后在固定时间后再被消费者看到。
    <ul>
      <li>默认是0秒，最大是15分钟</li>
    </ul>
  </li>
</ul>

<h4 id="delay-queue-producer-触发-queue-level">Delay Queue （producer 触发） (queue level)</h4>

<ul>
  <li>message 进入queue 之后一段时间， consumer 才能看到并接收</li>
  <li>所有的message 到了这个queue 都要等待同样的一段时间才能被消费者看到</li>
  <li>默认是0秒， 马上可以看到, max 是15分钟</li>
  <li>可以在queue中修改默认值</li>
  <li>producer 可以通过参数 DelaySeconds来修改默认值</li>
</ul>

<h4 id="sqs-有-shot-polling-和-long-polling">SQS 有 shot polling 和 long polling.</h4>

<ul>
  <li>shot polling 是默认的， 消费者定期去拿消息， 没有拿到就返回。</li>
  <li>long polling 是消费者去连接SQS， 并等待一段时间， 拿到数据返回(或者超时返回) ， 更详细解释看下面Long Polling</li>
  <li>SQS 的付费机制是消费者的连接次数， 所以long polling 可以在更少的连接次数中获取数据， 所以更节省成本</li>
</ul>

<h4 id="long-polling-consumer-触发">Long Polling （consumer 触发）</h4>

<ul>
  <li>consumer 可以在message 还么到到queue之前就在那里等着</li>
  <li>好处是高效的处理消息， 降低延迟</li>
  <li>可以在queue中打开设置选项。 时间范围 1-20 秒</li>
  <li>consumer 可以通过 WaitTimeSecond 来设wait 时间</li>
  <li></li>
</ul>

<h4 id="sqs-temporary-queue">SQS Temporary Queue</h4>

<ul>
  <li>
    <p>Request-Response messaging pattern 是一种双向Queue 的设计模式, 通过SQS Temporary Queue 来实现</p>
  </li>
  <li><strong>SQS Temporary Queue Client</strong> 是个服务， 可以实现这个模式</li>
  <li>两个服务之间需要请求和回复</li>
  <li>producer 可以指定response 的queue name</li>
  <li>consumer 处理完message之后将结果发送到指定的queue.</li>
  <li>多个producter 可以分别指定自己要接收的queue的名字， 多个consumer 操作完分别回给不同的producer</li>
  <li>如果有多个 producer , 需要一个request queue, 多个 response queue</li>
</ul>

<h4 id="sqs-与-asg-的设计模式">SQS 与 ASG 的设计模式</h4>

<ul>
  <li>模式1
    <ul>
      <li>SQS 后面接一个ASG , 里面是一堆EC2 实例</li>
      <li>给 CloudWatch指定 Costom Metric(自定义的指标) ， 比如queue length, 实例个数等</li>
      <li>CloudWatch Alarm 发现指标超出阈值， 发送信息给ASG</li>
    </ul>
  </li>
  <li>模式2
    <ul>
      <li>Queue 两边都是ASG</li>
    </ul>
  </li>
</ul>

<h4 id="上游和下游个数需要匹配">上游和下游个数需要匹配</h4>

<ul>
  <li>如果SQS 有多个数据源（比如1个IoT设备），如果也希望有10个 consumer 对应， 就需要每个IOT 设备提供一个unique ID, 通过 SQS FIFO 让消费者可以根据unique ID ,并且按顺序来提取数据</li>
</ul>

<h3 id="kinesis">Kinesis</h3>

<h4 id="kinesis-1">Kinesis</h4>

<ul>
  <li>实时收集、处理、分析流数据</li>
  <li>每条数据包含
    <ul>
      <li>Partition Key, 就是数据ID
        <ul>
          <li>同一个partition key 的数据会被同一个shard 来处理， 其他shard 不会处理</li>
        </ul>
      </li>
      <li>Data Blob, 就是数据内容本身</li>
    </ul>
  </li>
  <li>场景
    <ul>
      <li>application log</li>
      <li>website click stream, IOT data</li>
      <li>DMS 将数据从S3 导入到KDS</li>
    </ul>
  </li>
  <li>四个组成 部分
    <ul>
      <li>Kinesis Data Stream
        <ul>
          <li>获取，处理和保存数据流</li>
        </ul>
      </li>
      <li>Kinesis Data Firehose
        <ul>
          <li>读取数据流到AWS 数据存储</li>
        </ul>
      </li>
      <li>Kinesis Data Analytics
        <ul>
          <li>通过SQL or Apache Flink 分析数据</li>
        </ul>
      </li>
      <li>Kinesis Video Streams
        <ul>
          <li>获取，处理和保存视频流</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Kinesis Agent
    <ul>
      <li>kinesis agent 是一个独立的java 程序，</li>
      <li>部署在需要读取数据的client side, 作为 kinesis 服务的上游， 可以写入到KDS or KDF</li>
    </ul>
  </li>
  <li>Shard
    <ul>
      <li>KDS 是有多个Shard 组成的</li>
      <li>吞吐量 - 1M/每秒/每shard， or 1000 message/每秒/每shard</li>
      <li>通过增加 Shard 的数量提高 Kinesis 的吞吐量</li>
      <li>一个 shard 流量过高, 可以拆成多个 shards</li>
      <li>多个 shard 流量过低, 可以合并</li>
    </ul>
  </li>
</ul>

<h4 id="kinesis-data-stream">Kinesis Data Stream</h4>

<ul>
  <li>数据进入就不能删，可放置一年， 数据可以被反复处理</li>
  <li>每秒可以处理1M 的数据进入/每个 shard,
    <ul>
      <li>每秒1000条message/每个 shard</li>
    </ul>
  </li>
  <li>每个shard 单独计费，增加shard 就加钱
    <ul>
      <li>可以通过batch 的方式增加吞吐量还不用多花钱</li>
    </ul>
  </li>
  <li>上游的数据来源 - Producer (1m/s)
    <ul>
      <li>DMS</li>
      <li>applications</li>
      <li>AWS SDK/KPL(Kinesis Producer Library)</li>
      <li>Kinesis Agent
        <ul>
          <li>基于 KPL 开发的</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>下游 - Consumer (2m/s)
    <ul>
      <li>apps , KCL (Kinesis Consumer Library)</li>
      <li>Lambda
        <ul>
          <li>可以写到 S3, Redshift, opensearch, dynamoDB, 其他任何地方</li>
          <li>可以作为 简单版本的 ETL</li>
          <li>可以作为 triger, 发邮件, 通知等</li>
        </ul>
      </li>
      <li>AWS SDK</li>
      <li>Kinesis Data Firehose</li>
      <li>Kinesis Data Analytics</li>
      <li>Kinesis Connector Library (比较老的方案, 现在基本都是用 lambda 和 firehose 代替)
        <ul>
          <li>可以写到 S3, Redshift, opensearch, dynamoDB</li>
        </ul>
      </li>
      <li>3rd party libraries , 比如:
        <ul>
          <li>Spark, log4j, Appenders, Flume, Kafka …</li>
        </ul>
      </li>
      <li>去重
        <ul>
          <li>producer 在数据中加一个 unique ID</li>
          <li>consumer 可以在最终的数据存储的地方进行去重检查</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>场景
    <ul>
      <li>kinesis data stream 是处理数据流的, 用例包括
        <ol>
          <li>将不同源的记录路由到一个记录处理器， 并保持顺序</li>
          <li>多个应用读取同一个数据流</li>
          <li>存储几个小时的数据，然后供其他应用消费。 Kinesis Data Stream 默认存24小时的数据， 最长可以存储最长365天的时间。</li>
        </ol>
      </li>
    </ul>
  </li>
</ul>

<h4 id="kinesis-enhanced-fan-out">Kinesis Enhanced Fan Out</h4>

<p>New game-changing feature from August 2018.</p>
<ul>
  <li>用 KCL 2.0 和 Lambda 实现(Nov 2018)</li>
  <li>每个 Consumer 从每个 shard 获取 2 MB/s 带宽的流量</li>
  <li>可以同时有 20 consumers , 就意味着可以把带宽流量扩大到 40MB/s 每个 shard</li>
  <li>No more 2 MB/s limit!</li>
  <li>Enhanced Fan Out: Kinesis pushes data to consumers over HTTP/2</li>
  <li>可以减少 70 ms 的延迟
Fan out 和标准consumer 的对比</li>
  <li>Standard consumers:
    <ul>
      <li>Low number of consuming applications (1,2,3…) -</li>
      <li>Can tolerate ~200 ms latency</li>
      <li>Minimize cost</li>
    </ul>
  </li>
  <li>Enhanced Fan Out Consumers:
    <ul>
      <li>Multiple Consumer applications for the same Stream</li>
      <li>Low Latency requirements ~70ms</li>
      <li>Higher costs (see Kinesis pricing page)</li>
      <li>Default limit of 20 consumers using enhanced fan-out per data stream</li>
    </ul>
  </li>
</ul>

<h4 id="kinesis-data-firehose">Kinesis Data Firehose</h4>

<ul>
  <li>serverless ，自动伸缩，无需人工干预， 不存在因为scale 限制写不进去， 需要扩容的问题。
    <ul>
      <li>full managed service,</li>
      <li>near-real time</li>
      <li>读取数据到 S3, OpenSearch, Splunk</li>
    </ul>
  </li>
  <li>上游 (1m/s)，和KDS 一样的, 还多了
    <ul>
      <li>KDS</li>
      <li>CloudWatch logs/events</li>
      <li>AWS IOT</li>
      <li>SNS</li>
    </ul>
  </li>
  <li>中间， KDF 可以和Lamdba 结合, 对数据进行 data transformation</li>
  <li>下游 （batch write）
    <ul>
      <li>S3</li>
      <li>Redshift (数据仓库)</li>
      <li>ElasticSearch</li>
      <li>HTTP endpoint</li>
      <li>3rd party data store
        <ul>
          <li>datadog</li>
          <li>splunk</li>
          <li>new relic</li>
          <li>mongodb</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Firehose 每1分钟 （1 minute） 可以把数据写入到下游存储中(比如 S3)</li>
  <li>所有操作失败的数据可以保存到 S3 bucket 中 ,( 正常数据也可以转存到 S3)</li>
  <li>Spark 和 KCL 不能从 KDF 中读数据</li>
  <li>场景：
    <ul>
      <li>日志分析流， 获取不同类型日志进行分析，并存储在永久的存储中， 可以供后期做分析用</li>
    </ul>
  </li>
</ul>

<h4 id="kinesis-data-streams-vs-firehose-的区别">Kinesis Data Streams vs Firehose 的区别</h4>

<ul>
  <li>Streams
    <ul>
      <li>Going to write custom code (producer / consumer)</li>
      <li>实时 (~200 ms latency for classic, ~70 ms latency for enhanced fan-out)</li>
      <li>手动伸缩 (shard splitting / merging)</li>
      <li>存数据 for 1 to 365 days, replay capability, multi consumers</li>
      <li>Use with Lambda to insert data in real-time to OpenSearch (for example)</li>
    </ul>
  </li>
  <li>Firehose
    <ul>
      <li>Fully managed, send to S3, Splunk, Redshift, OpenSearch</li>
      <li>无服务, Serverless data transformations with Lambda</li>
      <li>准实时 (lowest buffer time is 1 minute)</li>
      <li>自动伸缩</li>
      <li>不存数据</li>
    </ul>
  </li>
</ul>

<h4 id="kinesis-data-stream-和-sqs-的区别">Kinesis Data Stream 和 SQS 的区别</h4>
<ul>
  <li>Kinesis Data Stream:
• Data can be consumed many times
• Data is deleted after the retention period
• Ordering of records is preserved (at the shard level) – even during replays
• Build multiple applications reading from the same stream independently (Pub/Sub)
• “Streaming MapReduce” querying capability (Spark, Flink…)
• Checkpointing needed to track progress of consumption (ex: KCL with DynamoDB)
• Provisioned mode or on-demand mode</li>
  <li>
    <p>SQS:
• Queue, decouple applications
• One application per queue
• Records are deleted after consumption (ack / fail)
• Messages are processed independently for standard queue
• Ordering for FIFO queues (decreased throughtput)
• Capability to “delay” messages
• Dynamic scaling of load (no-ops)</p>
  </li>
  <li>不同的使用场景</li>
  <li>SQS use cases:
• Order processing
• Image Processing
• Auto scaling queues according to messages.
• Buffer and Batch messages for future processing. 
• Request Offloading</li>
  <li>Kinesis Data Streams use cases:
• Fast log and event data collection and processing 
• Real Time metrics and reports
• Mobile data capture
• Real Time data analytics
• Gaming data feed
• Complex Stream Processing
• Data Feed from “Internet of Things”</li>
</ul>

<h4 id="cloudwatch-订阅过滤器-与-kinesis">Cloudwatch 订阅过滤器 与 Kinesis</h4>
<ul>
  <li>cloudwatch 是 流式的日志系统
    <ul>
      <li>可以把日志流到
        <ul>
          <li>KDS,</li>
          <li>KDF,</li>
          <li>Lambda</li>
        </ul>
      </li>
      <li>案例: 准实时
        <ul>
          <li>CloudWatch Logs -&gt; Subscription Filter -&gt; KDF (分支 -&gt; Lambda 做数据转换) -&gt; OpenSearch</li>
        </ul>
      </li>
      <li>案例: 实时
        <ul>
          <li>CloudWatch Logs -&gt; Subscription Filter -&gt;  Lambda 代替 KDF 并做数据转换 -&gt; OpenSearch</li>
        </ul>
      </li>
      <li>案例: 分析
        <ul>
          <li>CloudWatch Logs -&gt; Subscription Filter -&gt;  KDS -&gt; KDA - &gt; Lambda 进行一些任务处理</li>
        </ul>
      </li>
      <li>可以使用 cloudwatch filter</li>
      <li>可以通过 AWS CLI 开启</li>
    </ul>
  </li>
</ul>

<h4 id="kinesis-data-analytics">Kinesis Data Analytics</h4>

<ul>
  <li>可以理解为一个在KDS/KDF 的中间的分析环节</li>
  <li>关键词：
    <ul>
      <li>time series analytics</li>
      <li>real-time analytics</li>
      <li>real-time dashboard</li>
      <li>real-time metrics</li>
    </ul>
  </li>
  <li>上游
    <ul>
      <li>KDS</li>
      <li>KDF</li>
    </ul>
  </li>
  <li>中间， KDA 用 SQL</li>
  <li>下游
    <ul>
      <li>KDS</li>
      <li>KDF</li>
    </ul>
  </li>
</ul>

<h4 id="kinesis-data-analytics-和-athena-的区别">Kinesis Data Analytics 和 Athena 的区别</h4>

<ul>
  <li>Kinesis Data Analytics 和 Athena 都用SQL, 都把数据存到S3</li>
  <li>Kinesis Data Analytics 分析实时数据流</li>
  <li>Athena 分析历史数据</li>
</ul>

<h4 id="kinesis-中的数据的排序">kinesis 中的数据的排序</h4>

<ul>
  <li>场景：
    <ul>
      <li>100个卡车的GPS 定位数据传送到Kinesis 来分析卡车的位置</li>
      <li>同一个卡车发送的定位数据需要按顺序被处理，如果先后顺序不对， 行走路线就是来回跑了。</li>
      <li>一共有3个 shard</li>
    </ul>
  </li>
  <li>处理逻辑
    <ul>
      <li>每个卡车有一个unique id 作为partition key (只有这样，才会正确排序)</li>
      <li>每个partition key 会被同一个shard 来处理</li>
      <li>100个车的partition key 分别送到了3个shard 中， 大概每个shard 会处理1/3 的所有车辆，且服务的车辆对象固定不变</li>
    </ul>
  </li>
  <li>考试会让你从 Kinesis Data Stream 和 SQS FIFO 中选一个，需要知道怎么选</li>
  <li>考试会问为啥没有排序正确， 就是因partition key 没有放对应的 user id</li>
</ul>

<h4 id="batch-messages">Batch messages</h4>

<ul>
  <li>可以在不增加成本的情况下让Kinesis Data Stream消息并行的发送（http 请求）， 这可以最大化的利用现有shard的情况下来提高性能。是节省成本的理想方案</li>
</ul>

<h3 id="amazon-mq">Amazon MQ</h3>

<ul>
  <li>为了让on-premise 的 MQTT， AMQP， STOMP， Openwire, WSS 等开源queue 可以迁移到AWS, 且不用 re-engeering , AWS 提供 Amazon MQ</li>
  <li>是代替SQS / SNS 的方案 ， 有他们基本功能 ， Queue 和 Topic
    <ul>
      <li>Amazon MQ has both queue feature (~SQS) and topic features (~SNS)</li>
    </ul>
  </li>
  <li>Amazon MQ HA
    <ul>
      <li>通过EFS mount 到两个Amazon MQ Broker 来实现 failover.</li>
    </ul>
  </li>
  <li>场景： 公司希望把 开源Queue/通知 迁移到AWS , 那就用 Amazon MQ</li>
  <li>关键词
    <ul>
      <li>message <strong>broker</strong></li>
    </ul>
  </li>
</ul>

<h2 id="计算">计算</h2>

<h3 id="beanstalk">Beanstalk</h3>

<ul>
  <li>
    <p>paas 服务， beanstalk 负责iaas （ec2 asg, elb, rds, health check and ect.）, 我们负责applicaiton代码, 和对系统的配置</p>
  </li>
  <li>
    <p>beanstalk 本身不收费， 产生的底层iaas</p>
  </li>
  <li>
    <p>环境类型</p>

    <ul>
      <li>web 服务器环境， 用于网站开发</li>
      <li>工作线程环境， 用于内部工作</li>
    </ul>
  </li>
  <li>
    <p>配置预设</p>

    <ul>
      <li>单一实例</li>
      <li>单一实例-spot</li>
      <li>高可用</li>
      <li>高可用-spot</li>
      <li>自定义</li>
    </ul>
  </li>
  <li>
    <p>工作步骤</p>

    <ul>
      <li>
        <p>创建 环境</p>

        <ul>
          <li>
            <p>EC2, ASG, ELB, RDS,….</p>
          </li>
          <li>选择应用名称， 开发语言级版本（比如php）， 上传代码， 点击开始创建</li>
          <li>创建application 过程中会自动创建
            <ol>
              <li>target group</li>
              <li>security group</li>
              <li>Auto Scaling group (asg 会自动创建ec2)</li>
              <li>ELB</li>
              <li>Cloud Watch</li>
              <li>部署 EC2 实例
                <ol>
                  <li>包括webserver 和 RDS</li>
                </ol>
              </li>
              <li>application available</li>
              <li>health check 检查完毕状态从pending 改成 ok</li>
              <li>完成后就多了一个application 和一个环境， 点击application url就可以看到php congratulation 页面了</li>
              <li>要修EC2,RDS 需要去ec2， RDS, ASG, ELB, SG 要去 对应的consule 界面进行管理</li>
              <li>删除环境会把所有的都删掉</li>
            </ol>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="ec2">EC2</h3>

<h4 id="ec2-1">EC2</h4>

<ul>
  <li>
    <p>user data (run with root user, only first boot)</p>

    <ul>
      <li>dynamic configuration. 把100个需要配置的EC2 的user data 写到一个地方， 作用是避免重复劳动，不能加快部署速度。</li>
    </ul>
  </li>
  <li>
    <p>security group</p>

    <ul>
      <li>only have allow rule for IP CIDR or security group</li>
      <li>实际是绑定网卡的， 和EC2是多对多</li>
      <li>Stateful，能进来就能出去</li>
      <li>默认不能进， 随便出</li>
      <li>time out 是 security group 的问题， connection refused 是EC2的问题</li>
      <li>22,21,80,443,3389</li>
      <li>inbound rule
        <ul>
          <li>允许上游SG/IP(or range) 的inblound on 自己的 port</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>purchase options</p>

    <ul>
      <li>
        <p>on-demand</p>

        <ul>
          <li>On-demand instances are not bound by any contract or agreement and can be modified at any time, including on termination, without any penalty.
            <ul>
              <li>比如： 一个 instances that can be resized at any time in order to execute performance testing</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>reserved (1or3 year, 70% discount)</p>
      </li>
      <li>
        <p>spot instance (90% discount) , 关闭的方法是先关掉 spot request, 再terminate spot instance</p>

        <ul>
          <li>spot fleets 是on-demand和spot 组合的，自动获取spot并用了最低的价格</li>
          <li>Spot Fleets 是一堆Spot instances, 通过ASG 进行部署的， 用于最大化的HA。</li>
        </ul>
      </li>
      <li>
        <p>dedicated host</p>

        <ul>
          <li>对物理机有绝对的拥有权。 可以自己决定如何部署instance.</li>
          <li>有 host ID， 可以被应用直接访问</li>
          <li>在dedicated host 上可以部署VMs, 只支持两种purchae options
            <ul>
              <li>on-demand</li>
              <li>reservation</li>
            </ul>
          </li>
          <li>关键词
            <ul>
              <li>自己有license</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>dedicated instance</p>

        <ul>
          <li>
            <p>Dedicated instance 可能会和同一个AWS account 的其他instance 分享同一个物理机器，但是dedicated instance 所在的物理机不会让其他账户进行访问。</p>
          </li>
          <li>
            <p>关键词</p>

            <ul>
              <li>single tenant hardware</li>
              <li>isolatiing instance</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>

    <p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h0xoh5kh9gj20fo08ot8y.jpg" alt="img" /></p>

    <ul>
      <li>scheduled (scheduled reserved instance)
        <ul>
          <li>Scheduled Reserved Instances: Scheduled Reserved Instances (Scheduled Instances) enable you to purchase capacity reservations that recur on a daily, weekly, or monthly basis, with a specified start time and duration, for a one-year term. You reserve the capacity in advance, so that you know it is available when you need it. You pay for the time that the instances are scheduled, even if you do not use them.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>重启机器，public ip会换掉</p>
  </li>
</ul>

<h4 id="placement-group">placement group</h4>

<ul>
  <li>cluster (same az, same rack)
    <ul>
      <li>Cluster placement group 是所有EC2在同一个AZ同一个Rack上， 所以网络延迟最低（10G带宽）</li>
    </ul>
  </li>
  <li>spread (HA, max 7 instance per group per az)
    <ul>
      <li>Spread placement group, 所有的实例都不在一个物理硬件上， 支持最大化的高可用</li>
    </ul>
  </li>
  <li>partition (hadoop, cassandra, kafka, max 7 partition per az)
    <ul>
      <li>Partition placement group, 每个AZ里面可以有很多机器， 适合HDFS，HBase， Cassandra， Kafka 的场景</li>
    </ul>
  </li>
</ul>

<h4 id="eni">ENI</h4>

<ul>
  <li>一个ENI 可以从一个EC2换相同AZ下的另一个EC2</li>
  <li>一个ENI可以有一个Public ip, 一个主private ip 多个secondry ip.</li>
  <li>一个private ip只能绑定一个elastic ip</li>
  <li>最大吞吐量 25Gbps</li>
</ul>

<h4 id="elastic-ip">Elastic IP</h4>

<ul>
  <li>普通的public IP， 停止后再启动，IP地址会变。 如果想要一个固定不变的IP地址，就需要申请一个Elastic IP</li>
  <li>一个EIP只能一次attach 到一个实例上</li>
  <li>可以把EIP从出问题的实例上remapping 到 正常的实例上</li>
  <li>EIP不是一个好的架构选择
    <ul>
      <li>Instead, use a random public IP and register a DNS name to it</li>
      <li>Or, use a Load Balancer + private IP</li>
    </ul>
  </li>
</ul>

<h4 id="ec2-instance-hibernate">ec2 instance hibernate</h4>

<ul>
  <li>
    <p>将启动时需要加载的内容从内存里放在磁盘文件上， 下次启动直接读文件到内存中， 加快启动速度</p>
  </li>
  <li>
    <p>场景：</p>

    <ul>
      <li>需要一个进程一直不停， 需要保存ram状态， 需要加速启动速度</li>
      <li>EC2 上有个内存数据库，希望重启后数据仍然保留</li>
    </ul>
  </li>
  <li>
    <p>限制条件： C,R,M 3，4，5 系列， ram &lt; 150g, encrypted EBS only, on-demand and reserved instance. max 60 days hibernate</p>
  </li>
</ul>

<h4 id="ebs">EBS</h4>

<ul>
  <li>可以在同一个az的不同ec2之间插拔</li>
  <li>
    <p>目前最大支持64T 容量</p>
  </li>
  <li>
    <p>多EBS 对一 ec2 的关系</p>

    <ul>
      <li>特例是EBS Multi-attach
        <ul>
          <li>只能在同一个az下实现一个ebs 对多个ec2 实例， 只有io1,io2 可以</li>
          <li>Provisioned IOPS SSD volumes(io1, io2)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>by default, root volume 在ec2 terminate的时候也会被删除</p>

    <ul>
      <li></li>
      <li>实例没有运行
        <ul>
          <li>通过console，API,CLI 直接修改DeleteOnTermination 参数为 False</li>
        </ul>
      </li>
      <li>这个实例还在运行， 怎么修改这个错误呢？
        <ol>
          <li>通过命令行来设置 DeleteOnTermination 参数为 False</li>
        </ol>
      </li>
    </ul>
  </li>
  <li>
    <p>通过snapshot的方式进行备份（可跨az）</p>
  </li>
  <li>
    <p>type</p>

    <ul>
      <li>
        <p>gp2,gp3,io2,io3(最快), st1, sc1(第二慢), standard (最慢)</p>

        <ul>
          <li>EBS Standard 最便宜。存储上限是1T</li>
          <li>SC1 适合 cold storage data set</li>
          <li>ST1 适合high throughput</li>
          <li>gp2 （general purpose）是launch EC2的默认选择，<strong>有中等偏上</strong>的IOPS能力，价格比其他SSD类型都低。</li>
          <li>EBS io2 (PIOPS) Block Express可以最大化IOPS, 是下一代的EBS 存储方案架构, 最贵</li>
        </ul>
      </li>
      <li>
        <p>gp， io，instance store 是ssd,可以做boot volume</p>
      </li>
      <li>
        <p>价格对比</p>

        <ul>
          <li>standard &lt; SC1 &lt; ST1 &lt; GP2 &lt;IO1/IO2 &lt; instance store</li>
          <li>既要为预留的size 付费，又要为读取的流量付费。（EFS 只为流量付费）</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>encryption</p>

    <ul>
      <li>可通过snapshot 的方式对未加密的EBS加密， 是在copy snapshot的时候进行加密的</li>
      <li>EBS volume 可以被设置成默认就被加密</li>
      <li>关于加密了的 EBS 正确的描述是：
        <ol>
          <li>数据在volume 和 instance 之间流动时是被加密的</li>
          <li>Snapshot 是被加密的</li>
          <li>volume 中的数据是被加密的</li>
        </ol>
      </li>
    </ul>
  </li>
  <li>
    <p>EBS 的 RAID</p>

    <ul>
      <li>Use <strong>RAID 0</strong> when I/O performance is more important than failt tolerance</li>
      <li>Use RAID 1 when fault tolerance is more important than I/O performance
        <ol>
          <li>EBS 支持标准 RAID 的配置，包括RAID 0 和 RAID 1
            <ol>
              <li>RAID 0 是需要性能更高的时候使用， 但是有磁盘损坏无法修复的风险</li>
              <li>RAID 1 是两个磁盘互为备份，但是性能差一些。</li>
            </ol>
          </li>
        </ol>
      </li>
    </ul>
  </li>
</ul>

<h4 id="ec2-instance-store">EC2 instance store</h4>

<ul>
  <li>better i/o 方案 比ebs</li>
  <li>目前最大支持10G 容量</li>
  <li>重启ec2， 数据就丢了</li>
  <li>通过备份和 replica 可以解决</li>
  <li>是个硬件设备</li>
  <li>intance store 最大也就支持3.8T (不支持太大的存储)</li>
  <li>如果这个EC2 实例挂的是 Instance Store 的 volume, 那就无法被Cloud Watch Alarm 触发来进行自动的 recovery.</li>
  <li>正确的描述
    <ul>
      <li>不能把一个instance store 从一个实例上 detach 然后再attache 到另一个实例上。</li>
      <li>如果给一个挂了 instance store 的EC2做 AMI， instance store 上的数据不会被保留</li>
      <li>其他的正确答案 （不正确的改成正确的）
        <ol>
          <li>Instance store 是一个物理硬盘(This storage is located on disks that are physically attached to the host computer)，不是网络存储(network storage)</li>
          <li>只用在launch 一个新的实例的时候可以指定他的instance store. 重启的时候不能指定，因为重启后instance store 的数据就丢了</li>
          <li>不管你是stop, terminate or hibernate, instance store 的block 都会被重置，数据会丢失。</li>
        </ol>
      </li>
    </ul>
  </li>
</ul>

<h4 id="ami">AMI</h4>

<ul>
  <li>特性
    <ol>
      <li>通过加密的snapshot 拷贝一个 AMI , 不会产生一个非加密的snapshot</li>
      <li>你可以跨Region 拷贝一个 AMI</li>
      <li>你可以在不同的AWS账号间分享AMI</li>
    </ol>
  </li>
  <li>有三种， public ami (aws 提供)， own ami, marketplace ami</li>
  <li>az1 的 ec2 创建一个ami，copy 到 az2(可选择加密选项) 在az2 恢复成另一个一样的一个ec2</li>
  <li>同一个AMI 只能在同一个az创建实例, 不能 在另一个az创建实例</li>
  <li>Golden AMI ， 黄金AMI, 把本来要创建实例后需要做的软件安装， 依赖安装鞥工作提前做到AMI中， 作用是加快部署速度，快速启动实例</li>
</ul>

<h4 id="ec2-metadata">EC2 Metadata</h4>

<ul>
  <li>可以通过URL http://168.254.168.254/latest/meta-data/ 获得；也可以通过CLI 命令行获得</li>
  <li>包含了EC2 的基本信息， 比如 IAM, HostName 等</li>
</ul>

<h4 id="ec2-instance-auto-recovery">EC2 Instance Auto Recovery</h4>

<ul>
  <li>EC2 实例的恢复</li>
  <li>用CloudWatch alarm 来自动回复受损 （impaired）EC2 实例</li>
  <li>一旦没有问题， 会恢复和以前一样。一个恢复完的实例就等同于原来的实例
    <ul>
      <li>私有IP</li>
      <li>共有IP</li>
      <li>Elastic IP</li>
      <li>Metadata</li>
      <li>Placement Group</li>
    </ul>
  </li>
  <li>这里要注意，一个正常的EC2 实例，重启后IPV4 地址会变掉
    <ul>
      <li>但是因为 auto recovery 恢复的实例， IPV4地址不会变</li>
    </ul>
  </li>
</ul>

<h4 id="ec2-enhanced-networking-sr-iov">EC2 Enhanced Networking (SR-IOV)</h4>

<ul>
  <li>更高的带宽， 更高的PPS(每秒packet) , 更低的延迟</li>
</ul>

<h4 id="elastic-fabric-adapter-efa">Elastic Fabric Adapter (EFA)</h4>

<ul>
  <li>是Elastic 织物适配器</li>
  <li>更高的计算性能和网络带宽
    <ul>
      <li>Elastic Fabric Adapter (EFA) 是一个网络设备， 可以attach 到 EC2上， 来支持 HCP 和 机器学习应用。 EFA 还提供 允许应用和硬件接口直接通信， 提高网络通信速度。</li>
      <li>The EFA exhibits both the highest throughput and the lowest latency of any network interface in AWS.</li>
    </ul>
  </li>
</ul>

<h4 id="spot-fleet">Spot Fleet</h4>

<ul>
  <li>Spot Fleets allow us to automatically request Spot Instances with the lowest price</li>
  <li>Spot Fleets = set of Spot Instances + (optional) On-Demand Instances</li>
  <li>Spot Fleet stops launching instances when reaching capacity or max cost</li>
  <li>可以用 Spot fleet 提交一个一次性的任务， 比如2个小时的大数据计算， fleet 会启动一堆 spot instance 来执行任务， 执行完成后spot instance 会被terminate, fleet 也会结束。 也可以在fleet 中使用 on-demand 实例。</li>
</ul>

<h4 id="spot-有两种类型">spot 有两种类型</h4>

<ul>
  <li>
    <p>可以是one-time 的，</p>
  </li>
  <li>
    <p>也可以设置成 persistant , 只有设置成了persistant, 才有下面 stop/interrupted 这些故事</p>

    <ul>
      <li>
        <p>如果 spot request 还在， 那么如果spot instane被中断了(interrupted), spot request 就会被再打开</p>

        <ul>
          <li>spot instance 如果是被stop 了， 只有instance 再次启动后， spot request 才会被再打开</li>
        </ul>
      </li>
      <li>
        <p>当你cancel 了一个 active spot request, 这并不会terminate 对应的instance</p>

        <ul>
          <li>如果要关闭 instance, 需要手动关闭。</li>
        </ul>
      </li>
      <li>
        <p>spot blocks 设计成不会被打断（interrupted）</p>

        <ul>
          <li>Spot block 是被设置成可以执行固定时间的、不会被打断的 instance 。 时间可以设置成1-6个小时。</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h0zpn6ts6bj20h00abaa4.jpg" alt="img" /></p>

<h4 id="spot-instance-spot-blocks-spot-fleets-的区别">Spot instance, Spot blocks, Spot Fleets 的区别</h4>

<ol>
  <li>Spot instance 是一种EC2 实例可行，可以被打断（提前2分钟通知），能省90%的钱。</li>
  <li>Spot Block 是不会被打断的Spot instance,一次可以使用1-6个小时</li>
  <li>Spot Fleets 是一堆Spot instances, 通过ASG 进行部署的， 用于最大化的HA。</li>
</ol>

<h4 id="ec2-实例的tenancy">EC2 实例的tenancy</h4>

<ol>
  <li>
    <p>一共有三种 tenancy, 分别是</p>

    <ol>
      <li>default - 实例在分享的硬件上运行</li>
      <li>dedicated (dedicated instance) - 实例在 single-tenant hardward 上运行（只给你用，但是你不能配置它）
        <ol>
          <li>但是可能会分享同一个账户的多个实例在一个硬件上运行</li>
        </ol>
      </li>
      <li>host (dedicated host) - 实例在dedicated host 、隔绝的、可以配置的服务器上运行 （只给你用， 你可以随便配置）
        <ol>
          <li>一个实例就在一个硬件上， 同一个账户的其他实例也不会在这个硬件上运行。</li>
        </ol>
      </li>
    </ol>
  </li>
  <li>
    <p>tenancy 之间的转换规则</p>

    <ol>
      <li>可以把实例的 tenancy 从 dedicated 改成 host</li>
      <li>可以把实例的 tenancy 从 host 改成 dedicated</li>
      <li>不能从default 迁到 host</li>
      <li>不能从 default 迁到 dedicated</li>
      <li>不能从dedicated to default</li>
      <li>不能从 host 迁到 default</li>
    </ol>
  </li>
  <li>
    <p>ASG 的launch configuration 和 VPC 都可以设置 tenancy.</p>
  </li>
  <li>
    <p>ASG 中设置的 launch configuration 的 tenancy 类型是和 VPC 的 tenancy 相关的</p>

    <ol>
      <li>如果launch configuraiton 的 tenancy 设置成了default, 那么就会继承VPC 的 tenancy</li>
    </ol>
  </li>
  <li>
    <p>如果launch configuration 的 tenancy 设置成了非default ， 那就会覆盖VPC 的 tenancy</p>
  </li>
</ol>

<h2 id="容器">容器</h2>

<h3 id="ecr">ECR</h3>

<ul>
  <li>
    <p>AWS 容器 Images (镜像)管理平台</p>
  </li>
  <li>
    <p>底层通过S3 进行管理</p>
  </li>
  <li>
    <p>安全</p>

    <ul>
      <li>IAM role</li>
      <li>Vulnerability scanning 弱点扫描</li>
      <li>version</li>
    </ul>
  </li>
  <li>
    <p>image lifecycle</p>
  </li>
</ul>

<h3 id="aws-fargate">AWS Fargate</h3>

<ul>
  <li>
    <p>AWS Serverless 无服务容器平台</p>
  </li>
  <li>Fargate 是一种无服务技术，让Docker 可以脱离EC2 直接运行在AWS 上面， 它支持EKS 和 ECS</li>
  <li>
    <p>Fargate 默认是支持跨az的，不需要单独配置multi-az</p>

    <ul>
      <li>ECS with Fargate</li>
      <li>EKS with Fargate</li>
    </ul>
  </li>
  <li>看ECS的介绍</li>
</ul>

<h3 id="ecs">ECS</h3>

<h4 id="ecs-1">ECS</h4>

<ul>
  <li>
    <p>AWS 提供的Docker 容器管理平台</p>
  </li>
  <li>
    <p>是基于EC2的， 要自己维护EC2</p>
  </li>
  <li>
    <p>这里真正能执行任务的容器是task</p>
  </li>
  <li>
    <p>task 有自己的role （policy）用于给外面的服赋予权限对自己进行访问</p>
  </li>
  <li>
    <p>ECS launch type</p>

    <ul>
      <li>
        <p>EC2</p>

        <ul>
          <li>在ECS Cluster 中放一个ASG</li>
          <li>
            <p>在 ASG 下面部署多个EC2 实例，</p>

            <ul>
              <li>EC2 实例同时也ECS Cluster 当中</li>
            </ul>
          </li>
          <li>EC2 实例是分布在不同的AZ当中的，实现了HA</li>
          <li>
            <p>每个实例上有一个 ECS agent 和 多个ECS Tasks</p>

            <ul>
              <li>ECS agent 负责和容器外部的 ECS 服务通信， 对ECS tasks 进行管理</li>
              <li>每个 task 没有自己的 IP 但是有一个被动态分配的 port</li>
            </ul>
          </li>
          <li>好处
            <ul>
              <li>Predictable cost, regardless of the number of running containers
                <ul>
                  <li>When deploying ECS onto EC2, there is no charge for the ECS management layer, and the customer can take advantage of cost discounts by using reserved instances.</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>Fargate</p>

        <ul>
          <li>serverless, 直接把Docer运行在AWS上， 不需要EC2 了, 简单了</li>
          <li>需要给每个task 配一个ENI (网卡)，每个task 就有了一个unique private IP</li>
          <li>如果容器一直在Fargate上运行，那么从长期的角度来看，Fargate 要比 EC2 版本的ECS 要贵很多。</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>安全</p>

    <ul>
      <li>IAM Role for ECS， 有两层roles
        <ul>
          <li>EC2 instance role , 是给ECS agent 用的， 可以对外进行通信用的比如对外获取镜像， 发送日志到cloud watch等</li>
          <li>ECS task role , 允许每个EC2里面的task 有自己的role, 这个role 可以允许task 访问S3, DynamoDb 等服务</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>存储</p>

    <ul>
      <li>ECS 容器的Volume 方案是EFS
        <ul>
          <li>不管是EC2 中的 task 还是 Fargate中的 task, 都可以直接 mount 到 EFS 上</li>
          <li>因为 EFS 支持 multi-az, 所以在任何 az 的 task 都可以 mount 到 EFS 上， task 默认就是跨 AZ 的</li>
          <li>Fargate + EFS是完美的 Multi-AZ 无服务容器 + 存储方案</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="ecs-和-alb">ECS 和 ALB</h4>

<ul>
  <li>ALB 对外暴露域名或 IP, 对内直接连接 不同 instance 上的 tasks</li>
  <li>EC2上 的 tasks
    <ul>
      <li>每个 task 有一个被动态分配的 port (比如 36789)</li>
      <li><strong>Dynamic Port Mapping</strong> 可以让 ALB 转发流量到多个 ECS Tasks 中, 解决了每个 task 的端口不一样的问题.</li>
      <li>需要在 ALB 的安全组中进行设置， 允许 任何 port 的EC2安全组进入</li>
    </ul>
  </li>
  <li>Fargate 上的 tasks
    <ul>
      <li>每个 port 都分配了一个ENI , 带有唯一的 private IP</li>
      <li>所有的task （ENI）都使用同一个 port (比如80)</li>
      <li>需要在 ALB 的 安全组中设置， 允许 带有 task 的端口号的所有 ENI 可以进入</li>
    </ul>
  </li>
</ul>

<h4 id="ecs-和-aws-event-bridge">ECS 和 AWS Event Bridge</h4>

<ul>
  <li>EventBridge 是 serverless 服务， 让一种无服务调用另一种无服务。</li>
  <li>当需要让 S3 的 Event 可以调用 ECS task 来处理任务时， 需要用 EventBridge 来调度task</li>
  <li>需要给 task 的 role 设置权限允许 访问 S3 和 dynamoDB.</li>
  <li>场景
    <ul>
      <li>客户上传一个图片， 希望通过容器里的服务创建缩略图， 并将数据记录的 DynamoDB 中。</li>
    </ul>
  </li>
</ul>

<h4 id="ecs-scaling">ECS Scaling</h4>

<ul>
  <li>
    <p>通过 Cloud Watch metrics（ECS CPU usage）检测发现超过阈值 ， CloudWatch alarm 通知ASG 增加 tasks 数量。</p>

    <ul>
      <li>如果是 EC2 版本的 tasks, 还可以增加EC2 的数量 （optional）</li>
    </ul>
  </li>
</ul>

<h4 id="ecs-rolling-update">ECS Rolling Update</h4>

<ul>
  <li>比如， task 的 python 应用需要升级， V1 升到 V2, 一共100个 task ，要轮换的替换现有V1 保证服务一直对外提供</li>
  <li>通过设置min ， max 的 百分比来对所有 task 轮换升级
    <ul>
      <li>min 50%， max100% , 就是先换掉 50个v1，加50个v2, 再换掉另外50个v1，再加50个v2, 保证总数最少被不少于50， 总数最大不超过100个</li>
      <li>min 100%, max 150%, 就是先增加50个v2， 再减掉50个v1, 再加50个v2, 再减掉50个v1. 保证总数不少于100， 不大于150</li>
    </ul>
  </li>
</ul>

<h4 id="ecs-访问-s3-的权限">ECS 访问 S3 的权限</h4>
<ul>
  <li>给S3 建IAM Role + 把这个role 作为 task 的 taskRoleArn
    <ul>
      <li>Create an IAM role with S3 permissions, and then specify that role as the taskRoleArn in the task definition.</li>
    </ul>
  </li>
</ul>

<h3 id="eks">EKS</h3>

<ul>
  <li>Amazon’s Kubernetes
    <ul>
      <li>Pods 相当于instance</li>
      <li>notes 相当于tasks</li>
    </ul>
  </li>
  <li>是 serverless</li>
  <li>是ECS 的替代方案</li>
  <li>除了API被AWS 改写了， 其他的和开源版的kubernetes基本一样</li>
  <li>场景：
    <ul>
      <li>公司已经使用了K8s, 希望迁移到AWS, 就选EKS</li>
    </ul>
  </li>
</ul>

<h2 id="存储">存储</h2>

<h3 id="s3">S3</h3>

<h4 id="s3-1">S3</h4>

<ul>
  <li>
    <p>bucket - 装文件（object）的桶</p>

    <ul>
      <li>
        <p>名字要全球唯一, 小写字母数字组合</p>
      </li>
      <li>
        <p>multi-region level</p>

        <ul>
          <li>When configuring S3 cross-region replication, need manually copy existing objects.
            <ul>
              <li>Enabling cross-region replication does not copy existing objects by default, and so it is up to the customer to perform this task</li>
              <li>cross-region replica 需要打开 version</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>S3 Standard is described in the SLA documentation as being designed for 4 9s availability and 11 9s durability.</p>

        <ul>
          <li>11 9s durability 需要对object 做三次 replica</li>
        </ul>
      </li>
      <li>
        <p>versioning</p>

        <ul>
          <li>在启动version 之前就已经存在的文件， 他们的第一个版本是 null</li>
          <li>Versioning 一旦开启就不能关闭了， 且只能暂停一次。</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Object</p>

    <ul>
      <li>S3://my-bucket/folder/subfolder/my_file.txt</li>
      <li>﻿key 是整个url, 其中my_file.txt是 object name, /folder/subfolder 是 prefix</li>
      <li>最大5T, 超过5g 需要multi-part upload， 建议超过100m 就 multi-part upload</li>
      <li>Meta data 元数据, 就是给上传的文件定义一堆key value， 用来描述文件类型， 语言， 和其他自定义的任何定义文件的信息， 可以通过CLI获取</li>
      <li>tag 标签, 一堆key value , 方便之后用于文件的生命周期管理</li>
      <li>S3 object 只属于上传他的账号（创建者）， 如果是其他用户/应用上传的文件， 就算是S3 owner 也看不到（没有访问权限）。</li>
    </ul>
  </li>
  <li>
    <p>encryption ,</p>

    <ul>
      <li>S3 Glacier 默认就是SSE 加密at-rest 的数据的</li>
      <li>
        <p>bucket/文件 加密 4种</p>

        <ul>
          <li>SSE-S3 , key 的管理和加密过程由aws 完成， 看不到key, 也不能参与管理
            <ul>
              <li>设置header “ x-amz-server-side-encryption:aes256”</li>
            </ul>
          </li>
          <li>SSE-KMS, key 的管理和加密过程由KMS完成, 可设置rotation policy
            <ul>
              <li>设置header “x-amz-server-side-encryption”: ”aws:kms”</li>
              <li>KMS is a shared-tenancy,  region-scoped service that uses resilient architecture to protect your encryption keys</li>
            </ul>
          </li>
          <li>SSE-C, key 的管理在客户端， 加密在服务端
            <ul>
              <li>必须用HTTPS</li>
              <li>key 需要在header 中提供</li>
            </ul>
          </li>
          <li>Client Side Encryption - key 的管理和加密解密都在客户端</li>
        </ul>
      </li>
      <li>
        <p>in flight 加密</p>

        <ul>
          <li>SSL or TLS</li>
          <li>S3 网站如果需要TLS 加密的话需要使用 default s3.amazonaws.com TLS certificate.</li>
        </ul>
      </li>
      <li>
        <p>强制bucket 对内容进行加密的方法</p>

        <ul>
          <li>
            <p>在policy中设置， 如果api请求的header 中没有加密的key value, 那么就拒绝</p>
          </li>
          <li>
            <p>Default Encryption 设置项</p>

            <ul>
              <li>可以给bucket 打开Default Encryption 选项， 打开后上传的未加密文件会自动被加密</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Security</p>

    <ul>
      <li>
        <p>IAM policy (user level)</p>
      </li>
      <li>
        <p>Object/Bucket ACL （resource level）</p>

        <ul>
          <li>如果没有显性deny, 那么只要是IAM policy 允许或者 object/bucket policy 允许， 这个用户明访问s3资源</li>
        </ul>
      </li>
      <li>
        <p>可以跨账号访问</p>
      </li>
      <li>
        <p>encryption</p>

        <ul>
          <li>Glacier 默认支持加密， 包括了 数据加密和传输加密（data at rest and in-transit）</li>
        </ul>
      </li>
      <li>
        <p>MFA delete</p>

        <ul>
          <li>没那么容易删 object version 或suspend version on bucket</li>
        </ul>
      </li>
      <li>需要开启version
        <ul>
          <li>bucket owner/root 才能开关bucket 的 MFA</li>
          <li>only support CLI</li>
        </ul>
      </li>
      <li>
        <p>Pre-signed URLs</p>

        <ul>
          <li>给临时想访问的人</li>
        </ul>
      </li>
      <li>通过CLI or SDK 创建 url
        <ul>
          <li>下载url 通过CLI</li>
          <li>上传url 通过SDK</li>
          <li>默认3600秒有效期， 通过TIME_BU_SECOND 参数设置</li>
          <li>URL的使用者权限继承了创建url的人得权限</li>
        </ul>
      </li>
      <li>
        <p>logging</p>

        <ul>
          <li>S3 access log (对人)</li>
          <li>存在另一个bucket 中， 可以通过Athena 来进行查询分析
            <ul>
              <li>不要去监控logging bucket</li>
            </ul>
          </li>
          <li>CloudTrail to log API calls （对应用）</li>
        </ul>
      </li>
      <li>S3 access log 只知道谁访问了S3, 但不知道谁改了配置。</li>
    </ul>
  </li>
  <li>
    <p>Block public access</p>

    <ul>
      <li>可以在bucket 中设置中禁止外网访问bucket</li>
      <li>可以在account level 设置</li>
    </ul>
  </li>
  <li>
    <p>S3 website</p>

    <ul>
      <li>给bucket 打开配置， 并上传一个index.html 和 error.html</li>
      <li>给bucket 的policy 开通外网访问权限</li>
      <li>S3 网站如果需要TLS 加密的话需要使用 default s3.amazonaws.com TLS certificate.</li>
    </ul>
  </li>
  <li>
    <p>S3 CORS header （基于S3 website)</p>

    <ul>
      <li>（Cross-Origin Resource Sharing） 跨域资源共享</li>
      <li>A 站 的网页要显示 B 站的图片， 需要先去B拿允许，A使用 CROS Headers (ex: Access-Conrol-Allow-Origin) 再去请求资源</li>
      <li>在Bucket 中设置一段json ,授权请求方可以访问， Json内容包括
        <ul>
          <li>AllowedHeaders</li>
          <li>AllowedMethods</li>
          <li>AllowOrigins</li>
          <li>ExposeHeaders</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Access Point</p>

    <ul>
      <li>类似SG的功能， allow 某个VPC 或者所有 internet 的访问， 并为之设置 policy.</li>
    </ul>
  </li>
  <li>
    <p>Consistency policy</p>

    <ul>
      <li>S3保证app 调用API 写入信息后，立即读取就可以读到写入的内容。</li>
    </ul>
  </li>
  <li>
    <p>S3 Replication</p>

    <ul>
      <li>必须启动versioning</li>
      <li>两种方式(CRR &amp; SRR)
        <ul>
          <li>CRR , cross region replica
            <ul>
              <li>场景是：合规要求， 跨账号的 replica</li>
            </ul>
          </li>
          <li>SRR, Same region 的 replica
            <ul>
              <li>场景： 需要一个用来分析日志的bucket</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>replica 创建好后，老的数据并不会同步到replica, 只有新的object 才会同步到replica.</li>
      <li>主S3 的 delete 标志也会被同步到replica, (选项可以被关闭)</li>
      <li>但是删除的版本ID不会被同步， 防止可以删除</li>
      <li>replication 的复制不能是链状的， 只能是两个bucket 之间的， 比如只能是a→b, 不能是a→b→c</li>
    </ul>
  </li>
</ul>

<h4 id="s3-storage-classes">S3 Storage Classes</h4>

<ul>
  <li>
    <p>Type</p>

    <ul>
      <li>General</li>
      <li>IA
        <ul>
          <li>4 9s</li>
          <li>场景 - backups, 灾备</li>
        </ul>
      </li>
      <li>One Zone IA
        <ul>
          <li>可以重建的数据， 第二备份</li>
          <li>2.5 9s S3中最低的</li>
          <li>场景：可重建的缩略图，xx天后可删除</li>
        </ul>
      </li>
      <li>Glacier
        <ul>
          <li>场景：xx天后，用户可以等待xx小时获取数据</li>
          <li>Glacier 默认支持加密， 包括了 数据加密和传输加密（data at rest and in-transit）</li>
          <li>Retrieval Mode
            <ul>
              <li>expedited 版要1-5分钟</li>
              <li>standard版要3-5个小时</li>
              <li>bulk版要5-12个小时</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Glacier Deep Archive
        <ul>
          <li>Retrieval Mode
            <ul>
              <li>standard 版要12个小时才能读到数据</li>
              <li>bulk 版要48个小时才能读到数据</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Intelligent Tiering
        <ul>
          <li>AI 基于数据使用情况每个月做一次自动扫描分析和自动分层。</li>
          <li>S3 intelligent Tiering class 是为了优化成本而设计， 可以自动迁移数据到成本优化的访问层。 主要分为两层
            <ol>
              <li>频繁访问层</li>
              <li>不频繁访问层。</li>
            </ol>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>LifeCycle policy/Rule</p>

    <ul>
      <li>将object 在满足某个条件后从一个 存储类型转到另一个存储类型 ， 或者删除</li>
      <li>rule 可以应用于某个过滤条件
        <ul>
          <li>比如：创建一个 lifecycle policy, 45天后通过 prefix 把/images 放到 S3 Standard IA</li>
        </ul>
      </li>
      <li>只能从高往低转， 不能从低往高转
        <ul>
          <li>object 在从standard 到 IA （或者从 IA 到 one zone IA）状态最少要30天后才能转型到另一个状态</li>
          <li>从 standard 到 Glacier/Glacier Deep Archive 没有限制，当天或者过一天就可以转</li>
        </ul>
      </li>
    </ul>

    <p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h0uhff2cmgj20h10aot8v.jpg" alt="img" /></p>
  </li>
  <li>
    <p>S3 Analytics</p>

    <ul>
      <li>对当前存储分类进行分析， 并给出建议， 比如应该把一些object 放到 IA 等</li>
      <li>不支持One Zone 和 Glacier</li>
      <li>可以和LifeCycle Rule 配合一起使用，用S3 Analytics 分析好了之后就用 LifeCycle Rule 给文件做规划</li>
    </ul>
  </li>
  <li>
    <p>Athena</p>

    <ul>
      <li>serverless</li>
      <li>对S3 的对象做分析的工具</li>
      <li>使用标准的SQL 语句分析S3上的文件</li>
      <li>场景
        <ul>
          <li>BI, 分析，报表</li>
          <li>VPC 的 Flow logs, ELB logs, Cloudtrail trails and etc.</li>
          <li>后面可以再接一个Amazon QuickSight 服务。</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="s3-performance">S3 Performance</h4>

<ul>
  <li>S3 的性能是可以同时支持5500个读操作/秒，同时支持3500个写操作/秒</li>
  <li>提升性能的方法
    <ul>
      <li>Multi-part upload, 提高并发，加快速度</li>
      <li>S3 Transfer Acceleration,通过网络优化加快速度（ 从AWS Edge介入AWS 内网专线到达S3 ）</li>
      <li>S3 Byte Range Fetches, 分多块并行下载， 加快下载速度。也可以用于只下载大文件的一小部分</li>
      <li>S3 Select &amp; Glacier Select,
        <ul>
          <li>客户端发送带 Where(SQL) 语句的请求给S3, S3 在服务端执行语句， 把过滤后的结果的object 返回给客户端， 减少传输size , 加快下载速度。</li>
        </ul>
      </li>
      <li>Prefixes （前缀法）
        <ul>
          <li>S3://my-bucket/folder/subfolder/my_file.txt</li>
          <li>﻿key 是整个url, 其中my_file.txt是 object name, /folder/subfolder 是 prefix</li>
          <li>可以通过在bucket 中建立多个 prefix 的方式并行并行处理读写， 成倍增加吞吐量
            <ul>
              <li>比如增加10个 prefix 可以把吞吐量提高到 35000 的写， 55000的读</li>
            </ul>
          </li>
          <li>S3 没有限制 prefix 的个数，</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="s3-event-notification">S3 Event Notification</h4>

<ul>
  <li>比如上传了一个图片， 就触发一个推送</li>
  <li>触发的对象可以是
    <ul>
      <li>SNS</li>
      <li>SQS</li>
      <li>SNS -&gt; SQS</li>
      <li>Lambda</li>
      <li>Event Bridge -&gt; ECS</li>
    </ul>
  </li>
</ul>

<p>S3 Requester Pays</p>

<ul>
  <li>
    <p>默认是bucket owner 付费</p>
  </li>
  <li>
    <p>requester pays</p>

    <ul>
      <li>是owner负责 storage 的费用</li>
      <li>请求数据的人付下载数据的费用</li>
    </ul>
  </li>
  <li>
    <p>requester 必须是AWS 用户， 不能是非AWS账号用户</p>
  </li>
</ul>

<h4 id="文件锁-两种">文件锁， 两种</h4>

<ul>
  <li>Glacier Vault Lock 保险箱锁
    <ul>
      <li>应用于 WORM （write once and read many）模式 。 只允许写一次， 之后就再也不能修改/删除这个文件了，可以随便读。</li>
      <li>放在S3中的 object 和 对应的policy 可以被 vault lock 锁上， 没人可以修改这个文件以及对应的权限了。</li>
      <li>用于合规和特殊数据保护</li>
    </ul>
  </li>
  <li>S3 Object Lock
    <ul>
      <li>应用于 WORM （write once and read many）模式 。 只允许写一次， 之后就再也不能修改/删除这个文件了，可以随便读。</li>
      <li>把一个对象的一个版本锁住一段时间</li>
      <li>Modes
        <ul>
          <li>普通模式 - 限制一个版本一段指定的时间</li>
          <li>Legal mode, 限制一个版本，没有指定时间</li>
          <li>Governance mode ， 不允许大多数用户修改，少数用户可</li>
          <li>Compliance mode, 比Governance mode 更严格， 包括 root 在内， 谁也不能改， 时间段也不能缩短</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="s3-storage-gateway">S3 Storage Gateway</h4>

<ul>
  <li>S3 是 AWS私有的技术， 不能在on-premise 服务器上应用</li>
  <li>Storage Gateway 用于bridge on-premise 和 AWS S3 的数据传输</li>
  <li>有三种Storage Gateway ， 都要安装在客户的服务器上
    <ul>
      <li>File gateway
        <ul>
          <li>用于on-premise应用将数据文件存储/备份到AWS上</li>
          <li>通过IAM Role 访问S3 bucket</li>
          <li>**使用NFS 和 SMB **</li>
          <li>和AD （active directory） 整合进行用户认证</li>
          <li>关键字 - AD， <strong>NFS, SMB</strong>， aata file</li>
          <li>案例：</li>
          <li>公司的legacy 报表应用有上G 的.json 文件来自不同的数据源都存在了on-premise storage location， 没有办法承受继续增加的文件size.  公司并不想改变这个 legacy 应用， 希望可以把数据从 on-premise 应用更新到S3 上， 建议的方案是：
            <ol>
              <li>在 on-premise 上设置 file gateway,</li>
              <li>配置数据源写.json 文件到file gateway 上。</li>
              <li>让 legacy 应用读取 file gateway 的文件。</li>
              <li>file gateway 可以把数据replica 到S3上</li>
            </ol>
          </li>
        </ul>
      </li>
      <li>Volume gateway
        <ul>
          <li>将基于云的iSCSI block storage volume 给on-premise 应用 使用
            <ul>
              <li>Volume Gateway provides an iSCSI target, which enables you to create block storage volumes and mount them as iSCSI devices from your on-premises or EC2 application servers. The Volume Gateway runs in either a cached or stored mode:</li>
              <li>In the cached mode, your primary data is written to S3, while retaining your frequently accessed data locally in a cache for low-latency access.</li>
              <li>In the stored mode, your primary data is stored locally and your entire dataset is available for low-latency access while asynchronously backed up to AWS.</li>
            </ul>
          </li>
          <li>Volume Gateway 提供的服务是让on-primise 的应用/用户可以在本地访问网络磁盘， 通过 <strong>cached volume</strong> 把经常访问的文件缓存到用户本地， 而同时把所有的文件都备份到S3中。</li>
          <li>关键字 volume, <strong>block storage</strong>， iSCSI</li>
        </ul>
      </li>
      <li>Tape gateway
        <ul>
          <li>用于把 tape backup 挪到 cloud.</li>
          <li>关键字 VTL (Virtual Tape Library), Tape， tape</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Harware Applianc
    <ul>
      <li>如果客户不让安装Storage Gateway软件， 那么让客户买个硬件 - hardware appliance , 它上面自带了storage gateway</li>
      <li>关键字 - 没有on-premise virtulization</li>
    </ul>
  </li>
</ul>

<h4 id="s3-bucket-policy">S3 Bucket Policy</h4>

<ul>
  <li>可以定义S3 被不同账号的用户进行访问。</li>
  <li>Bucket policy 可以给不同账号分配权限来访问资源，可以带上若干条件
    <ul>
      <li>date condition - 比如访问时间</li>
      <li>bollean condition - 比如是否是SSL</li>
      <li>IP condition - 比如是否来自某个地区</li>
      <li>string condition - 比如是否来自某个应用</li>
    </ul>
  </li>
  <li><strong>想让外部用户访问S3 Bucket，并确保 bucket owner (并不是object 的创建者) 可以访问所有的object, 就需要创建bucket policy ，在上传文件的时候 grant bucket-owner-full-control 权限</strong></li>
  <li>案例
    <ul>
      <li>提到公司给客户提供S3使用的服务， 希望可以既有用户层面的跨账号访问能力， 又有账号层面的一个账号有多个用户的能力， 方案是 - 使用S3 Bucket Policy</li>
    </ul>
  </li>
</ul>

<h4 id="s3-sync">S3 Sync</h4>

<ul>
  <li>S3 之间拷贝大量数据 （不能用Snowball 的前提下）</li>
  <li>使用 S3 Sync 命令 可以将大量数据快速在S3 之间进行copy</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1</pre></td><td class="code"><pre>aws s3 sync s3://DOC-EXAMPLE-BUCKET-SOURCE s3://DOC-EXAMPLE-BUCKET-TARGET
</pre></td></tr></tbody></table>
</div>
</div>

<ul>
  <li>案例
    <ul>
      <li>公司把1P的数据通过Driect connection 方式拷贝到了一个AZ 的S3中， 现在希望把数据也拷贝到另一个AZ的S3，(不能用Snow Ball) 最好的方法是S3 sync 命令</li>
    </ul>
  </li>
</ul>

<h4 id="s3-bucket-object-retention-文件的保留时间">S3 Bucket Object Retention (文件的保留时间)</h4>

<ul>
  <li>
    <p>可以通过两种方法</p>

    <ul>
      <li>
        <p>用Retain Until Date (一个指定的明确的过期日期) 给一个object 的 version 设置retention period</p>

        <ul>
          <li>一个object 的不同的版本可以设置不同的 retention mode 和 periods</li>
        </ul>
      </li>
      <li>
        <p>也可以通过bucket 的 default setting 中设置 retention period, 但只能设置duration , 不能设置 retain until date。</p>
      </li>
    </ul>
  </li>
  <li>
    <p>如果题目说了每个对象会有不一样的retention, 就不能bucket default setting</p>
  </li>
</ul>

<h4 id="s3-的-consistent-一致性">S3 的 consistent （一致性）</h4>

<ol>
  <li>S3 is strongly consistent for all <strong>GET</strong>, <strong>PUT</strong> and <strong>LIST</strong> operations.</li>
  <li>当做完一个成功的写操作/overwrite/delete , 后续的读操作都会得到最新的版本的object 和 list</li>
  <li>S3 已经支持修改 tag, ACL, metadata 之后的读也会拿到最新版本的 objects 和 list</li>
</ol>

<h3 id="efs">EFS</h3>

<h4 id="efs-1">EFS</h4>

<ul>
  <li>跨az</li>
  <li>对ec2是一对多 (100+)</li>
  <li>有单独的SG</li>
  <li>比gp2贵3倍</li>
  <li>最大吞吐量 3Gbps</li>
  <li>linux only(NFS 4.1) , auto scale (pb)</li>
  <li>通过 CloudWatch BurstCreditBalance metric 来检测EFS的性能是否在正常水平</li>
  <li>encryption
    <ul>
      <li>Upon file system creation, check the Encrypted File System option.
        <ul>
          <li>在创建文件</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>type
    <ul>
      <li>performance mode (速度快)
        <ul>
          <li>MaxIO</li>
          <li>General Purpos</li>
        </ul>
      </li>
      <li>throughput mode (吞吐量大)
        <ul>
          <li>provisioned throughput mode</li>
          <li>bursting throughput mode
            <ol>
              <li>Provisioned Throughput Mode 是预留吞吐量模式，用于有明确的高吞吐量的预期的情景。 可以随时提升吞吐能力，但是降低吞吐能力需要等待超过24小时。
                <ol>
                  <li><strong>如果您的文件系统相对较小，但也可以提供高吞吐率</strong></li>
                </ol>
              </li>
              <li>Bursting Throughput Mode
                <ol>
                  <li>是默认的EFS 吞吐量模式，平时维持低吞吐量，可以应付爆炸式的瞬间高吞吐量，然后再落回地吞吐量模式。</li>
                  <li><strong>您存储的越多，您可以使用的吞吐量就越大</strong></li>
                </ol>
              </li>
              <li>AWS EFS 默认使用Bursting Throughput Mode, 但如果你的EFS有大量是的数据需要高频率的读写， 那么建议改成 provisioned Throughput mode.</li>
            </ol>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>storage tiers (life cycle management 可以把不常用的文件放从standard放到infrequent access （EFS-IA） 省点钱)</li>
</ul>

<h4 id="efs-ia-infrequent-access">EFS IA (Infrequent Access)</h4>
<ul>
  <li>可以通过给EFS 创建 lifecycle 来把EFS 转成EFS IA 来达到省钱的目的。</li>
  <li>Choose Lifecycle Management file access policy to transition files to infrequent access (7, 14, 30, 60, or 90 days) using the AWS CLI, API, or Amazon EFS Management Console.
    <ul>
      <li>最多可以把文件创建90天后转成 EFS IA</li>
    </ul>
  </li>
</ul>

<h4 id="efs-ebs-s3-的价格对比">EFS, EBS, S3 的价格对比</h4>

<ul>
  <li>
    <p>EFS -</p>

    <ul>
      <li>用多少付多少</li>
      <li>$0.3 / GB / Month</li>
    </ul>
  </li>
  <li>
    <p>EBS</p>

    <ul>
      <li>Provision（预定） 多少付多少</li>
      <li>$0.1 / GB / Month</li>
    </ul>
  </li>
  <li>
    <p>S3</p>

    <ul>
      <li>用多少付多少</li>
    </ul>
  </li>
  <li>
    <p>$0.023 / GB / Month</p>
  </li>
  <li>
    <p>有可能EBS 会Provision 了很多G磁盘， 所以会很贵</p>
  </li>
</ul>

<h4 id="efs-performance-modes">EFS performance modes</h4>

<ul>
  <li>有两种性能模式
    <ul>
      <li>Max I/O 性能模式
        <ul>
          <li>高并发的应用和负载， 比如大数据分析， 媒体文件处理， 基因分析等</li>
        </ul>
      </li>
      <li>General Purpose 性能模式
        <ul>
          <li>用于一般的EFS 存储场景， 比如web 环境， CMS ， 主页目录， 一般性的文件存储。</li>
          <li>如果创建EFS 的时候没有选择 performance mode, 默认就是 general purpose mode</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="fsx">FSx</h3>

<h4 id="fsx-1">FSX</h4>

<ul>
  <li>
    <p>FSX用于加载第三方的文件系统， 包含Windows 等</p>
  </li>
  <li>
    <p>FSx for windows file server</p>

    <ul>
      <li>支持将microsoft Distributed file system replication(DFS / DFSR) 迁移到AWS FSX for windows file server</li>
      <li>
        <p>SMB （Server Message Block）是windows 的文件系统。 提到SMB 就应该是 FSx for windows file server</p>
      </li>
      <li><strong>- FSX for windows file server 和 Storage Gateway (FSx File Gateway) 都支持 SMB</strong>
  <strong>- 题目提到的如果是如何迁移到AWS, 就是 Storage Gateway (FSx File Gateway)</strong>
  <strong>- 题目提到的如果是如何迁移后如何在AWS 管理, 就是 FSx for windows file server</strong></li>
    </ul>
  </li>
  <li>
    <p>FSx for Lustre, 是并行分布式文件系统, 支持</p>

    <p>并行数据处理， 支持人工智能, HPC,</p>

    <ul>
      <li>和 S3 无缝衔接， 把S3读到FSX中， 再把计算结果写回到S3中</li>
    </ul>
  </li>
  <li>
    <p>提到 windows 文件系统迁移就是 FSx for windows file server, 提到 POSIX 和高性能 IOPS , 就是 FSX for Luster</p>
  </li>
  <li>
    <p>文件系统部署选项</p>

    <ul>
      <li>短期的用Scratch File System (性能更好 但是没有replica)</li>
      <li>长期的用persistent file system, 有replica</li>
    </ul>
  </li>
</ul>

<h2 id="数据库">数据库</h2>

<h3 id="elasticache">ElastiCache</h3>

<h4 id="elasticash">ElastiCash</h4>

<ul>
  <li>管理Redis 和 Memcached</li>
  <li>通过内存数据库的高速响应缓解数库的大量重复的I/O工作</li>
  <li>底层是EC2</li>
  <li>需要改代码</li>
  <li>用途
    <ul>
      <li>将频繁读取的数据放到cache中</li>
      <li>放用户的session 数据 （可设置TTL）</li>
    </ul>
  </li>
  <li>场景
    <ul>
      <li>排行榜 （Redis Sorted Sets 功能， 随着新元素的加入，可以快速创建元素的排序）</li>
    </ul>
  </li>
  <li>Redis 和 memcache 区别
    <ul>
      <li>Redis 支持
        <ul>
          <li>multi az, auto failover</li>
          <li>Read Replica to scale</li>
          <li>Data Durability， 使用AOF 支持数据持久性(把数据存在硬盘上)</li>
          <li>backup, restore</li>
        </ul>
      </li>
      <li>Memcache (多线程架构）支持
        <ul>
          <li>multi-node sharding</li>
          <li>multi-threading</li>
          <li>不支持
            <ul>
              <li>HA，persistent, backup/restore</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Security
    <ul>
      <li>security group</li>
      <li>不支持IAM Database authentication (application/ aws user level)</li>
      <li>Redis Auth 在创建Redis cluster 的时候可以设置 password/token, 让用户应用访问。这不是IAM level 的 auth.</li>
      <li>Memcached Auth , 支持 SASL 认证</li>
      <li>ElastiCache 没有什么 IAM policy， 只能 用于 API level 安全</li>
      <li>SSL for flight encryption</li>
    </ul>
  </li>
</ul>

<h4 id="elasticache-strategy">ElastiCache Strategy</h4>

<ul>
  <li>Cache-aside 模式
    <ul>
      <li>读的时候先读缓存，没有就读数据库，读出来后放入缓存，同时返回响应</li>
      <li>更新的时候，先删除缓存， 然后在更新数据库（缓存和数据库双写）</li>
    </ul>
  </li>
  <li>Lazy Loading/ Lazy Population
    <ul>
      <li>只有需要的时候才把数据加载到Cache中，这种策略可以节省缓存的size.  但是读的时候往往需要先从数据库中读，稍微慢点。</li>
      <li>为什么是删除缓存而不是更新缓存， 这里就是懒加载的策略
        <ul>
          <li>因为当前的缓存可能会成为冷数据， 访问频率不高，没必要去更新，只有当下一次对该数据有读的请求的时候，采取更新缓存。这就是一种懒加载的思想。</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Write Through
    <ul>
      <li>只要写到数据库，就写到缓存，这样比较费cache 的size，但好处是可以提供最快的读。</li>
      <li>双写，对数据库写了， 就要写cache</li>
    </ul>
  </li>
  <li>Cache 的消除（Evictions）的几种途径
    <ul>
      <li>手动直接删除cache 中的item内容</li>
      <li>内存满了，会把最近不使用的item 删掉</li>
      <li>为item 设置一个TTL</li>
    </ul>
  </li>
</ul>

<h4 id="elasticache-cluster-mode">ElastiCache Cluster Mode</h4>
<ul>
  <li>ElastiCache Replication
    <ul>
      <li>Cluster Mode Disabled
        <ul>
          <li>所有的数据都在一个Shard 里面</li>
          <li>1个Shard 里面 有1个primary node, 可以有最多5个 replicas</li>
          <li>primary node 负责读和写， 其他replica 负责读</li>
          <li>数据是通过异步形式传输</li>
          <li></li>
        </ul>
      </li>
      <li>Cluster Mode Enabled
        <ul>
          <li>数据跨Shard ， 可以多点写入</li>
          <li>1个Shard 里面 有1个primary node, 可以有最多5个 replicas</li>
          <li>可以跨AZ部署</li>
          <li>每个Cluster 可以有最多500个nodes</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="rds">RDS</h3>

<h4 id="rds-1">RDS</h4>

<ul>
  <li>
    <p>AWS 管理， Cannot SSH， 底层是EC2 + EBS Volume</p>
  </li>
  <li>
    <p>auto backup, AWS 负责执行</p>

    <ul>
      <li>daily full backup, 5 mins transation log backup</li>
      <li>can restore 5 mins ago</li>
      <li>备份默认存7天， 可延长到35天</li>
    </ul>
  </li>
  <li>
    <p>auto storage scaling</p>

    <ul>
      <li>aws 负责自动扩容db的容量</li>
      <li>还剩10%， 还剩5分钟用完就自动扩</li>
      <li>可以手设置 max limit for db storage</li>
      <li>默认RDS Mysql 是不开启auto scalling 的, 需要手动打开 <strong>storage auto-scaling</strong> 设置</li>
    </ul>
  </li>
  <li>
    <p>Snapshot</p>

    <ul>
      <li>手动进行， 是backup的补充， 可以自定义保留backup 时间</li>
    </ul>
  </li>
  <li>
    <p>Read Replica /读写分离 (用于scaling)</p>

    <ul>
      <li>最多5个 read replica (aurora15个)</li>
      <li>async （异步传输）
        <ul>
          <li>跨region花钱， 同region 不花钱</li>
        </ul>
      </li>
      <li>需要调整代码</li>
    </ul>
  </li>
  <li>
    <p>Multi AZ (用于灾备， 不是用于scaling)</p>

    <ul>
      <li>
        <p>single dns name (统一入口， 下面是跨az 的 master 和 standbys)</p>
      </li>
      <li>
        <p>3.5 9s</p>
      </li>
      <li>
        <p>sync (同步传输)</p>

        <ul>
          <li>Sync 的解释：
            <ul>
              <li>Two-way communication between a client and an app or between two apps that require a response to each request
                <ul>
                  <li>比如 HTTPS, SSH, HTTP 都是同步的</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>auto failover (无需人工介入, 不用改代码）</p>

        <ul>
          <li>当一个数据库挂了， Multi-AZ 可以快速在Primary 和 Standby 之间进行切换 （跨AZ）。</li>
          <li>切换时间一般在60-120秒之间</li>
        </ul>
      </li>
      <li>
        <p>当一个 multi-az 的 RDS 的 primary instance 挂了，会发生什么事情？</p>

        <ul>
          <li>
            <p>CNAME 记录会被更新，指向 standby DB.</p>

            <ol>
              <li>single dns name (统一入口， 下面是跨az 的 master 和 standbys)</li>
              <li>CNAME 可以将 一个域名跳转到转另一个域名</li>
              <li>RDS multi-az 通过 更新CNAME 记录 来实现 auto failover ， 自动的将原来的RDS URL 指向standby DB</li>
              <li>连接数据库的URL 并没有变化</li>
            </ol>
          </li>
          <li>
            <p>当 primary database 失败了， RDS 自动 启动 （initiate）failover to standby</p>
          </li>
        </ul>
      </li>
      <li>
        <p>OS 升级维护的流程</p>

        <ul>
          <li>RDS 先在 Standby 上 执行OS 更新 进行 维护工作， 然后等standby 启动后把standby 设置成 primary</li>
          <li>然后再对old primary 进行维护， 然后把old primary设置成standby;</li>
        </ul>
      </li>
      <li>
        <p>Multi-az <strong>database engine level 升级</strong>维护</p>

        <ol>
          <li>部署了 multi-az 的 RDS DB 的任何engine level 的升级维护，都需要让 primary 和 standby <strong>同时升级</strong>， 会有downtime ，直到升级完成。
            <ol>
              <li>downtime 要根据升级的规模大小而定</li>
            </ol>
          </li>
        </ol>
      </li>
      <li>
        <p>single az to multi az的步骤 - 点击modify 按钮就可以了。 背后的逻辑</p>

        <ul>
          <li>创建snapshot → 恢复成standby db 到另一个az → 开始sync</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>encryption</p>

    <ul>
      <li>
        <p>type</p>

        <ul>
          <li>at rest (数据库本身)</li>
          <li>done only first time create DB instance
            <ul>
              <li>kms aes-256</li>
              <li>主没加密， 从也不能加密</li>
            </ul>
          </li>
          <li>in-flight (数据传输)
            <ul>
              <li>SSL</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>
        <p>加密操作 ：</p>
      </li>
      <li>create snapshot → copy and encrypt → restore to new → delete old</li>
      <li>Transparent Data Encryption (TDE) 透明数据加密
        <ul>
          <li>只有 Oracle 和 Sql Server 支持</li>
          <li>Only SQL Server and Oracle DB support TDE, which encrypts the data at a database level, on top of the storage layer and in the software itself.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Security</p>

    <ul>
      <li>put in private subnet</li>
      <li>security group</li>
      <li>IAM policy (user level) &amp; Role (service level)</li>
      <li>username &amp; password(admin level) in secret manager</li>
      <li>IAM Database authentication (application level/user level)
        <ul>
          <li>mysql &amp; postgresql</li>
          <li>应用程序/aws用户不需要用户名密码，而是拿着 IAM role 去RDS Server 那个token, 然后拿着token去连接数据库</li>
        </ul>
      </li>
      <li>题目：
        <ul>
          <li>哪种AWS Database 可以用 IAM Database Authentication 来配置 （选两个）
            <ol>
              <li>RDS Mysql &amp; RDS PostGreSQL</li>
              <li>通过 IAM Database Authentication， 用户/应用就不需要用用户名和密码来访问数据库了， 只用authentication token 就可以了。</li>
              <li>Token 的有效期是15分钟。</li>
              <li>IAM database authentication works with MySQL, MariaDB and PostgreSQL.</li>
            </ol>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="aurora">Aurora</h4>

<ul>
  <li>
    <p>3倍postgresql, 5倍mysql</p>
  </li>
  <li>
    <p>master + up to 15 replicas</p>
  </li>
  <li>
    <p>Aurora Serverless (Aurora Cluster)</p>

    <ul>
      <li>是Aurora 的无服务模式， 可以按照访问量的高低自动增加和减少 replica， 完全不需要人员干预。</li>
      <li>是为OLTP（online Dtansactional Processing） 而设计的数据库模式， 可以scall down to 0, scall up to many.
        <ul>
          <li>OLTP - 联机事务处理过程(<em>OLTP</em>)，也称为面向事务的处理过程，一个步骤失败，都失败，所有步骤成功，都成功。</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>HA &amp; auto scale</p>

    <ul>
      <li>都是自动的， 原生的</li>
      <li>一个writer endpoint, 接一个master</li>
      <li>一个 reader endpoint 连接 Load banance, 下面接auto scaling 的 read replicas</li>
      <li>optional 可以有一个Customer endpoint, 用来指定某些高性能的read replica 用于特殊场景的读， 比如做分析报表。</li>
    </ul>
  </li>
  <li>
    <p>Multi-AZ Failover</p>

    <ul>
      <li>
        <p>游戏公司使用了5个 Aurora multi-az read replica 并使用了 failover target. 5个 replica 被分配了如下 failover priority tiers 和 实例size.</p>

        <ul>
          <li>tier-1 (16TB), tier-1 (32TB), tier-10 (16TB), tier-15 (16TB), tier-15 (32TB) .</li>
          <li>发生了failover , Aurora 会 promote 哪个 read replica? 答案是 tier-1 (32TB)</li>
        </ul>
      </li>
      <li>
        <p>每个Aurora replica 可以分配 priority tier (0-15, 数字越小优先级越高) 来支持 failover.</p>
      </li>
      <li>
        <p>如果有多个replica 使用了相同的tier, 那么failover 时会promote size更大的那个。</p>
      </li>
      <li>
        <p>如果tier 和 size 一样， 就随机挑一个</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Multi-Master</p>

    <ul>
      <li>为了能够瞬间处理Write Note的 failover</li>
      <li>Improved query concurrency
        <ul>
          <li>When deploying multiple masters for a relational database, it is possible to direct a higher number of write queries to the underlying database because the compute and storage tiers are separate infrastructures.</li>
        </ul>
      </li>
      <li>每个note 都做 R/W, 互相之间做 replica</li>
    </ul>
  </li>
  <li>
    <p>Cross Region</p>

    <ul>
      <li>
        <p>Aurora Global Database,</p>

        <ul>
          <li>1 region 做 primary （R/W）</li>
          <li>Up to 5 secondary regions (Read only)</li>
          <li>每个 secondary region 可以有最多16个 read replicas</li>
          <li>primary 的region 挂了， 立刻换到另一个region 作为 primary region</li>
          <li>Recovery Point Objective (RPO) of 1 second and a Recovery Time Objective (RTO) of 1 minute.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Security</p>

    <ul>
      <li>at rest , use KMS</li>
      <li>in flight use SSL</li>
      <li>IAM token (application level, 和 RDS一样)</li>
      <li>cannot ssh</li>
    </ul>
  </li>
  <li>
    <p>ML</p>

    <ul>
      <li>Aurora 可以应用机器学习服务
        <ul>
          <li>SageMaker, Comprehend</li>
          <li>场景， 产品推荐， 观点分析， 广告标签， 欺诈检测等</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="数据库端口">数据库端口</h4>

<ul>
  <li>PostgreSQL: 5432</li>
  <li>MySQL: 3306</li>
  <li>Oracle RDS: 1521</li>
  <li>MSSQL Server: 1433</li>
  <li>MariaDB: 3306 (same as MySQL)</li>
  <li>Aurora: 5432 (if PostgreSQL compatible) or 3306 (if MySQL compatible)</li>
</ul>

<h4 id="应用程序访问rds-需要的临时认证权限">应用程序访问RDS 需要的临时认证权限</h4>

<ul>
  <li>比如应用是 lambda ,不安全的方案是直接把用户名和密码配置到了应用中。更安全的方式是临时认证方案：
    <ol>
      <li>attach 一个 <strong>AWS Identity</strong> 和 <strong>IAM role</strong> 给Lambda</li>
      <li>使用 <strong>IAM ahthentication</strong> 让Lambda 去访问 RDS</li>
    </ol>
  </li>
</ul>

<h3 id="neptune">Neptune</h3>

<ul>
  <li>
    <p>高性能图数据库， 用于处理复杂关系， 比如社交网络, 谁 like 了谁， 谁回复了谁</p>
  </li>
  <li>
    <p>案例是Wikipedia , 知识图谱</p>
  </li>
  <li>
    <p>HA</p>

    <ul>
      <li>across 3 AZ, 15个 replicas</li>
      <li>clastering</li>
    </ul>
  </li>
  <li>
    <p>Backup , 连续backup 到S3</p>
  </li>
  <li>
    <p>安全</p>

    <ul>
      <li>KMS + HTTPS</li>
      <li>IAM authenticaiton</li>
    </ul>
  </li>
  <li>
    <p>关键字</p>

    <ul>
      <li>Graphs</li>
    </ul>
  </li>
</ul>

<h3 id="athena">Athena</h3>

<ul>
  <li>无服务数据库， 使用SQL 语句</li>
  <li>用于搜索S3中的数据</li>
  <li>可以根据建立自己的表， 用于存储搜索的内容， 结果可以返回给S3</li>
  <li>安全
    <ul>
      <li>IAM</li>
    </ul>
  </li>
  <li>场景
    <ul>
      <li>一次性SQL请求</li>
      <li>无服务的 S3查询</li>
      <li>日志分析</li>
    </ul>
  </li>
</ul>

<h3 id="redshift">RedShift</h3>

<h4 id="redshift-1">Redshift</h4>

<ul>
  <li>基于Postgresql</li>
  <li>相当与 Analytics / BI/ Data Warehouse</li>
  <li>是一个 OLAP (online analytical processing) 分析数据的数据仓库（data warehouse）</li>
  <li>支持高并发的请求 , 10倍 与其他data warehouse</li>
  <li>有SQL 接口</li>
  <li>和 AWS Quicksign ， AWS Tableau 集成</li>
  <li>上游
    <ul>
      <li>Kinesis Data Firehose</li>
      <li>S3 bucket</li>
      <li>EC2 JDBC</li>
      <li>DymamoDB</li>
      <li>DMS</li>
      <li>其他数据库</li>
    </ul>
  </li>
  <li>Node 是主要的计算单元
    <ul>
      <li>Leader Note - 负责计划和结果收集</li>
      <li>compute node - 负责执行queries, 发送结果给leader note</li>
    </ul>
  </li>
  <li>Redshift 数据库表的存储方式是<strong>列式存储</strong></li>
  <li>安全
    <ul>
      <li>backup &amp; restore</li>
      <li>IAM</li>
      <li>KMS</li>
    </ul>
  </li>
  <li>RedShift Cluster 是HA但不是fault-tolerant
    <ul>
      <li>A RedShift cluster is designed for performance and low latency, not for resilience, and while it has multiple components, the loss of any one will generate a short outage while it is replaced.</li>
    </ul>
  </li>
</ul>

<h4 id="redshift-spectrum">Redshift Spectrum</h4>

<ul>
  <li>专门用来读S3 的数据的</li>
  <li>需要先有Redshift cluster</li>
  <li>query 读取S3后 会放到上千个 Spectrum nodes中进行处理</li>
  <li>处理后放到Redshift compute node 中， 最后回到 leader node 中</li>
  <li>案例：
    <ul>
      <li>公司RedShift中的一部分历史数据迁移到了S3中， 分析师希望有一个每日的报告， 要使用这部分历史数据， 最好的方法是 Redshift Spectrum
        <ul>
          <li>使用 RedShift 的 Spectrum 功能， 将S3的历史数据映射到RedShift的Cluster Table中。 分析团队就可以链表查询了</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="redshift-durability">Redshift durability</h4>
<p>https://aws.amazon.com/blogs/aws/automated-cross-region-snapshot-copy-for-amazon-redshift
 <strong>想要增加RedShift 的 durability, 就用 cross-region snapshots</strong></p>

<h4 id="redshift-enhanced-vpc-routing">Redshift Enhanced VPC Routing</h4>

<ul>
  <li>为Redshift 优化的VPC, 方便通过 VPC 拷贝和上传数据， 不需要走外网。</li>
</ul>

<h4 id="redshift-和-athena-的比较">Redshift 和 Athena 的比较</h4>

<ul>
  <li>都是读S3 进行分析</li>
  <li>Redshift 更快， 感谢indexes</li>
</ul>

<h3 id="glue">Glue</h3>

<ul>
  <li>ETL 工具 （extract, transform, load）</li>
  <li>是个中间工具， 用于从数据源获取数据后进行转换， 然后再给分析的应用</li>
  <li>上游 抽取
    <ul>
      <li>RDS</li>
      <li>S3</li>
    </ul>
  </li>
  <li>下游
    <ul>
      <li>Redshift</li>
      <li>Athena -&gt;  QuickSignt</li>
      <li>EMR</li>
    </ul>
  </li>
  <li>Glue Data Catelog
    <ul>
      <li>Glue Data Crawler（爬虫）去S3, RDS, DynamoDB, JDBC 里面去抓取元数据</li>
      <li>将元数据写入到Data Catelog中的数据库和表中</li>
      <li>Glue Jobs 会 对数据进行转换</li>
      <li>将数据转换后发给 Athena, Redshift, EMR</li>
    </ul>
  </li>
</ul>

<h3 id="elasticsearchopensearch">ElasticSearch/OpenSearch</h3>

<ul>
  <li>新的名字是OpenSearch</li>
  <li>可以把数据库中的数据进行索引， 提供快速的搜索服务</li>
  <li>是对传统数据库的一个补充</li>
  <li>提供cluster 集群服务</li>
  <li>与AWS 进行整合的服务包括
    <ul>
      <li>Kinesis Data Firehose</li>
      <li>AWS IOT</li>
      <li>CLoudWatch logs</li>
    </ul>
  </li>
  <li>支持 multi-az</li>
  <li>安全
    <ul>
      <li>Cognito</li>
      <li>IAM</li>
      <li>KMS , SSL</li>
      <li>VPC</li>
    </ul>
  </li>
</ul>

<h2 id="灾备和迁移">灾备和迁移</h2>

<h3 id="灾备回复策略">灾备回复策略</h3>

<h4 id="备份策略">备份策略</h4>

<ol>
  <li>backup restore
    <ol>
      <li>等生产挂了，重新把备份恢复回去</li>
    </ol>
  </li>
  <li>Pilot Light - 小灯</li>
</ol>

<ul>
  <li>data center 为主</li>
  <li>阉割（critical infrastructure）版本运行在AWS （基础的EC2(stop)、read replica 的 RDS）</li>
  <li>不介意RTO (recovery point objective)比较长 ,</li>
  <li>类似备份恢复机制
    <ul>
      <li>data center 挂了</li>
      <li>启动EC2</li>
      <li>Route53 将流量切到AWS 的EC2上</li>
    </ul>
  </li>
</ul>

<ol>
  <li>Warm Standby - 热备份</li>
</ol>

<ul>
  <li>Data center 为主</li>
  <li>mini 的完整版本运行在AWS上 （ELB + EC2 带了ASG + slave RDB）</li>
  <li>data center 挂了， route53 马上切到AWS， 根据流量情况auto scale up/down EC2 和 RDS 的 Replica</li>
</ul>

<ol>
  <li>Multi Site / Hot Site Approach - 热站</li>
</ol>

<ul>
  <li>Active Active 模式</li>
  <li>Data Center 和 AWS 都是生产</li>
  <li>Route 53 会将流量分散到两边， 哪边挂了都不影响。</li>
</ul>

<ol>
  <li>AWS Muli Region</li>
</ol>

<ul>
  <li>没有 data center 了</li>
  <li>服务分别部署在两个 Region 中</li>
  <li>Active Active 模式</li>
  <li>Route 53 会将流量分散到两边， 哪边挂了都不影响。</li>
</ul>

<h4 id="rto--rpo">RTO &amp; RPO</h4>

<ul>
  <li>
    <p>RTO：</p>

    <ul>
      <li>Recovery Time Objective</li>
      <li>从宕机到恢复运营的时间段, 越长越不好。</li>
    </ul>
  </li>
  <li>
    <p>RPO:</p>

    <ul>
      <li>Recovery Point Objective</li>
      <li>从宕机到恢复运营， 恢复了怎样的程度。 也许恢复到了宕机前1周的程度，或者恢复了5分钟之前的程度。 越长越不好。</li>
    </ul>
  </li>
</ul>

<h4 id="灾难发生后如何快速恢复">灾难发生后如何快速恢复</h4>

<ul>
  <li>场景1： Goden AMI + 拷贝到 region
    <ol>
      <li>安装完软件后创建一个AMI ， 把AMI 拷贝到所有的region, （当灾难发生时）使用每个region 本地的AMI 进行灾难恢复
        <ol>
          <li>安装完软件后创建一个AMI的目的是做一个Golden AMI</li>
          <li>把AMI 拷贝到每个region 的目的是可以让每个region 在灾难发生时快速使用本地的 golden ami 来快速回复。</li>
        </ol>
      </li>
    </ol>
  </li>
</ul>

<h3 id="dms---data-migration-service">DMS - Data Migration Service</h3>

<ul>
  <li>数据迁移服务</li>
  <li>支持的迁移包括
    <ul>
      <li>Homogeneous migration 同质迁移</li>
      <li>Heterogeneous migration 异质迁移</li>
    </ul>
  </li>
  <li>必须要创建一个EC2 来执行 replication tasks
    <ul>
      <li>EC2 是在源和目标库之间进行迁移动作</li>
    </ul>
  </li>
  <li>源
    <ul>
      <li>on-premise database
        <ul>
          <li>oracle, mss sql server, mysql, mariadb, postgresql, mongodb, sap, db2</li>
        </ul>
      </li>
      <li>azure Sql db</li>
      <li>amazone RDS</li>
      <li>Amazon S3</li>
    </ul>
  </li>
  <li>Target
    <ul>
      <li>on-premise database
        <ul>
          <li>oracle, mss sql server, mysql, mariadb, postgresql, sap</li>
        </ul>
      </li>
      <li>AWS RDS</li>
      <li>AWS Redshift</li>
      <li>AWS DynamoDB</li>
      <li>AWS S3</li>
      <li>ElasticSearch</li>
      <li>Kinesis</li>
      <li>DocumentDB</li>
    </ul>
  </li>
  <li>AWS Schema Conversion Tool (SCT)
    <ul>
      <li>用于在异质数据库做迁移时，对数据模型的 Schema进行转换</li>
    </ul>
  </li>
  <li>迁移步骤
    <ul>
      <li>在源库所在环境安装AWS SCT</li>
      <li>SCT 将源数据库schema 转换成目标库的schema， 并创建目标库</li>
      <li>DMS 的 EC2 实例执行 replication task, 将源数据库的数据导入到目标数据库。</li>
    </ul>
  </li>
</ul>

<h3 id="sms---server-migration-service">SMS - Server Migration Service</h3>

<ul>
  <li>把on-premise 的服务器迁移到AWS</li>
</ul>

<h3 id="datasync">DataSync</h3>

<h4 id="datasync-1">DataSync</h4>

<ul>
  <li>从 on-premise/AWS 移动大量数据到 AWS
    <ul>
      <li>也可以是AWS不同region之间 进行数据迁移</li>
    </ul>
  </li>
  <li>比命令行快10倍</li>
  <li>和 DMS 不同， DMS 迁的是数据库， DataSync 迁移的是文件系统的数据</li>
  <li>上游
    <ul>
      <li>NAS, NFS, SMB 文件系统的文件</li>
    </ul>
  </li>
  <li>下游 （没有EBS, 因为EBS 不是文件系统。 所以不会从EBS 同步数据，也不会向EBS 同步数据）
    <ul>
      <li>S3</li>
      <li>EFS</li>
      <li>FSx</li>
    </ul>
  </li>
  <li>replication task 可以定时进行，每小时/天/周</li>
  <li>需要在on-premise 安装一个 DataSync agent</li>
  <li>可以设置迁移时使用的带宽限制</li>
  <li>案例
    <ul>
      <li>NFS/SMB Server → DataSync agent → AWS DataSync → AWS S3/EFS/FSx</li>
      <li>VPC1 EFS → VPC1 EC2 instance with DataSync agent → VPC2 AWS DataSync → VPC2 EFS</li>
    </ul>
  </li>
</ul>

<h4 id="迁移大量数据的计算">迁移大量数据的计算</h4>

<ul>
  <li>例如 迁移200T的数据， 带宽是100Mbps , 需要多长时间
    <ul>
      <li>数据大小（M）/ 速度（Mb/s） = 时间(s)
        <ul>
          <li>1 Mbps = 1/8 Mb/s</li>
          <li>1 天 = 86400 s</li>
          <li>200 *1000 * 1000 / ( 100/8 ) = 160000000s = 185天</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>如果用Direct Connect (DX) 1Gbps
    <ul>
      <li>需要等一个月， 然后还需要18.5天</li>
    </ul>
  </li>
  <li>用 snowball 迁
    <ul>
      <li>2-3 个 snowball</li>
      <li>1周时间把数据搞到snowball 里面 + 运输 + 迁移完成</li>
    </ul>
  </li>
</ul>

<h3 id="aws-backup">AWS Backup</h3>

<h4 id="aws-backup-1">AWS Backup</h4>

<ul>
  <li>
    <p>AWS Backup 对AWS 的服务备份进行集中管理，做到符合公司的合规要求和数据保护。</p>
  </li>
  <li>
    <p>创建好back plan 之后， 备份就是自动进行</p>
  </li>
  <li>
    <p>流程</p>

    <ul>
      <li>AWS Backup → 创建备份计划 → 执行备份 → 备份拷贝到 S3</li>
    </ul>
  </li>
  <li>
    <p>支持的服务包括 (</p>

    <p>不包含S3</p>

    <p>)</p>

    <ul>
      <li>FSx</li>
      <li>EFS</li>
      <li>DynamoDB</li>
      <li>EC2</li>
      <li>EBS</li>
      <li>RDS</li>
      <li>Aurora</li>
      <li>Storage Gateway</li>
    </ul>
  </li>
  <li>
    <p>支持 跨 Region 备份</p>
  </li>
  <li>
    <p>支持跨 账号 备份</p>
  </li>
  <li>
    <p>支持 即时恢复 （PITR point-in-time recovery）</p>
  </li>
  <li>
    <p>按序， 定时备份</p>
  </li>
  <li>
    <p>基于 tag 的 备份策略</p>
  </li>
</ul>

<h4 id="backup-plan--可以在不同维度设置backup-plan-的-policy">Backup Plan , 可以在不同维度设置backup plan 的 policy</h4>

<ul>
  <li>频率 - 每12小时， 周，月， cronjob</li>
  <li>备份转为cold storage - 永不， day, week, month, year</li>
  <li>备份保留时间 - 永远， days, weekly, monthly</li>
</ul>

<h2 id="无服务">无服务</h2>

<h3 id="aws-cognito">AWS Cognito</h3>

<h4 id="aws-cognito-1">AWS Cognito</h4>

<ul>
  <li>
    <p>是AWS 的一个独立服务， 为客户提供认证管理服务</p>
  </li>
  <li>
    <p>Cognito User Pools</p>

    <ul>
      <li>为用户提供登录（sign in）服务</li>
      <li>和API Gateway 进行整合</li>
      <li>返回JWT (json web token)</li>
    </ul>
  </li>
  <li>
    <p>Cognito Identity Pools (Federated Identity)</p>

    <ul>
      <li>为客户提供AWS 认证， 以便让用户可以访问AWS 服务</li>
      <li>场景： 让一个facebook 用户可以访问AWS 的S3 bucket</li>
    </ul>
  </li>
  <li>
    <p>Cognito Sync</p>

    <ul>
      <li>在用device 和Cognito 之间同步数据</li>
    </ul>
  </li>
  <li>
    <p>Cognito 通过 AWS STS 生成temporary credentials 给客户（mobile app）， 客户拿着证书再去访问其他的服务（AWS S3）</p>

    <ul>
      <li>场景不仅仅是S3, 还可以是 DynamoDB, Lambda 等等</li>
    </ul>
  </li>
</ul>

<h3 id="api-gateway">API Gateway</h3>

<h4 id="api-gateway-1">API Gateway</h4>

<ul>
  <li>提供 restful API 给客户、其他AWS 服务
    <ul>
      <li>通过Lambda 提供 Put, Post, Get, Delete 等 Restful API 接口</li>
    </ul>
  </li>
  <li>客户可以直接请求API gateway, api gateway 再调用 lambda 对逻辑进行处理， 然后将结果写入到 DynamoDB</li>
  <li>可以提供API 版本功能</li>
  <li>可以生成 SDK 和 API 文档说明书（specifications）</li>
  <li><strong>可以Cache API 的 response</strong></li>
  <li>安全
    <ul>
      <li>通过<strong>SigV4</strong> 提供 IAM Credential 认证和登录</li>
      <li>Custom (Lambda ) Authorizer
        <ul>
          <li>利用Lambda 来验证请求的 header 中带过来的 token</li>
          <li>lambda 会使用OAuth/SAML等第三方认证进行验证</li>
          <li>Lamdba 需要返回一个IAM Policy 给用户， 下次用户就用这个policy 访问 API</li>
        </ul>
      </li>
      <li>AWS Cognito User Pools
        <ul>
          <li>AWS Gateway 通过访问 Cognito验证token</li>
          <li>cognito user pool维护用户在google, facebook 等网站的用户认证。</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>关键词
    <ul>
      <li>Swagger</li>
      <li>Open API</li>
      <li>SigV4 (Signature Version 4 (SigV4) , 把将身份验证信息添加到由 HTTP 发送的 AWS API 请求的过程.)</li>
      <li>Customer Authorizer</li>
      <li>Cognito , Google, Facebook login</li>
    </ul>
  </li>
</ul>

<h4 id="三种方法来部署api-gateway---endpoint-type">三种方法来部署API Gateway - Endpoint type</h4>

<ul>
  <li>
    <p>Edge-optimized (default) : for global client.</p>

    <ul>
      <li>API Gateway 部署在某个Region ,但是通过CloudFront edge location来优化线路， 加快全球的访问速度</li>
    </ul>
  </li>
  <li>
    <p>Regional - 只在一个国家部署。</p>
  </li>
  <li>
    <p>Private - 只能在AWS 内部被VPC 通过ENI 访问</p>
  </li>
</ul>

<h3 id="lambda">Lambda</h3>

<h4 id="lambda-1">Lambda</h4>

<ul>
  <li>virtual <strong>functions</strong></li>
  <li>优势
    <ul>
      <li>自动 scaling</li>
      <li>deployed globally</li>
      <li>Lambda 的concurrency setting on function 体现了Well-Architected Framework的 <strong>Performance efficiency and cost optimization</strong></li>
    </ul>
  </li>
  <li>限制因素， （超过了下面这些限制就不要用lambda 了）
    <ul>
      <li>不能跨 region</li>
      <li>每个Lambda 最多可以运行15分钟，如果需要运行1小时的应用，就别用Lambda了</li>
      <li>内存限制128m-10g</li>
      <li>环境变量 4k</li>
      <li>磁盘使用的大小 512M</li>
      <li>Lamdba 代码和依赖包大小 250M</li>
      <li>Lambda 压缩包大小50M</li>
      <li>并发的lambda 个数1000（可以联系管理员（AWS Support）增加）</li>
    </ul>
  </li>
  <li>和Lambda 整合的主要服务
    <ul>
      <li>API Gateway</li>
      <li>Kinesis</li>
      <li>DynamoDB</li>
      <li>S3</li>
      <li>CloudFront</li>
      <li>CloudWatch/Event Bridge</li>
      <li>CloudWatch Logs</li>
      <li>SNS/SQS</li>
      <li>Cognito</li>
      <li>etc….</li>
    </ul>
  </li>
  <li>Pricing
    <ul>
      <li>Lambda 按照vCPU 和 Memory 的使用收费</li>
      <li>同时 也对程序的运行时间收费
        <ul>
          <li>所以要在Lambda function 中设置超时退出功能，否则程序一直run 会造成多花没必要的钱。</li>
        </ul>
      </li>
      <li>可以选择多种支付方式
        <ul>
          <li>pey per calls</li>
          <li>pay per duration</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="lambda-edge">Lambda Edge</h4>

<ul>
  <li>应用于CloudFront</li>
  <li>When a Lambda function version is deployed to Lambda@Edge, it becomes a globally scoped resource.</li>
  <li>可以用Lambda 在边缘侧辅助CloudFront 做一些逻辑处理
    <ul>
      <li>对到应用的请求进行过滤</li>
      <li>修改 CloudFront request 和 response
        <ul>
          <li>收到user 的请求后修改 - viewer request</li>
          <li>发送给origin 时修改 - origin request</li>
          <li>得到origin响应时修改 - origin response</li>
          <li>返回给user 时修改 - viewer response</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>应用场景
    <ul>
      <li>网站安全和隐私处理</li>
      <li>搜索引擎优化</li>
      <li>处理爬虫 （bot mitigation）</li>
      <li>实时边缘侧图片转换</li>
      <li>A/B 测试 at edge</li>
      <li>用户认证/登录</li>
      <li>用户行为分析</li>
    </ul>
  </li>
</ul>

<h4 id="lambda-最佳实践">Lambda 最佳实践</h4>

<ul>
  <li>如果Lambda中有代码会被其他lambda重用， 那么最好的办法是做一个Layer， Layer是一个zip 压缩包， 类似于一个类库， 可以被很多lamdba调用， 避免重复code.</li>
  <li>Lambda 可以被打包放在容器中</li>
  <li>所有Lamdba的依赖包都应该和Lamdba一起打到一个包里面</li>
  <li>不要过度配置lambda函数的超时来提高可以占用的内存大小， 否则会有意想不到的额外费用产生。</li>
  <li>Lambda默认是属于一个VPC的， 一旦VPC-enabled for Lamdba, 就需要设置路由， 让它能通过NAT访问互联网。</li>
  <li>Lamdba可以快速根据流量的情况自动伸缩， 所以最好设置一个CloudWatch Alarm服务, 当lambda发生伸缩的时候（ConcurrentExecutions or Invocations exceeds the expected threshold）可以及时通知团队</li>
</ul>

<h4 id="lambda-runtime-支持的开发语言">Lambda runtime 支持的开发语言</h4>

<ul>
  <li>C#/.NET</li>
  <li>Go</li>
  <li>Java</li>
  <li>Node.js</li>
  <li>Python</li>
  <li>Ruby</li>
</ul>

<h4 id="lambda-access-policy">Lambda access policy</h4>

<ul>
  <li>Lambda 函数访问策略具有多个灵活性范围，并且可以在 Lambda 服务中包含不同的资源和版本。Lambda 函数访问策略包括
    <ul>
      <li>Function</li>
      <li>Version</li>
      <li>Alias</li>
      <li>Layer version</li>
    </ul>
  </li>
</ul>

<h3 id="dynamodb">DynamoDB</h3>

<h4 id="dynamodb-1">DynamoDB</h4>

<ul>
  <li>跨AZ, 的高可用，自动伸缩， No-Sql数据库</li>
  <li>DynamoDB 不是in-memory 数据库</li>
  <li>Table 是存数据的表
    <ul>
      <li>每个表有一个primary key, 创建的时候就需要指定</li>
      <li>每个表可以设置sort key, 用来排序</li>
      <li>每个表可以有无限个 items(rows)</li>
      <li>每个 item 可以有attributes （column）, 随便多少，随便是什么。 可以是null, 最大400k.</li>
      <li>DnyamoDB 的Item 有TTL 限制， 过期会被删掉</li>
      <li>DynamoDB tables can be configured using either On-Demand or Provisioned mode.
        <ul>
          <li>on-demand 可以支持 highly resilient and capable of automatically scaling read and write capacity.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>安全
    <ul>
      <li>IAM Role</li>
    </ul>
  </li>
</ul>

<h4 id="dynamodb-pricing--readwrite-capacity-mode">DynamoDB pricing , Read/Write Capacity Mode</h4>

<ul>
  <li>DynamoDB 的付费方式决定了读写能力</li>
  <li>两种付费方式
    <ul>
      <li>Provisioned mode (default)
        <ul>
          <li>可以测流量的时候用</li>
          <li>可设置 auto-scaling</li>
          <li>需要先设置好读和写的吞吐量</li>
          <li>读的单位是RCU （Read Capacity union）， 比如每秒读5M</li>
          <li>写的单位是WCU</li>
          <li></li>
        </ul>
      </li>
      <li>On-Demand Mode
        <ul>
          <li>不可预测流量的时候用</li>
          <li>用多少付多少，</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="dynamodb-accelerator-dax">DynamoDB Accelerator (DAX)</h4>

<ul>
  <li>可以理解成DynamoDB 的缓存， 加速DynamoDB 对外read 响应的效率</li>
  <li>DynamoDB Dax 不是 in-memory DB, 但是有 in-memory cache 功能</li>
  <li>5分钟的TTL for Cache(default)</li>
  <li>DAX 可以提高10倍的DynamoDB 的performance</li>
  <li>DAX 将是透明的，不需要重构应用程序, 所以解决了热分区（hot partition problem）问题。</li>
</ul>

<h4 id="dynamodb-streams">DynamoDB Streams</h4>

<ul>
  <li>有点类似S3 Event Notification 功能， 当对DynamoDB 进行 create/update/delete 动作时触发事件， 就会以stream 的方式输出数据和其他AWS服务进行互动</li>
  <li>item-level
    <ul>
      <li>发送到 Kinesis data stream</li>
      <li>被lambda读取</li>
      <li>被 kinesis client library 读取</li>
      <li>etc…</li>
    </ul>
  </li>
  <li>例题：
    <ol>
      <li>客户要找一个可以自动伸缩， 高可用， 可以根据IoT的 data feed 随时处理data attributes over time(随时), 可以基于数据提供输出一个 持续的 stream 。 你建议的数据库是：
        <ol>
          <li>DynameDB</li>
        </ol>
      </li>
    </ol>
  </li>
</ul>

<h4 id="dynamodb-global-tables">DynamoDB Global Tables</h4>

<ul>
  <li>两个table 分别在两个region</li>
  <li>之间通过 two-way replication 进行数据同步</li>
  <li>也叫做 active-active replication</li>
  <li>应用可以read /write 到任何一个table</li>
  <li>前提条件是要打开 DynamoDB Stream, DynamoDB Stream 会把 changlog 来在另一个region 中的DB中复制数据</li>
  <li>好处
    <ul>
      <li>Lower latency of table access</li>
    </ul>
  </li>
</ul>

<h4 id="dynamodb---ttl">DynamoDB - TTL</h4>

<ul>
  <li>每条item 都有一个过期时间的字段</li>
  <li>DynamoDB 会定期扫描过期item, 找到就删掉</li>
  <li>场景
    <ul>
      <li>通过只保留近期的数据来减少不必要的数据量</li>
      <li>有法规要求， 只能保留xxx 天数据</li>
    </ul>
  </li>
</ul>

<h4 id="dynamodb---transactions-事务">DynamoDB - Transactions （事务）</h4>

<ul>
  <li>写两个表， 要么都成功，要么都失败</li>
  <li>如果写第二个表的时候失败了， 第一个成功了也要被撤销。</li>
</ul>

<h2 id="特色服务">特色服务</h2>

<h3 id="cloudformation">CloudFormation</h3>

<h4 id="cloudformation-1">CloudFormation</h4>

<ul>
  <li>
    <p>Infrastructure as code.</p>
  </li>
  <li>
    <p>描述一个infrastructure, CloudFormation 就帮你把它创造出来了</p>

    <ul>
      <li>要安全组</li>
      <li>要两个 EC2 使用这个安全组</li>
      <li>要两个EIP, 绑定两个EC2</li>
      <li>要S3</li>
      <li>要个ELB, 放在前面</li>
      <li>….</li>
    </ul>
  </li>
  <li>
    <p>Stack</p>

    <ul>
      <li>一个Stack 是一堆AWS 资源的集合， 你可以把它们看做是一个单位进行管理.</li>
      <li>StackSet - 可以跨账号、跨Region deploy 相同的template</li>
      <li>StackSet 可以用一个CloudFormation模板(template) 就可以给多个账号部署相同的AWS 资源</li>
      <li>需要通过Org 的 admin 账号设置 CloudFormation 的 template</li>
    </ul>

    <p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h13m89r9pjj20hi0a4aa9.jpg" alt="img" /></p>
  </li>
  <li>
    <p>Template 保存在S3 上</p>
  </li>
  <li>
    <p>带版本</p>

    <ul>
      <li>要update 一个 模板，不能删改原来的， 只能建一个新的版本修改</li>
    </ul>
  </li>
  <li>
    <p>模板中的一些关键参数</p>

    <ul>
      <li>Resource - 自己的AWS 资源</li>
      <li>Parameters - dynamic 输入变量</li>
      <li>Mappings - static 输入变量</li>
      <li>Outputs - 指已经创建出来的内容</li>
      <li>Conditionals: 列出创建资源需要的依赖</li>
      <li>Metadata - 元数据</li>
    </ul>
  </li>
  <li>
    <p>CloudFormation StackSets</p>

    <ul>
      <li></li>
    </ul>
  </li>
  <li>
    <p>好处</p>

    <ul>
      <li>快速部署和重建环境</li>
      <li>自动出一个架构图</li>
      <li>可以生成一个模板，方便重用， 避免重新发明轮子</li>
      <li>还可能出文档</li>
    </ul>
  </li>
</ul>

<h4 id="cloudformation与beanstalk区别">CloudFormation与BeanStalk区别</h4>

<ul>
  <li>都可以用来调用云资源和服务，也可以做相同的一件事情
    <ul>
      <li>都可以快速创建应用环境</li>
    </ul>
  </li>
  <li>他们的区别如下：</li>
</ul>

<ol>
  <li>CloudFormation面向的是开发者，BeanStalk面向的是应用程序</li>
  <li>CloudFormation是为做某件事情而整合资源，BeanStalk是为某个应用程序而整合资源。</li>
  <li>使用CloudFormation要比使用BeanStalk复杂得多，CloudFormation的配置模版是一份json数据，这个对于不懂编程的人来说很难应用！BeanStalk可以通过界面向导来配置。</li>
</ol>

<h3 id="step-function">Step Function</h3>

<ul>
  <li>无服务虚拟工作流</li>
  <li>配合Lambda ，Glue 等无服务一起使用</li>
  <li>json 格式</li>
  <li>包括的功能
    <ul>
      <li>顺序</li>
      <li>并行</li>
      <li>条件</li>
      <li>超时</li>
      <li>错误处理。。。。</li>
    </ul>
  </li>
  <li>可以整合的服务
    <ul>
      <li>EC2,</li>
      <li>ECS,</li>
      <li>On- premise server</li>
      <li>API Gateway</li>
    </ul>
  </li>
  <li>最多可执行1年</li>
  <li>场景
    <ul>
      <li>工作流</li>
      <li>订单处理流程</li>
      <li>数据处理流程</li>
      <li>网页应用。。。</li>
    </ul>
  </li>
</ul>

<h3 id="swf---simple-workflow-service">SWF - Simple Workflow Service</h3>

<ul>
  <li>和 Step Function 都是工作流服务</li>
  <li>运行在EC2 上的工作流服务</li>
  <li>功能和Step Funcing 类似</li>
  <li>AWS 更推荐用 Step Funcing 做工作流</li>
  <li>但是SWF有一些特色是Step Function 没有的
    <ul>
      <li>需要外部的信号干预流程</li>
      <li>需要子进程把信息返回给父进程</li>
    </ul>
  </li>
</ul>

<h3 id="emr---elastic-map-reduce">EMR - Elastic Map Reduce</h3>

<ul>
  <li>做大数据计算分析用的框架</li>
  <li>通过Hadoop Cluster 创建</li>
  <li>底层是EC2 实例 （可以有上百个）</li>
  <li>使用 Spot 实例进行自动伸缩</li>
  <li>支持 Apache Spark, HBase, Presto, Flink…</li>
  <li>关键词：
    <ul>
      <li>数据处理</li>
      <li>机器学习</li>
      <li>web 索引</li>
      <li>大数据</li>
    </ul>
  </li>
</ul>

<h3 id="opswork">OpsWork</h3>

<ul>
  <li>自动化运维工具</li>
  <li>底层是 Puppet 和 Chef</li>
  <li>和EC2, on-premise VM 配合</li>
  <li>Chef / Puppet 介绍
    <ul>
      <li>Managing configuration as code</li>
      <li>使用 Recipes 和 Manifests 来管理配置</li>
      <li>和 SSM/Beanstalk/CloudFormation 作用类似， 但是 Chef/Puppet 是开源的</li>
    </ul>
  </li>
  <li>关键词
    <ul>
      <li>Puppet</li>
      <li>Chef</li>
    </ul>
  </li>
</ul>

<h3 id="workspaces">WorkSpaces</h3>

<ul>
  <li>安全的云桌面 (Cloud Desktop）</li>
  <li>是集成了on-premise 的 <strong>VDI</strong> (Virtual Desktop Infrastructure)</li>
  <li>整合了微软的 AD</li>
  <li>关键词
    <ul>
      <li>VDI</li>
      <li>Desktop</li>
    </ul>
  </li>
</ul>

<h3 id="appsync">AppSync</h3>

<ul>
  <li>在Web App 和Mobile 之间保存，实时同步数据</li>
  <li>使用 GraphQL (Facebook 的移动技术)</li>
  <li>和DynamoDB / Lambda 整合</li>
  <li>实时订阅</li>
  <li>离线数据同步</li>
  <li>关键词：
    <ul>
      <li>在web 和 mobile app之间同步数据</li>
      <li>GraphQL</li>
    </ul>
  </li>
</ul>

<h3 id="cost-explorer">Cost Explorer</h3>

<ul>
  <li>把在AWS 使用的成本视觉化，便于理解</li>
  <li>创建客户报告分析成本和使用数据</li>
  <li>跨账号分析cost</li>
  <li>按天，月，等时间尺度分析</li>
  <li>可选择做一个 Saving Plan 来优化成本</li>
  <li>通过过去的使用预测未来12个月的成本</li>
  <li>关键词
    <ul>
      <li>成本有点高</li>
      <li>节省成本</li>
      <li>预测未来12个月内的成本</li>
    </ul>
  </li>
</ul>

<h3 id="cicd">CICD</h3>

<h4 id="cicd-1">CICD</h4>

<ul>
  <li>
    <p>AWS 提供一系列工具来进行CICD</p>
  </li>
  <li>
    <p>整体用 AWS CodePipeline 作为底层支撑， 上面包含了：</p>

    <ul>
      <li>
        <p>CodeCommit</p>

        <ul>
          <li>Code 管理</li>
        </ul>
      </li>
      <li>
        <p>底层是 GitHub</p>
      </li>
      <li>
        <p>CodeBuild</p>

        <ul>
          <li>Build Test</li>
        </ul>
      </li>
      <li>
        <p>底层是 Jenkins</p>
      </li>
      <li>
        <p>BeansTalk / CodeDeploy</p>

        <ul>
          <li>deploy , Perversion</li>
        </ul>
      </li>
      <li>
        <p>底层是EC2, CloudFormation</p>
      </li>
    </ul>
  </li>
</ul>

<p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h0ozej2pccj20n70cqmxi.jpg" alt="img" /></p>

<h4 id="codedeploy">CodeDeploy</h4>

<ul>
  <li>
    <p>AWS CodeDeploy 可自动将软件部署到各种计算服务，例如</p>

    <ul>
      <li>EC2、</li>
      <li>Fargate、</li>
      <li>Lambda</li>
      <li>和您的本地服务器。</li>
    </ul>
  </li>
  <li>
    <p>您可以定义要执行的策略，例如就地部署或蓝/绿部署。</p>
  </li>
</ul>

<h3 id="compute-optimizer">Compute optimizer</h3>

<ul>
  <li>找到计算资源的优化空间</li>
  <li>往往配合Cost Explorer 一起使用</li>
</ul>

<h3 id="trusted-advisor---可信的顾问">Trusted Advisor - 可信的顾问</h3>

<ul>
  <li>优化性能和安全方面的建议</li>
  <li>不能优化成本</li>
</ul>

<h3 id="几个-advisor-的比较">几个 advisor 的比较</h3>

<h4 id="trusted-advisor-account-level">Trusted Advisor (account level)</h4>

<ul>
  <li>查看账号下服务的性能和安全情况， 并给出建议</li>
</ul>

<p><strong>Access advisor</strong> (user level)</p>

<ul>
  <li>可以看到有哪些服务权限授予了这个用户， 并且可以看到什么时候用户对这些服务进行了访问</li>
</ul>

<p><strong>Access Analyzer</strong></p>

<ul>
  <li>分析哪些资源分享给了外部实体</li>
</ul>


            </div>

            <!-- Rating -->
            
            <div class="rating mb-4 d-flex align-items-center">
                <strong class="mr-1">Rating:</strong> <div class="rating-holder">
<div class="c-rating c-rating--regular" data-rating-value="4.5">
  <button>1</button>
  <button>2</button>
  <button>3</button>
  <button>4</button>
  <button>5</button>
</div>
</div>
            </div>
            

            <!-- Post Date -->
            <p>
            <small>
                <span class="post-date"><time class="post-date" datetime="2022-04-23">23 Apr 2022</time></span>           
                
                </small>
            </p>

            <!-- Post Categories -->
            <div class="after-post-cats">
                <ul class="tags mb-4">
                    
                    
                    <li>
                        <a class="smoothscroll" href="/categories#AWS">AWS</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="/categories#Architecture">Architecture</a>
                    </li>
                    
                </ul>
            </div>
            <!-- End Categories -->

            <!-- Post Tags -->
            <div class="after-post-tags">
                <ul class="tags">
                    
                    
                </ul>
            </div>
            <!-- End Tags -->

            <!-- Prev/Next -->
            <div class="row PageNavigation d-flex justify-content-between font-weight-bold">
            
            <a class="prev d-block col-md-6" href="//Python-in-Container-02/"> &laquo; Python in Container Part Two</a>
            
            
            <a class="next d-block col-md-6 text-lg-right" href="//Agile-Project-Management-and-Agile-Delivery/">Agile Project Management and Agile Delivery &raquo; </a>
            
            <div class="clearfix"></div>
            </div>
            <!-- End Categories -->

        </div>
        <!-- End Post -->

    </div>
</div>
<!-- End Article
================================================== -->

<!-- Begin Comments
================================================== -->

    <div class="container">
        <div id="comments" class="row justify-content-center mb-5">
            <div class="col-md-8">
                <section class="disqus">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        var disqus_shortname = 'demowebsite'; 
        var disqus_developer = 0;
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = window.location.protocol + '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>

            </div>
        </div>
    </div>

<!--End Comments
================================================== -->

<!-- Review with LD-JSON, adapt it for your needs if you like, but make sure you test the generated HTML source code first: 
https://search.google.com/structured-data/testing-tool/u/0/
================================================== -->

<script type="application/ld+json">
{
  "@context": "http://schema.org/",
  "@type": "Review",
  "itemReviewed": {
    "@type": "Thing",
    "name": "Step by Step for AWS Certified Solutions Architect Associate"
  },
  "author": {
    "@type": "Person",
    "name": "Dalong"
  },
  "datePublished": "2022-04-23",
  "reviewRating": {
    "@type": "Rating",
    "ratingValue": "4.5",
    "bestRating": "5"
  }
}
</script>

</div>


    
</div>

<!-- Categories Jumbotron
================================================== -->
<div class="jumbotron fortags">
	<div class="d-md-flex h-100">
		<div class="col-md-4 transpdark align-self-center text-center h-100">
            <div class="d-md-flex align-items-center justify-content-center h-100">
                <h2 class="d-md-block align-self-center py-1 font-weight-light">Explore <span class="d-none d-md-inline">→</span></h2>
            </div>
		</div>
		<div class="col-md-8 p-5 align-self-center text-center">
            
            
                
                    <a class="mt-1 mb-1" href="/categories#Linux">Linux (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Python">Python (16)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Mysql">Mysql (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Redis">Redis (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#MongoDB">MongoDB (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Flask">Flask (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Django">Django (2)</a>
                
                    <a class="mt-1 mb-1" href="/categories#DjangoRest">DjangoRest (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Numpy">Numpy (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Panda">Panda (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Sklearn">Sklearn (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Jupyter">Jupyter (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#OpenCV">OpenCV (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#AI">AI (3)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Tensorflow">Tensorflow (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Microservice">Microservice (2)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Docker">Docker (3)</a>
                
                    <a class="mt-1 mb-1" href="/categories#NLP">NLP (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#AWS">AWS (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Architecture">Architecture (2)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Agile">Agile (2)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Scrum">Scrum (2)</a>
                
                    <a class="mt-1 mb-1" href="/categories#MLPS">MLPS (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#PIPL">PIPL (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Metaverse">Metaverse (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Togaf">Togaf (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#ChatGPT">ChatGPT (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#OpenAI">OpenAI (2)</a>
                
                    <a class="mt-1 mb-1" href="/categories#LLM">LLM (2)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Azure">Azure (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Data-Science">Data Science (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#ITIL">ITIL (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#IT">IT (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Jekyll">Jekyll (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Github">Github (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Liquid">Liquid (1)</a>
                
                    <a class="mt-1 mb-1" href="/categories#Markdown">Markdown (1)</a>
                
            
            
		</div>
	</div>
</div>

<!-- Begin Footer
================================================== -->
<footer class="footer">
    <div class="container">
        <div class="row">
            <div class="col-md-6 col-sm-6 text-center text-lg-left">
                Copyright © 2023 Dalong's personal blog 
            </div>
            <div class="col-md-6 col-sm-6 text-center text-lg-right">    
                <a target="_blank" href="#">Designed</a> by Dalong.work
            </div>
        </div>
    </div>
</footer>
<!-- End Footer
================================================== -->

</div> <!-- /.site-content -->

<!-- Scripts
================================================== -->

<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script>

<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js" integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k" crossorigin="anonymous"></script>

<script src="/assets/js/mediumish.js"></script>



<script src="/assets/js/ie10-viewport-bug-workaround.js"></script> 


<script id="dsq-count-scr" src="//demowebsite.disqus.com/count.js"></script>


</body>
</html>
